<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>笑松小站</title>
  
  <subtitle>写我喜欢 读我所爱</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://peachyy.gitee.io/"/>
  <updated>2023-03-25T06:06:24.523Z</updated>
  <id>https://peachyy.gitee.io/</id>
  
  <author>
    <name>peachyy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kubernetes健康检查liveness readiness startupProbe探针</title>
    <link href="https://peachyy.gitee.io/2023/03/25/k8s-liveness-readiness-startup/"/>
    <id>https://peachyy.gitee.io/2023/03/25/k8s-liveness-readiness-startup/</id>
    <published>2023-03-24T16:00:00.000Z</published>
    <updated>2023-03-25T06:06:24.523Z</updated>
    
    <content type="html"><![CDATA[<p>由于历史项目跑在kubernetes中 出现了一些如下问题 </p><ul><li>程序发布的时候 新版本的pod还没有启动成功 老版本的pod就已经停止了 ，这就导致部分请求访问到了新pod，由于新pod内程序还没有启动成功，所有这部分请求就以失败告终。还有可能新pod 启动失败了 就会出现pod一直在重启 然而服务又不可用。</li><li>运行中的pod 因为网络或者某种原因导致服务暂时不可用，对于kubernetes来说pod是状态是正常的，这时候的业务流量也可能会分发在次pod中，也是会报错误失败。</li><li>如何让kubernetes定义pod是否健康 是否启动成功？</li></ul><h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>当前的kubernetes版本为 v1.19 提供了三种健康检查。</p><ol><li><p>存活探针 livenessProbe：通过检测容器响应是否正常来决定是否<em>重启</em></p><p>如果此探针检查失败 会重启容器</p></li><li><p>就绪探针 readinessProbe:  用来确定容器是否已经就绪可以<em>接受请求</em></p><p>如果配置了就绪探针 只有通过探针检查后 才会认为pod具备访问的能力，kubernetes才会把ip port 加入到service中的endpoint中去，反之失败也会从endpoint中移除，这样流量就不会被分配到没有准备好的容器中去。</p></li><li><p>启动探针 startupProbe: 检测容器内应用是否<em>已经启动</em> v1.18+才支持</p><p>启动探针在没有探测成功之前 livenessProbe、readinessProbe 探针会处于禁用状态。基于此特性 就可以避免livenessProbe由于一直失败 一直重启容器的死锁问题。</p></li></ol><p>这3种探针都分别提供3种探测方式 </p><ul><li>exec 执行命令行检查  如果返回值为0，则认为容器健康。</li><li>httpGet  HTTP请求检查  如果状态码为200~400之间，则认为容器健康</li><li>tcpSocket TCP端口检查  如果端口是通的就认为容器健康。</li></ul><p>由于项目使用SpringBoot 2.2.6项目 就自然使用到了spring-boot-starter-actuator包，<em>注意</em> 这里不同的Boot版本有点区别 如1.x，2.2.x和2.3 配置暴露指标的访问有些不一样。</p><p>springboot2.3+版本 还有提供 可读就绪指标<code>/actuator/health/readiness</code>   和 存活指标<code>/actuator/health/liveness</code>接口 可以直接分别用于kubernetes的就绪探针和存活探针。由于这里使用的2.2.6就都使用<code>/actuator/health</code>指标。</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>配置暴露health指标</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">management.endpoints.web.base-path=/actuator</span><br><span class="line">management.endpoints.web.exposure.include=health</span><br></pre></td></tr></table></figure><p>配置启动探针检查  理论是只有应用启动成功之后 才能对外提供服务 所以配置了httpGet探针来探测容器内 <code>ip:port/actuator/health</code>地址 如能成功返回200则认为是启动成功。 </p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">startupProbe:</span>  <span class="comment"># 启动探针</span></span><br><span class="line"><span class="attr">  httpGet:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/actuator/health</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  failureThreshold:</span> <span class="number">30</span></span><br></pre></td></tr></table></figure><p>这里额外配置了一些指标参数。三种探针 startupProbe 、livenessProbe、readinessProbe 都是一样的配置 这也是kubernetes在健康检查的配置上做得比较优秀的地方。</p><ul><li>periodSeconds  检查周期(s) 多少秒去检查一次</li><li>initialDelaySeconds 延迟时间 (s) pod启动后 延迟多少时间 (s)后再去检查</li><li>timeoutSeconds 超时时间 (s)  访问探测方式的超时时间  如上面访问<code>ip:port/actuator/health</code>如果5秒还没有返回则认为是超时失败。</li><li>successThreshold 成功阈值 (次数)  默认情况下 只要有1次访问成功 就算成功</li><li>failureThreshold  最大失败次数 如上面配置的30次  30次都尝试都失败就表示Pod启动失败。这里可以配合periodSeconds参数来控制某些程序启动耗费时间太长的问题 如上面配置30*10=300s都没有成功的话 就失败。</li></ul><p>配置存活探针 其目的是为了探测保证程序假死的情况 </p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">livenessProbe:</span>                 <span class="comment"># 存活探针</span></span><br><span class="line"><span class="attr">  httpGet:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/actuator/health</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  failureThreshold:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><p>配置就绪探针 其目的是为了探测保证程序随时都可用  如果就绪探针出现不可用的时候 会剔除service中的endpoint的ip port。保证流量只分发到可用的容器中去。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">readinessProbe:</span>                <span class="comment"># 就绪探针</span></span><br><span class="line"><span class="attr">  httpGet:</span></span><br><span class="line"><span class="attr">      path:</span> <span class="string">/actuator/health</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">  initialDelaySeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  periodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">  timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  successThreshold:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  failureThreshold:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><p>这3中探针并不是必须都要配置， 需要视情况配置，如果不配置的情况下 默认按照Pod状态读取。如果Pod状态是成功  那么就认为是存活的、就绪的。</p><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><ol><li><p>刚开始只配置了存活探针和就绪探针。导致启动的时候  存活探针一直失败达到了重启的条件。就出现一直重启pod的情况。后面加了启动探针 保证启动时间周期内不触发就绪探针。尽可能的配置failureThreshold * periodSeconds 来包容最坏情况下的启动耗时。</p></li><li><p>部分服务出现deadline的情况 </p><p> <code>context deadline exceeded (Client.Timeout exceeded while awaiting headers)Back-off restarting failed container</code></p><p>可以把timeoutSeconds 配置调节大几秒钟。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;由于历史项目跑在kubernetes中 出现了一些如下问题 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;程序发布的时候 新版本的pod还没有启动成功 老版本的pod就已经停止了 ，这就导致部分请求访问到了新pod，由于新pod内程序还没有启动成功，所有这部分请求就以失败告终。还有可能新po
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/kubernetes/"/>
    
    
      <category term="java" scheme="https://peachyy.gitee.io/tags/java/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>proto IDL管理工具buf使用实践</title>
    <link href="https://peachyy.gitee.io/2022/12/19/proto_buf_build/"/>
    <id>https://peachyy.gitee.io/2022/12/19/proto_buf_build/</id>
    <published>2022-12-18T16:00:00.000Z</published>
    <updated>2022-12-20T05:07:31.957Z</updated>
    
    <content type="html"><![CDATA[<p>proto是在当今使用最广泛的IDL之一，起因是dubbo3的<strong>Triple</strong> 协议需要用到proto文件来生成统一规范的跨语言代码，Grpc也有类似的问题，想想一个团队有很多的业务模块，涉及到一些相互调用依赖的问题，如 A模块需要用到B模块的接口，就需要找到B模块开发者，请告知一下 B模块相关的proto文件是哪些，我需要copy到A模块来生成客户端调用代码，虽说这个场景单看起来条理是清晰的，后续如果越来越多的模块需要相互引用依赖，版本变更 ，昨天提供给你的proto文件 今天已经被提供者加了字段 或者删减了字段，需要一一通知到位，并需要重新copy最新的proto文件给使用者，如果B模块又依赖了C模块，这个时候如果使用者要用到B模块的时候 需要把B、C相关的proto都要提供，处理这类繁琐易错的问题还是相当复杂的。所以让<code>buf</code>来帮你解决这个问题。</p><p><strong>buf 可以解决</strong></p><ul><li>统一管理proto文件 类似git一样 区分仓库 Buf Schema Registry（BSR）支持远程拉取、推送、提交。</li><li>检查proto依赖以及语法问题</li><li>检查兼容性问题</li><li>生成多语言代码 根据buf.gen.yaml 自定义配置非常很方便</li></ul><h4 id="buf安装"><a href="#buf安装" class="headerlink" title="buf安装"></a>buf安装</h4><p> 以下软件环境均在linux x64，需要安装go环境。官方提供源码、二进制包、Tarball 3种安装方式 为了方便这里使用官方二进制包方式。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">BIN="/usr/local/bin" &amp;&amp; \</span><br><span class="line">VERSION="1.10.0" &amp;&amp; \</span><br><span class="line">  curl -sSL \</span><br><span class="line">    "https://github.com/bufbuild/buf/releases/download/v$&#123;VERSION&#125;/buf-$(uname -s)-$(uname -m)" \</span><br><span class="line">    -o "$&#123;BIN&#125;/buf" &amp;&amp; \</span><br><span class="line">  chmod +x "$&#123;BIN&#125;/buf"</span><br></pre></td></tr></table></figure><p>验证buf命令是否安装成功 能输出一系类的命令使用帮助表示安装就没问题。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf --help</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line"> beta        Beta commands. Unstable and likely to change.</span><br><span class="line"> breaking    Verify that the input location has no breaking changes compared to the against location.</span><br><span class="line"> build       Build all Protobuf files from the specified input and output a Buf image.</span><br><span class="line"> completion  Generate auto-completion scripts for commonly used shells.</span><br><span class="line"> convert     Convert a message from binary to JSON or vice versa</span><br><span class="line"> export      Export the files from the input location to an output location.</span><br><span class="line"> format      Format all Protobuf files from the specified input and output the result.</span><br><span class="line"> generate    Generate stubs for protoc plugins using a template.</span><br><span class="line"> help        Help about any command</span><br><span class="line"> lint        Verify that the input location passes lint checks.</span><br><span class="line"> ls-files    List all Protobuf files for the input.</span><br><span class="line"> mod         Manage Buf modules.</span><br><span class="line"> push        Push a module to a registry.</span><br><span class="line"> registry    Manage assets on the Buf Schema Registry.</span><br></pre></td></tr></table></figure><p>再安装一个protoc 针对后面java 、c++语言的生成代码演示 <em>如果只是为了生成grpc go的话可以不安装</em></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/protocolbuffers/protobuf/releases/download/v21.12/protoc-21.12-linux-x86_64.zip</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">把protoc可执行文件放再 /usr/<span class="built_in">local</span>/bin 方便直接执行</span></span><br><span class="line">cp bin/protoc /usr/local/bin/</span><br><span class="line"><span class="meta">#</span><span class="bash">验证</span></span><br><span class="line">protoc --version</span><br></pre></td></tr></table></figure><p>输出libprotoc 3.21.12 表示安装成功。</p><p>安装protoc go grpc代码生成工具 用于后续生成go代码</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">go install google.golang.org/protobuf/cmd/protoc-gen-go@latest</span><br><span class="line">go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest</span><br><span class="line">export PATH="$PATH:$(go env GOPATH)/bin"</span><br></pre></td></tr></table></figure><h4 id="build-ls-files"><a href="#build-ls-files" class="headerlink" title="build ls-files"></a>build ls-files</h4><p>clone示例proto文件仓库用于下面演示</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/DemoHubs/bufbuilddemo.git</span><br></pre></td></tr></table></figure><p>该演示项目大概是一个宠物服务的API接口定义。目录中有2个文件夹 start目录表示为你准备演示工作的proto文件, finish目录表示 start相关演示执行后的目录的样子 这里先不关注finish目录 。</p><h5 id="ls-files-用于查询目录下的proto文件列表"><a href="#ls-files-用于查询目录下的proto文件列表" class="headerlink" title="ls-files 用于查询目录下的proto文件列表"></a><strong>ls-files</strong> 用于查询目录下的proto文件列表</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bufbuilddemo </span><br><span class="line">buf ls-files</span><br><span class="line">-----------输出---------</span><br><span class="line">finish/paymentapis/payment/v1alpha1/payment.proto</span><br><span class="line">finish/petapis/pet/v1/pet.proto</span><br><span class="line">start/petapis/google/type/datetime.proto</span><br><span class="line">start/petapis/pet/v1/pet.proto</span><br></pre></td></tr></table></figure><p>你也可以用仓库clone到本地 用远程输入仓库的方式查询 还是非常方便的 </p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf ls-files "https://github.com/DemoHubs/bufbuilddemo.git#branch=main,subdir=start/petapis"</span><br><span class="line">------------输出---------</span><br><span class="line">start/petapis/google/type/datetime.proto</span><br><span class="line">start/petapis/pet/v1/pet.proto</span><br></pre></td></tr></table></figure><p>其中远程输入的地址加了参数 </p><p><code>branch</code> 表示查看的是哪个分支 这里是main分支</p><p><code>subdir</code> 表示查询的文件加是哪一个 支持多层级查找 这里查询的是 仓库种start/petapis目录下包含的proto文件列表</p><p>输入文档类型 支持 git dir mod tar zip 等主流的方式。</p><h5 id="配置一个新的buf空间"><a href="#配置一个新的buf空间" class="headerlink" title="配置一个新的buf空间"></a>配置一个新的buf空间</h5><p>进入bufbuilddemo/start/petapis，执行 buf mod init 会在当前目录中生成默认的buf.yaml文件,如果是一个新模块 就从这里开始让buf来管理你的proto文件。</p>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd bufbuilddemo/start/petapis</span><br><span class="line">buf mod init</span><br><span class="line">----- 生成的buf.yaml文件--------------</span><br><span class="line">version: v1</span><br><span class="line">breaking:</span><br><span class="line">  use:</span><br><span class="line">    - FILE</span><br><span class="line">lint:</span><br><span class="line">  use:</span><br><span class="line">    - DEFAULT</span><br></pre></td></tr></table></figure><h4 id="lint-检查你的proto规范"><a href="#lint-检查你的proto规范" class="headerlink" title="lint 检查你的proto规范"></a>lint 检查你的proto规范</h4><p>回到示例仓库 。进入bufbuilddemo/start/petapis 。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf lint </span><br><span class="line">------输出--------------</span><br><span class="line">google/type/datetime.proto:17:1:Package name "google.type" should be suffixed with a correctly formed version, such as "google.type.v1".</span><br><span class="line">pet/v1/pet.proto:44:10:Field name "petID" should be lower_snake_case, such as "pet_id".</span><br><span class="line">pet/v1/pet.proto:49:9:Service name "PetStore" should be suffixed with "Service".</span><br></pre></td></tr></table></figure><p>上面输入的可读性很差 可以指定以json的方式输出就好看多了。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf lint --error-format=json</span><br><span class="line">------输出----------</span><br><span class="line">&#123;"path":"google/type/datetime.proto","start_line":17,"start_column":1,"end_line":17,"end_column":21,"type":"PACKAGE_VERSION_SUFFIX","message":"Package name \"google.type\" should be suffixed with a correctly formed version, such as \"google.type.v1\"."&#125;</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","start_line":44,"start_column":10,"end_line":44,"end_column":15,"type":"FIELD_LOWER_SNAKE_CASE","message":"Field name \"petID\" should be lower_snake_case, such as \"pet_id\"."&#125;</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","start_line":49,"start_column":9,"end_line":49,"end_column":17,"type":"SERVICE_SUFFIX","message":"Service name \"PetStore\" should be suffixed with \"Service\"."&#125;</span><br></pre></td></tr></table></figure><p>可以看到规范检查输出了错误，这些buf默认的规范检查定义 在buf.yaml中可以看到 lint.use=DEFAULT。当然也是可以去掉某些规则</p><p>第1个错误 google/type/datetime.proto 第17行后缀不对。规则 <a href="https://docs.buf.build/lint/rules#package_version_suffix" target="_blank" rel="noopener"><code>PACKAGE_VERSION_SUFFIX</code></a></p><p>第2个错误 pet/v1/pet.proto 文件44行petID命名不对。规则 <a href="https://docs.buf.build/lint/rules#field_lower_snake_case" target="_blank" rel="noopener"><code>FIELD_LOWER_SNAKE_CASE</code></a></p><p>第3个错误 pet/v1/pet.proto 文件49行PetStore命名不对 必须要以Service结尾。规则 <a href="https://docs.buf.build/lint/rules#service_suffix" target="_blank" rel="noopener"><code>SERVICE_SUFFIX</code></a></p><p>添加except节点 人为的排除掉一些lint规则 如下 把这3个规则都排除了。重新执行buf lint就没有看到任何输出就证明 通过了lint检查。</p><p>还有更暴力的忽略检查<code>ignore</code> 指定Proto文件配置 在一些特殊场景可以使用</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">breaking:</span></span><br><span class="line"><span class="attr">  use:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">FILE</span></span><br><span class="line"><span class="attr">lint:</span></span><br><span class="line"><span class="attr">  use:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">DEFAULT</span></span><br><span class="line"><span class="attr">  ignore:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">google/type/datetime.proto</span></span><br><span class="line"><span class="attr">  except:</span></span><br><span class="line"><span class="comment">#    - PACKAGE_VERSION_SUFFIX</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">FIELD_LOWER_SNAKE_CASE</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">SERVICE_SUFFIX</span></span><br></pre></td></tr></table></figure><p>为了验证修复 先把节点去掉 except 。不排除默认lint规则。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="number">43</span> message DeletePetRequest &#123;</span><br><span class="line"><span class="number">44</span>   <span class="keyword">string</span> pet_id = <span class="number">1</span>; <span class="comment">//petID 改为 pet_id</span></span><br><span class="line"><span class="number">45</span> &#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="number">49</span> service PetStoreService &#123;<span class="comment">//PetStore改为PetStoreService</span></span><br><span class="line"><span class="number">50</span>   rpc GetPet(GetPetRequest) returns (GetPetResponse) &#123;&#125;</span><br></pre></td></tr></table></figure><p> 改了之后 在执行buf lint 就没有错误了。</p><h4 id="breaking-兼容性中断检查"><a href="#breaking-兼容性中断检查" class="headerlink" title="breaking 兼容性中断检查"></a>breaking 兼容性中断检查</h4><p>上面lint主要是检查proto语法相关的规范，但是如果 <code>Pet</code>  中的属性 pet_type 是PetType 类型 已经提供给使用者在用了，这个时候如果改变了数据类型 就兼容不正在使用的客户端，所以用breaking来解决对历史版本的兼容性问题筛查。</p><p>为了演示 把Pet的pet_type类型 从PerType变更为string。</p><figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">message Pet &#123;</span><br><span class="line">  string pet_type = 1;//PetType pet_type = 1;</span><br><span class="line">  string pet_id = 2;</span><br><span class="line">  string name = 3;</span><br><span class="line">  google.type.DateTime created_at = 4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行中段检查命令 需要传入一个against参数 用于本地和主干文件做对比 同样也支持像上面的设置分支和目录</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">  buf breaking --against "https://github.com/DemoHubs/bufbuilddemo.git#branch=main,subdir=start/petapis" --error-format=json</span><br><span class="line"> -----------输出------------</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","type":"SERVICE_NO_DELETE","message":"Previously present service \"PetStore\" was deleted from file."&#125;</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","start_line":20,"start_column":3,"end_line":20,"end_column":9,"type":"FIELD_SAME_TYPE","message":"Field \"1\" on message \"Pet\" changed type from \"enum\" to \"string\"."&#125;</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","start_line":44,"start_column":3,"end_line":44,"end_column":21,"type":"FIELD_SAME_JSON_NAME","message":"Field \"1\" with name \"pet_id\" on message \"DeletePetRequest\" changed option \"json_name\" from \"petID\" to \"petId\"."&#125;</span><br><span class="line">&#123;"path":"pet/v1/pet.proto","start_line":44,"start_column":10,"end_line":44,"end_column":16,"type":"FIELD_SAME_NAME","message":"Field \"1\" on message \"DeletePetRequest\" changed name from \"petID\" to \"pet_id\"."&#125;</span><br></pre></td></tr></table></figure><p>这里主要关注第2个错误\”Pet\” changed type from \”enum\” to \”string\”。就明确提示了 由enum变更为string。其它的错误是因为我们修复了默认的lint的几个规则。</p><h4 id="generate-code-生成代码"><a href="#generate-code-生成代码" class="headerlink" title="generate code 生成代码"></a>generate code 生成代码</h4><p>生成代码也是我们用这个工具的核心功能。回到start目录中 配置生成代码的模板规则文件buf.gen.yaml</p><h5 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ../</span><br><span class="line">vim buf.gen.yaml</span><br><span class="line">-------- 输入模板内容------</span><br><span class="line">version: v1</span><br><span class="line">plugins:</span><br><span class="line">  - plugin: cpp</span><br><span class="line">    out: gen/proto/cpp</span><br><span class="line">  - plugin: java</span><br><span class="line">    out: gen/proto/java</span><br><span class="line">  - plugin: go</span><br><span class="line">    out: gen/proto/go</span><br><span class="line">    opt: paths=source_relative</span><br><span class="line">  - plugin: go-grpc</span><br><span class="line">    out: gen/proto/go</span><br><span class="line">    opt: paths=source_relative</span><br></pre></td></tr></table></figure><p>这里配置了4个插件 分别的cpp java go go-grpc 用于生成c++ java go grpc代码</p><p>c++ 生成的源码放到gen/proto/cpp中</p><p>java 生成的源码放到 gen/proto/java中</p><p>go生成的源码放到 gen/proto/go中</p><p>go-grpc生成的源码放到 gen/proto/go中</p><p>执行生成代码命令 –template参数是指定模板的路径 不指定默认会在当前执行目录查找buf.gen.yaml</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> buf generate perapis --template buf.gen.yaml</span></span><br><span class="line">buf generate petapis</span><br></pre></td></tr></table></figure><p>如果没有报错 当前目录中 gen代码生成成功。使用 tree gen 查看gen目录以下文件树形的方式展开。可以看到c++ java go代码均生成成功</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tree gen</span><br><span class="line">gen</span><br><span class="line">└── proto</span><br><span class="line">    ├── cpp</span><br><span class="line">    │   ├── google</span><br><span class="line">    │   │   └── type</span><br><span class="line">    │   │       ├── datetime.pb.cc</span><br><span class="line">    │   │       └── datetime.pb.h</span><br><span class="line">    │   └── pet</span><br><span class="line">    │       └── v1</span><br><span class="line">    │           ├── pet.pb.cc</span><br><span class="line">    │           └── pet.pb.h</span><br><span class="line">    ├── go</span><br><span class="line">    │   └── pet</span><br><span class="line">    │       └── v1</span><br><span class="line">    │           ├── pet_grpc.pb.go</span><br><span class="line">    │           └── pet.pb.go  </span><br><span class="line">    └── java</span><br><span class="line">        ├── com</span><br><span class="line">        │   └── google</span><br><span class="line">        │       └── type</span><br><span class="line">        │           ├── DateTime.java</span><br><span class="line">        │           ├── DateTimeOrBuilder.java</span><br><span class="line">        │           ├── DateTimeProto.java</span><br><span class="line">        │           ├── TimeZone.java</span><br><span class="line">        │           └── TimeZoneOrBuilder.java</span><br><span class="line">        └── pet</span><br><span class="line">            └── v1</span><br><span class="line">                └── PetOuterClass.java</span><br></pre></td></tr></table></figure><h5 id="使用远程插件生成代码"><a href="#使用远程插件生成代码" class="headerlink" title="使用远程插件生成代码"></a>使用远程插件生成代码</h5><p>上面在生成代码的时候配置了plugin插件，比如go 我需要先安装好，这里可以直接使用远程插件。像这样 在buf.gen.yaml中把plugin的地址写为远程的地址即可。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">plugins:</span></span><br><span class="line"><span class="attr">  - plugin:</span> <span class="string">buf.build/protocolbuffers/go:v1.28.1</span></span><br><span class="line"><span class="attr">    out:</span> <span class="string">gen/proto/go</span></span><br><span class="line"><span class="attr">    opt:</span> <span class="string">paths=source_relative</span></span><br><span class="line"><span class="attr">  - plugin:</span> <span class="string">buf.build/grpc/go:v1.2.0</span></span><br><span class="line"><span class="attr">    out:</span> <span class="string">gen/proto/go</span></span><br><span class="line"><span class="attr">    opt:</span> <span class="string">paths=source_relative</span></span><br></pre></td></tr></table></figure><h5 id="代码托管配置模式"><a href="#代码托管配置模式" class="headerlink" title="代码托管配置模式"></a>代码托管配置模式</h5><p>代码托管配置模式就是对特定语言代码的参数做一个自定义的控制 不需要写死的proto文件中。让buf自己去管理特有的特性。同样是在buf.gen.yaml文件中配置</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">managed:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  cc_enable_arenas:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  java_multiple_files:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>enable 启用配置托管模式</p><p>java_multiple_files  生成的java代码 多文件模式 就是不用内部类的方式了</p><p>关于更多语言的配置 参考 <a href="https://docs.buf.build/generate/managed-mode" target="_blank" rel="noopener">https://docs.buf.build/generate/managed-mode</a></p><h4 id="远程仓库-BSR"><a href="#远程仓库-BSR" class="headerlink" title="远程仓库 BSR"></a>远程仓库 BSR</h4><p>BSR全称 Buf Schema Registry。可以理解为和maven的中央仓库、github这种仓库有点类似。只是bsr是用于buf远程管理仓库。要使用远程仓库功能 需要先注册<a href="https://buf.build/login" target="_blank" rel="noopener">https://buf.build/login</a>  注册之后需要在 设置中添加API TOKEN <a href="https://buf.build/settings/user" target="_blank" rel="noopener">https://buf.build/settings/user</a> 用于buf cli连接到BSR的凭证。</p><h5 id="buf-cli-登录到BSR"><a href="#buf-cli-登录到BSR" class="headerlink" title="buf cli 登录到BSR"></a>buf cli 登录到BSR</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf registry login</span><br></pre></td></tr></table></figure><p>按提示 输入注册的用户名 和 设置的api token。输出 Credentials saved to /root/.netrc. 后 表示登录成功。身份信息存储在/root/.netrc文件中。</p><h5 id="buf-cli-退出登录"><a href="#buf-cli-退出登录" class="headerlink" title="buf cli 退出登录"></a>buf cli 退出登录</h5><p>退出登录后 自动删除了/root/.netrc文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf registry logout</span><br><span class="line">------------ 输出-----------</span><br><span class="line">All existing BSR credentials removed from /root/.netrc.</span><br></pre></td></tr></table></figure><h5 id="推送到远程BSR"><a href="#推送到远程BSR" class="headerlink" title="推送到远程BSR"></a>推送到远程BSR</h5><p>目前 buf cli 好像还不能搭建自己的私有仓库服务。所以默认的仓库服务由buf提供。统一域名为buf.build。</p><p>仓库地址组成由 buf.build/$buf_username/$rep_name</p><p>buf_username 为上面注册buf的用户名</p><p>rep_name 为仓库的名称。</p><p>把演示的proto项目推送到BSR 这里 我的用户名为peachyy  仓库名为 bufbuilddemo –visibility 表示仓库的权限为公开。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> buf beta registry repository create buf.build/peachyy/bufbuilddemo --visibility public</span><br><span class="line"> ------------- 输出-----------</span><br><span class="line"> WARN    This command is in beta. It is unstable and likely to change. To suppress this warning, set BUF_BETA_SUPPRESS_WARNINGS=1</span><br><span class="line">Full name                       Created</span><br><span class="line">buf.build/peachyy/bufbuilddemo  2022-12-19T10:12:01Z</span><br></pre></td></tr></table></figure><p>仓库创建成功了，访问buf.build/peachyy/bufbuilddemo 能看到仓库文件信息。当前还是个空仓库。</p><p><strong>准备推送proto文件到远程</strong></p><p>进入 petapis 目录 为buf.yaml 新增name属性  值为上面创建的远程仓库全路径</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">buf.build/peachyy/bufbuilddemo</span></span><br><span class="line"><span class="attr">breaking:</span></span><br><span class="line"><span class="attr">  use:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">FILE</span></span><br><span class="line"><span class="string">.....</span></span><br></pre></td></tr></table></figure><p> 执行推送到主干 输出的字符串则为版本号。现在刷新在网页上刷新仓库能看到proto文件了。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf push</span><br><span class="line">-----------输出--------</span><br><span class="line">63458f6007e64ac0936d88c9caeae212</span><br></pre></td></tr></table></figure><p>如果你推送不想影响到主干 可能你的proto文件还有变更 不是很完善的时候  可以先提交草稿。同样的也会返回一个版本号</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf push --draft draft001</span><br><span class="line">---------------- 输出---------------</span><br><span class="line">8745a3039aa7403c8f1420a68a4b5f3e</span><br></pre></td></tr></table></figure><p>BSR还有像github中readme文件一样 用来描述这个Proto项目。它叫 <code>buf.md</code></p><h4 id="依赖管理"><a href="#依赖管理" class="headerlink" title="依赖管理"></a>依赖管理</h4><p> 可以看到  pet/v1/pet.proto  文件依赖了一个DateTime类型, DateTime类型的源文件位于 google/type/datetime.proto 。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="number">19</span> message Pet &#123;</span><br><span class="line"><span class="number">20</span>   <span class="keyword">string</span> pet_type = <span class="number">1</span>;<span class="comment">//PetType pet_type = 1;</span></span><br><span class="line"><span class="number">21</span>   <span class="keyword">string</span> pet_id = <span class="number">2</span>;</span><br><span class="line"><span class="number">22</span>   <span class="keyword">string</span> name = <span class="number">3</span>;</span><br><span class="line"><span class="number">23</span>   google.<span class="keyword">type</span>.DateTime created_at = <span class="number">4</span>; <span class="comment">//这里依赖了 google/type/datetime.proto 源文件。DateTime类型</span></span><br><span class="line"><span class="number">24</span> &#125;</span><br></pre></td></tr></table></figure><p>尝试把datetime.proto文件删除后 执行buf build。可以看到报错了 因为 datetime.proto不存在</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf build</span><br><span class="line">------------输出--------------</span><br><span class="line">pet/v1/pet.proto:5:8:google/type/datetime.proto: does not exist</span><br></pre></td></tr></table></figure><h5 id="添加远程依赖到本地"><a href="#添加远程依赖到本地" class="headerlink" title="添加远程依赖到本地"></a>添加远程依赖到本地</h5><p>新增依赖配置 deps 值是一个仓库列表</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">buf.build/peachyy/bufbuilddemo</span></span><br><span class="line"><span class="attr">deps:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">buf.build/googleapis/googleapis</span> <span class="comment">#指定了远程依赖仓库地址 这个是官方提供的示例代码 直接拿来引用一下</span></span><br><span class="line"><span class="attr">breaking:</span></span><br><span class="line"><span class="attr">  use:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">FILE</span></span><br><span class="line"><span class="attr">lint:</span></span><br><span class="line"><span class="attr">  use:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">DEFAULT</span></span><br><span class="line"><span class="attr">  except:</span></span><br><span class="line">          <span class="comment"># - PACKAGE_VERSION_SUFFIX</span></span><br><span class="line">          <span class="comment">#    - FIELD_LOWER_SNAKE_CASE</span></span><br><span class="line">          <span class="comment">#    - SERVICE_SUFFIX</span></span><br><span class="line"><span class="attr">  ignore:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">google/type/datetime.proto</span></span><br></pre></td></tr></table></figure><p>再次执行buf build。同样是错误输出 但是多了一个警告 意思是你deps依赖库不在buf.lock中。运行 <code>buf mod update</code> 生成buf.lock文件 这个文件保存了deps依赖信息。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf build </span><br><span class="line">-------------输出----------</span><br><span class="line">WARN    Specified deps are not covered in your buf.lock, run "buf mod update":</span><br><span class="line">        - buf.build/googleapis/googleapis</span><br><span class="line">pet/v1/pet.proto:5:8:google/type/datetime.proto: does not exist</span><br></pre></td></tr></table></figure><p>执行buf mod update 执行后生成的buf.lock文件记录了依赖的 远程服务地址、用户名、仓库名称、提交版本号。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf mod update </span><br><span class="line">----------buf.lock文件内容--------</span><br><span class="line">version: v1</span><br><span class="line">deps:</span><br><span class="line">  - remote: buf.build</span><br><span class="line">    owner: googleapis</span><br><span class="line">    repository: googleapis</span><br><span class="line">    commit: 75b4300737fb4efca0831636be94e517</span><br></pre></td></tr></table></figure><p>如果想指定依赖具体的版本号的仓库可以指定提交id 格式 <em>仓库地址:提交版本ID</em></p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deps:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">buf.build/peachyy/bufbuilddemo:63458f6007e64ac0936d88c9caeae212</span></span><br></pre></td></tr></table></figure><p>再次执行bud build 就不报错了。说明成功引用到了远程仓库，以后不需要copy到本地后再生成代码。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf build</span><br></pre></td></tr></table></figure><p>buf的编译构建的时候 会生成缓存在$HOME/.cache目录中。</p><h4 id="工作空间"><a href="#工作空间" class="headerlink" title="工作空间"></a>工作空间</h4><h5 id="buf-work-yaml使用"><a href="#buf-work-yaml使用" class="headerlink" title="buf.work.yaml使用"></a>buf.work.yaml使用</h5><p>新创建一个支付api模块定义 用于购买宠物的时候支付使用。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p paymentapis/payment/v1alpha1</span><br><span class="line">vim paymentapis/payment/v1alpha1/payment.proto</span><br></pre></td></tr></table></figure><p>paymentapis/payment/v1alpha1/payment.proto  定义了一个枚举PaymentProvider 和 order结构对象。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">package</span> payment.v1alpha1;</span><br><span class="line"></span><br><span class="line">option go_package = <span class="string">"github.com/bufbuild/buf-tour/petstore/gen/proto/go/payment/v1alpha1;paymentv1alpha1"</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//import "google/type/money.proto";</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// PaymentProvider represents the supported set</span></span><br><span class="line"><span class="comment">// of payment providers.</span></span><br><span class="line">enum PaymentProvider &#123;</span><br><span class="line">  PAYMENT_PROVIDER_UNSPECIFIED = <span class="number">0</span>;</span><br><span class="line">  PAYMENT_PROVIDER_STRIPE = <span class="number">1</span>;</span><br><span class="line">  PAYMENT_PROVIDER_PAYPAL = <span class="number">2</span>;</span><br><span class="line">  PAYMENT_PROVIDER_APPLE = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Order represents a monetary order.</span></span><br><span class="line">message Order &#123;</span><br><span class="line">  <span class="keyword">string</span> order_id = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">string</span> recipient_id = <span class="number">2</span>;</span><br><span class="line">  <span class="comment">//google.type.Money amount = 3;</span></span><br><span class="line">  PaymentProvider payment_provider = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>回到petapis模块 ，修改文件petapis/pet/v1/pet.proto ，新增一个支付rpc PurchasePet方法。支付请求参数引用了paymentapis模块的实体。</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">"payment/v1alpha1/payment.proto"</span>;</span><br><span class="line">.....</span><br><span class="line">.....</span><br><span class="line">service PetStoreService &#123;</span><br><span class="line">  rpc GetPet(GetPetRequest) returns (GetPetResponse) &#123;&#125;</span><br><span class="line">  rpc PutPet(PutPetRequest) returns (PutPetResponse) &#123;&#125;</span><br><span class="line">  rpc DeletePet(DeletePetRequest) returns (DeletePetResponse) &#123;&#125;</span><br><span class="line">  rpc PurchasePet(PurchasePetRequest) returns (PurchasePetResponse) &#123;&#125; <span class="comment">//新增支付方法</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message PurchasePetRequest &#123; <span class="comment">//支付请求参数</span></span><br><span class="line"> <span class="keyword">string</span> pet_id = <span class="number">1</span>;</span><br><span class="line"> payment.v1alpha1.Order order = <span class="number">2</span>; <span class="comment">//该实体在paymentapis模块定义</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message PurchasePetResponse &#123;<span class="comment">//支付响应值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>工作空间配置文件是在buf.work.yaml中进行配置， 用directories属性列表来引入目录。这里指定了petapis paymentapis。在刚刚修改的代码中 依赖关系是petapis 依赖了paymentapis。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">vim</span> <span class="string">buf.work.yaml</span></span><br><span class="line"><span class="bullet">-</span><span class="bullet">------buf.work.yaml内容----------</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">directories:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">paymentapis</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">petapis</span></span><br></pre></td></tr></table></figure><p>执行buf build ,并没有报错 这种工作空间的方式让petapis 成员引用到了paymentapis模块。 如果把buf.work.yaml中 - paymentapis注释后 执行buf build就提示找不到<em>petapis/pet/v1/pet.proto:6:8:payment/v1alpha1/payment.proto: does not exist</em> 错误</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">buf build</span><br></pre></td></tr></table></figure><p>同样的道理工作空间的方式，其他buf操作命令也是如此，包括buf {breaking,build,generate,ls-files}</p><h5 id="工作空间关于Push远程的问题"><a href="#工作空间关于Push远程的问题" class="headerlink" title="工作空间关于Push远程的问题"></a>工作空间关于Push远程的问题</h5><p>尝试操作推送 可是报错了。 </p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd petapis &amp;&amp; buf push</span><br><span class="line">-----------输出-----------</span><br><span class="line">Failure: pet/v1/pet.proto:6:8:payment/v1alpha1/payment.proto: does not exist</span><br></pre></td></tr></table></figure><p>解决这个问题需要先把paymentapis模块推送到远程后 在petapis 模块中使用deps的方法加入paymentapis地址才能push。</p><p>但是buf build命令却没有问题 因为工作区就在你本地能找到，推送远程的时候 paymentapis 模块远程找不到 所以才有这个问题。</p><p>参考 <a href="https://docs.buf.build/introduction" target="_blank" rel="noopener">https://docs.buf.build/introduction</a></p><p>示例仓库</p><p><a href="https://buf.build/peachyy/bufbuilddemo" target="_blank" rel="noopener">https://buf.build/peachyy/bufbuilddemo</a></p><p><a href="https://buf.build/peachyy/bufbuilddemo-paymentapis" target="_blank" rel="noopener">https://buf.build/peachyy/bufbuilddemo-paymentapis</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;proto是在当今使用最广泛的IDL之一，起因是dubbo3的&lt;strong&gt;Triple&lt;/strong&gt; 协议需要用到proto文件来生成统一规范的跨语言代码，Grpc也有类似的问题，想想一个团队有很多的业务模块，涉及到一些相互调用依赖的问题，如 A模块需要用到B模块的
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="proto" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/proto/"/>
    
      <category term="buf" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/proto/buf/"/>
    
    
      <category term="dubbo" scheme="https://peachyy.gitee.io/tags/dubbo/"/>
    
      <category term="proto" scheme="https://peachyy.gitee.io/tags/proto/"/>
    
      <category term="buf" scheme="https://peachyy.gitee.io/tags/buf/"/>
    
  </entry>
  
  <entry>
    <title>dubbo2升级到dubbo3实践</title>
    <link href="https://peachyy.gitee.io/2022/12/09/dubbo2upgradedubbo3/"/>
    <id>https://peachyy.gitee.io/2022/12/09/dubbo2upgradedubbo3/</id>
    <published>2022-12-08T16:00:00.000Z</published>
    <updated>2022-12-12T09:38:43.211Z</updated>
    
    <content type="html"><![CDATA[<p>dubbo当前版本 2.7.3  期望升级到 3.0.11。</p><h4 id="升级过程"><a href="#升级过程" class="headerlink" title="升级过程"></a>升级过程</h4><h5 id="maven依赖变更"><a href="#maven依赖变更" class="headerlink" title="maven依赖变更"></a>maven依赖变更</h5><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.dubbo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dubbo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.11<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.dubbo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>dubbo-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.11<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="dubbo2-升级到dubbo3兼容性配置"><a href="#dubbo2-升级到dubbo3兼容性配置" class="headerlink" title="dubbo2 升级到dubbo3兼容性配置"></a>dubbo2 升级到dubbo3兼容性配置</h5><p><strong>服务端</strong> </p><p>dubbo.application.register-mode 服务端提供者服务的注册模式 可选值有</p><ul><li>instance 只注册实例应用级</li><li>all  接口级+应用级均注册</li><li>interface 只注册接口级</li></ul><p>升级到3.x之后在不修改配置的情况下默认是 <code>all</code>配置   开启接口级+应用级注册</p><p><strong>消费端/客户端</strong></p><p>服务有注册模式 那么消费端肯定也有服务订阅发现模式设置</p><p>dubbo.application.service-discovery.migration  消费端订阅模式可选值有</p><ul><li>APPLICATION_FIRST   双订阅 即接口模式/应用级模式 智能决策 一般用于2.7.x与3.x 升级中 共存阶段  也是3.x版本默认的订阅模式</li><li>FORCE_APPLICATION  仅应用级订阅模式</li><li>FORCE_INTERFACE 仅接口级订阅模式</li></ul><p>关于兼容这一步如果项目升级的时候没有用户使用 不做兼容性升级也没问题，这里主要是介绍保障逐步把2.7.x版本升级到3.x 而不是全部停机后重新部署。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-12-09/1.png" alt="兼容升级中服务注册与发现" title="">                </div>                <div class="image-caption">兼容升级中服务注册与发现</div>            </figure><p>红色虚线框部分是3.x版本的部分升级后实例，左边是原始的2.7.x版本实例。大概操作流程如下</p><p>1、逐步把部分Provider替换为3.x  服务端注册模式为<code>all</code>应用级+接口级，这样2.7.x的消费端也能够根据接口服务发现</p><p>2、逐步把部分Consumer替换为3.x 消费订阅模式为<code>APPLICATION_FIRST</code>双订阅模式</p><p>3、观察3.x版本 服务端与消费端情况，如果异常就回滚到2.7.x。没啥问题的话就可以逐步全部切换到3.x版本</p><p>4、到了这一步说明当前所有实例均为3.x版本，下次再更新的时候就把服务端注册模式设置为<code>instance</code> ，消费端订阅模式设置为 <code>FORCE_APPLICATION</code> 就完美切换到3.x版本 并且是应用级服务发现。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-12-09/2.png" alt="升级3.x完成" title="">                </div>                <div class="image-caption">升级3.x完成</div>            </figure><h4 id="踩坑问题"><a href="#踩坑问题" class="headerlink" title="踩坑问题"></a>踩坑问题</h4><p>3.0.11其实也没有太多问题 好多问题都在之前版本就修复了，主要就是由于自身项目编码问题导致进了一个坑</p><p>由于原来项目编码不是很规范，在本地服务的接口中用到<code>@Autowired</code>、本服务内部调用有的又用到了 <code>@DubboReference</code> 这种情况启动的时候就会报错，在2.7.x却不报错。这是因为3.x把Reference的bean代理也注入到spring容器中去了。本身的@DubboService Bean也会注册到Spring容器中去。就会导致出现2个类型一样的springBean，导致使用Autowired，由于属性name不规范的时候就会报错。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Field demoService in org.apache.dubbo.springboot.demo.provider.DemoService2 required a single bean, but <span class="number">2</span> were found:</span><br><span class="line">- demoServiceImpl: defined in file [D:\opensource\dubbo-samples\<span class="number">1</span>-basic\dubbo-samples-spring-boot\dubbo-samples-spring-boot-provider\target\classes\org\apache\dubbo\springboot\demo\provider\DemoServiceImpl.class]</span><br><span class="line">- demoServiceRemote: defined in <span class="keyword">null</span></span><br></pre></td></tr></table></figure><h4 id="3-x主要新特性"><a href="#3-x主要新特性" class="headerlink" title="3.x主要新特性"></a>3.x主要新特性</h4><ol><li>服务注册与发现改版 由接口级别改为应用级</li><li>云原生更好的支持 如native image，dubbo proxyless Mesh，</li><li>可视化的dubbo-admin服务治理能力</li><li>全新通信协议<strong>Triple</strong> 让跨语言RPC迈了一大步，支持点对点调用、stream 流式调用。写proto IDL 文件可生成各类客户端代码，完全兼容<code>grpc</code> 让java<code>与</code>go`成为后端深度合作伙伴</li></ol><h4 id="3-x小版本更新"><a href="#3-x小版本更新" class="headerlink" title="3.x小版本更新"></a>3.x小版本更新</h4><p>  <strong>3.0.x升级到3.1.x</strong></p><p>  变动不大就只是针对nacos的group进行了对齐。如果配置中填写的nacos的地址带了group参数的话 ，需要客户端和服务端保持一致的group。</p><p>  当然也可以强制去掉group分组隔离功能  <code>dubbo.nacos-service-discovery.use-default-group=false</code> 全局属性值忽略该功能</p><p> <strong>3.1.x升级到3.2.x</strong></p><p> 最大的变更是默认序列化的变了，dubbo协议默认序列化由hessian2变更为 fastjson2，原因就是fastjson2性能更高也能兼容<code>hessian2</code> 也支持jdk17 和Native 。</p><p> triple协议支持自定义异常回传。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;dubbo当前版本 2.7.3  期望升级到 3.0.11。&lt;/p&gt;
&lt;h4 id=&quot;升级过程&quot;&gt;&lt;a href=&quot;#升级过程&quot; class=&quot;headerlink&quot; title=&quot;升级过程&quot;&gt;&lt;/a&gt;升级过程&lt;/h4&gt;&lt;h5 id=&quot;maven依赖变更&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="dubbo" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/dubbo/"/>
    
    
      <category term="java" scheme="https://peachyy.gitee.io/tags/java/"/>
    
      <category term="dubbo" scheme="https://peachyy.gitee.io/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>java中GC的日志认识详解</title>
    <link href="https://peachyy.gitee.io/2022/10/27/jvm_gc_log/"/>
    <id>https://peachyy.gitee.io/2022/10/27/jvm_gc_log/</id>
    <published>2022-10-26T16:00:00.000Z</published>
    <updated>2022-10-27T03:17:48.067Z</updated>
    
    <content type="html"><![CDATA[<p>不同的垃圾回收器 他们的日志都是完成不一样的，看懂日志是解决和发现问题的重中之重。</p><h5 id="Parallel-Scavenge-Parallel-Old-日志"><a href="#Parallel-Scavenge-Parallel-Old-日志" class="headerlink" title="Parallel Scavenge + Parallel Old 日志"></a>Parallel Scavenge + Parallel Old 日志</h5><p>启动参数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:+UseParallelGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:gc.log</span><br></pre></td></tr></table></figure><p>ygc日志</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-27/1.png" alt="1" title="">                </div>                <div class="image-caption">1</div>            </figure><p>fullgc日志 如下图 主要是 gc日志上多了回收老年代、元空间、GC类型变为Full GC</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-27/2.png" alt="2" title="">                </div>                <div class="image-caption">2</div>            </figure><p>年轻代的total=eden+1个s区 如图中 10752+1536=12288k</p><p>GC触发原因常见的有</p><ul><li>Allocation Failure  年轻代中没有足够区域能够存放需要分配的数据而失败</li><li>Ergonomics 常见于FullGc中  是因为 UseAdaptiveSizePolicy 开启了自适应调整策略而发生的GC 很正常的</li><li>Metadata GC Threshold 常见于Full Gc 元空间不足</li></ul><h5 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h5><p>G1有几种类型的gc，YGC (仅回收年轻代)  ，Miexd GC(年轻代和部分老年代都回收 也叫混合GC)，Full GC (整堆回收 g1中一般很少出现fullgc)，  启动参数如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:+UseG1GC -XX:InitiatingHeapOccupancyPercent=40 -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:gc.log</span><br></pre></td></tr></table></figure><p>MiexdGc 回收流程参考 <a href="/2022/10/19/javagcalg_gccoll/#G1%E6%94%B6%E9%9B%86%E5%99%A8">回收流程</a></p><h6 id="YGC-日志格式"><a href="#YGC-日志格式" class="headerlink" title="YGC 日志格式"></a>YGC 日志格式</h6><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-27/3.png" alt="3" title="">                </div>                <div class="image-caption">3</div>            </figure><h6 id="Miexd-GC日志格式"><a href="#Miexd-GC日志格式" class="headerlink" title="Miexd GC日志格式"></a>Miexd GC日志格式</h6><p>miexd gc日志就能完全体现出G1回收流程的几个阶段 初始标记-并发标记-最终标记-筛选回收</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-27/4.png" alt="4" title="">                </div>                <div class="image-caption">4</div>            </figure><h6 id="Full-gc日志格式"><a href="#Full-gc日志格式" class="headerlink" title="Full gc日志格式"></a>Full gc日志格式</h6><p>Full Gc日志看起来很轻松 在G1中应该避免不要产生FullGC </p><p><img src="/images/2022-10-27/5.png" alt="5"></p><h5 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h5><p>cms是老年代回收器 日志格式也是分阶段打印的  具体流程可以参考 <a href="/2022/10/19/javagcalg_gccoll/#CMS收集器">cms回收阶段流程</a> 启动参数如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-Xms50m  -Xmx50m -XX:+UseConcMarkSweepGC  -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:gc.log</span><br></pre></td></tr></table></figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-27/6.png" alt="6" title="">                </div>                <div class="image-caption">6</div>            </figure><p>老版的垃圾回收器如 parNew 串行不再去花太多时间研究了 一般也用不上 有更好的选择。</p><p>在线日志分析工具  <a href="https://gceasy.io/gc-index.jsp" target="_blank" rel="noopener">https://gceasy.io/gc-index.jsp</a>  </p><p>没怎么用过 <a href="https://sourceforge.net/projects/gcviewer/" target="_blank" rel="noopener">https://sourceforge.net/projects/gcviewer/</a></p><p>参考 <a href="https://zhuanlan.zhihu.com/p/267388951" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/267388951</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;不同的垃圾回收器 他们的日志都是完成不一样的，看懂日志是解决和发现问题的重中之重。&lt;/p&gt;
&lt;h5 id=&quot;Parallel-Scavenge-Parallel-Old-日志&quot;&gt;&lt;a href=&quot;#Parallel-Scavenge-Parallel-Old-日志&quot; cla
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="JVM" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/JVM/"/>
    
    
      <category term="java" scheme="https://peachyy.gitee.io/tags/java/"/>
    
      <category term="jvm" scheme="https://peachyy.gitee.io/tags/jvm/"/>
    
      <category term="gc" scheme="https://peachyy.gitee.io/tags/gc/"/>
    
  </entry>
  
  <entry>
    <title>java中GC的常用参数设置</title>
    <link href="https://peachyy.gitee.io/2022/10/26/jvm_gc_args/"/>
    <id>https://peachyy.gitee.io/2022/10/26/jvm_gc_args/</id>
    <published>2022-10-25T16:00:00.000Z</published>
    <updated>2022-10-27T02:28:11.279Z</updated>
    
    <content type="html"><![CDATA[<p>jvm有很多参数可供用户配置 记肯定是不现实，而且不同的版本还有些不一样 只需记住几个比较重要的参数就行</p><p><code>HotSport</code>参数格式分类</p><ul><li>标准 <code>-</code>号开头  如 java -version</li><li>非标准  <code>-X</code> 开头 特定的版本支持 实验性参数 如 java  -Xms</li><li>不稳定 <code>-XX</code>开头 后续版本可能不被支持 如 java  -XX:+UseSerialGC</li></ul><p>-XX:+PrintFlagsInitial 打印所有的默认参数设置</p><p>-XX:+PrintFlagsFinal  打印最终值，如果某个默认值被新值覆盖，显示新值 如果是覆盖的值赋值运算符号为<code>:=</code></p><figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">java -XX:+PrintFlagsInitial <span class="string">|grep G1</span></span><br></pre></td></tr></table></figure><p>-XX:+PrintCommandLineFlags 打印那些被新值覆盖的项 </p><p>不区分垃圾回收器常用的共用参数</p><p>-Xms128m JVM初始分配堆内存</p><p>-Xmx512m JVM最大允许分配的堆内存，按需分配</p><h5 id="Serial"><a href="#Serial" class="headerlink" title="Serial"></a>Serial</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:+UseSerialGC</span><br></pre></td></tr></table></figure><p>表示年轻代使用 serialGC 老年代使用 serial old 组合</p><h5 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h5><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-XX:+UseParNewGC</span><br></pre></td></tr></table></figure><p>新生代使用 ParNew GC 老年代默认还是Serial Old GC ，如果要使用cms 作为老年代回收器 -XX:+UseConcMarkSweepGC</p><h5 id="Parallel-Scavenge"><a href="#Parallel-Scavenge" class="headerlink" title="Parallel Scavenge"></a>Parallel Scavenge</h5><p>ps与parNew的功能区别上 ps支持吞吐量优先策略。 </p><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:UseParallelGC</span></span><br></pre></td></tr></table></figure><p>使用 Parallel Scavenge GC + Parallel Old GC 组合策略 是jdk8中的默认组合，单独使用 -XX:UseParallelOldGC 参数 新生代默认也会使用Parallel Scavenge，它两差不多</p><p>-XX:ParallelGCThreads   设置年轻代 Parallel Scavenge GC 线程数</p><p>-XX:MaxGCPauseMillis   设置垃圾回收器最大停顿时间（即 STW 的时间），单位是毫秒</p><p>-XX:+UseAdaptiveSizePolicy 设置Parallel Scavenge GC 具有自适应调节策略。在这种模式下，年轻代的大小、Eden 和 Survivor 的比例、晋升老年代的对象年龄等参数会被自动调整，已达到在堆大小、吞吐量和停顿时间之间的平衡点。</p><h5 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h5><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseConcMarkSweepGC</span></span><br></pre></td></tr></table></figure><p>启用cms垃圾回收 此参数默认组合为 parNew + cms+ serial old 老年版的串行回收是因为cms在回收的时候用户线程内存不足会启用serial old来回收</p><p>-XX:CMSInitiatingOccupanyFraction 内存使用率阈值，一旦超过该阈值，便开始回收</p><p>-XX:+UseCMSCompactAtFullCollection 指定在执行完 Full GC 后对内存进行压缩整理，以避免内存碎片的产生</p><p>-XX:CMSFullGCBeforeCompaction 设置在执行多少次 Full GC 后对内存空间进行压缩整理</p><p>-XX:ParallelCMSThread 设置CMS 线程数，默认 (ParallelGCThreads + 3) / 4</p><h5 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h5><p>G1不分代了 参数就简单很多 一般情况下一个启用参数就够用了，用G1回收一般不建议去指定年轻代的大小 让它自己调整更好。</p><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">-XX</span><span class="selector-pseudo">:+UseG1GC</span></span><br></pre></td></tr></table></figure><p>-XX:InitiatingHeapOccupancyPercent 触发GC周期的Java 堆占用率阈值，超过此值，触发 GC。默认 45</p><p>-XX:G1HeapReagionSize 设置region的大小 必须是2的次幂</p><p>-XX:MaxGCPauseMillis  期望达到的最大GC 停顿时间 默认是200ms Parallel Scavenge GC中也有类似的参数 JVM会根据这个参数来优先回收有价值的region。</p><p>-XX:ParalledGCThread 设置 STW 工作线程数，最大为 8</p><p>-XX:ConcGCThreads 设置并发标记线程数，一般设置为 ParalledGCThread 的 1/4 左右</p><p>另外就是生产环境一般会设置GC日志和堆信息相关的参数  就是怕万一内存溢出等异常情况能拿到异常时的堆内存以及GC日志来分析问题。</p><p>-XX:+PrintGCDetails  打印GC详情</p><p>-XX:+PrintGCDateStamps 打印GC时间戳</p><p>-XX:+PrintHeapAtGC  打印GC日志的时候输出堆信息</p><p>-Xloggc:logs/gc.log  生成GC日志文件</p><p>-XX:+UseGCLogFileRotation           开启滚动生成日志</p><p>-XX:NumberOfGCLogFiles=5     滚动GC日志文件数，默认0，不滚动</p><p>-XX:GCLogFileSize=20M        GC文件滚动大小，需开启UseGCLogFileRotation</p><p>-XX:+HeapDumpOnOutOfMemoryError 发生内存错误的时候导出堆信息</p><p>-XX:HeapDumpPath=logs/1.dump 发生内存错误的时候导出堆信息的路径 一般和HeapDumpOnOutOfMemoryError 配合使用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;jvm有很多参数可供用户配置 记肯定是不现实，而且不同的版本还有些不一样 只需记住几个比较重要的参数就行&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HotSport&lt;/code&gt;参数格式分类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标准 &lt;code&gt;-&lt;/code&gt;号开头  如 java -versio
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="JVM" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/JVM/"/>
    
    
      <category term="java" scheme="https://peachyy.gitee.io/tags/java/"/>
    
      <category term="jvm" scheme="https://peachyy.gitee.io/tags/jvm/"/>
    
      <category term="gc" scheme="https://peachyy.gitee.io/tags/gc/"/>
    
  </entry>
  
  <entry>
    <title>java中的垃圾回收算法与垃圾回收器</title>
    <link href="https://peachyy.gitee.io/2022/10/19/javagcalg_gccoll/"/>
    <id>https://peachyy.gitee.io/2022/10/19/javagcalg_gccoll/</id>
    <published>2022-10-18T16:00:00.000Z</published>
    <updated>2022-10-26T01:19:21.348Z</updated>
    
    <content type="html"><![CDATA[<h4 id="常用的垃圾回收算法"><a href="#常用的垃圾回收算法" class="headerlink" title="常用的垃圾回收算法"></a>常用的垃圾回收算法</h4><h5 id="标记-清除"><a href="#标记-清除" class="headerlink" title="标记-清除"></a>标记-清除</h5><p>   标记清除算法是一种非移动式的回收算法，分为<code>标记</code> <code>清除</code> 2个阶段，简而言之就是先标记出需要回收的对象，标记完成后再回收掉所有标记的内存对象，如下图</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/1.png" alt="1" title="">                </div>                <div class="image-caption">1</div>            </figure><p> 可见回收后图中被标记的对象被删除回收了，但是碎片化比较严重不连续 对于下次分配大对象的时候由于内存不连续性影响比较大，而且每一次Gc的时候需要执行2个操作 1次标记 1次回收 </p><h5 id="标记-整理压缩"><a href="#标记-整理压缩" class="headerlink" title="标记-整理压缩"></a>标记-整理压缩</h5><p>标记整理压缩算法是一种移动式的算法，由于上面标记清除算法导致内存不连续的问题 标记-整理算法就解决了这个问题。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/2.png" alt="2" title="">                </div>                <div class="image-caption">2</div>            </figure><p>工作原理也是2阶段操作而且更复杂了，首先找出(root)根地址的对象一直寻找标记是否被引用，引用了就标记一下，标记完成后把标记的对象按顺序移动排列在一起并清除掉边界的未标记的对象，这样就没有内存碎片。</p><p>缺点 </p><ul><li>由于标记完成后需要移动对象 移动的过程可能会产生STW</li><li>2次+调整指针</li></ul><h5 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h5><p> 复制算法更粗暴了，逻辑也很简单 通常直接申明了2块一样大小存储空间，每次只使用其中1块空间，当使用的这块空间不够用的时候就触发回收操作，将存活的对象copy到另一块空间中按顺序存放，可回收的就回收删除掉，这样一来就不会出现内存碎片，但是要多浪费50%的内存空间，主要用于年轻代 比如s0 s1亦是如此。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/3.png" alt="3" title="">                </div>                <div class="image-caption">3</div>            </figure><h5 id=""><a href="#" class="headerlink" title=" "></a> </h5><h5 id="分代回收算法"><a href="#分代回收算法" class="headerlink" title="分代回收算法"></a>分代回收算法</h5><p> 根据对象的存活周期划分为新生代、老年代。因此可以根据不同年代的特点使用不同的回收算法。分代收集目前是大部分JVM</p><ul><li><p>新生代特点</p><p>在新生代中大量的对象产生 又有大量的对象需要销毁，他们存活时间都比较短。基本上都是回收的时候大部分会被回收掉，只有少量的对象是存活不回收的。</p><p>存活对象少，垃圾对象多这就比较适合使用复制算法，复制算法需要用到2块内存空间 每次只使用其中一块，在jdk8中不只是单纯的划分为<code>s0</code> <code>s1</code> 二块存储空间，还新增了一块<code>Eden</code> ,s0 s1的默认大小是eden的8/1 这样设计的目的在于每次触发回收的时候把90(eden+其中1个s区)的区域中存活的对象copy到10%的存储中，理论上清除了90%的空间，这样做的好处就是不需要花50%的存储空间，只浪费了10%的空间就实现了这个算法逻辑。</p></li><li><p>老年代特点</p><p> 老年代的特点就是对象存活时间都比较长，大量的存活对象就不适合像新生代一样用复制算法了 因为copy的成本太高，这种就比较适合标记清除算法，或者标记清除整理算法。</p></li></ul><p>  优缺点概述</p><table><thead><tr><th>算法名称</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>标记-清除</td><td>简单</td><td>位置不联系 碎片化严重 效率低 2次扫描</td></tr><tr><td>标记-压缩整理</td><td>没有碎片</td><td>效率低 2次扫描 可能会多次重置指针</td></tr><tr><td>复制算法</td><td>没有碎片 简单高效</td><td>浪费空间</td></tr></tbody></table><h4 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h4><p>  上面的垃圾算法仅仅只是一个理论上的算法 ，正在实现这些算法的叫垃圾回收器，在工作中具体是怎么回收工作的可以不关心，但是需要了解不同的垃圾回收器是基于哪种算法实现的，有助于出现性能问题的时候有思路去参数调优，而不是盲目的问度娘。各个年轻代 老年代垃圾回收器可组合配对方式如下图所示</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/8.png" alt="8" title="">                </div>                <div class="image-caption">8</div>            </figure><h5 id="serial串行收集器"><a href="#serial串行收集器" class="headerlink" title="serial串行收集器"></a>serial串行收集器</h5><p>serial回收器是一个串行单线程回收器，在进行垃圾回收的时候必须暂停用户工作线程，直到回收线程处理完成，每次回收必然会STW。比较适合跑在client端应用</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/4.png" alt="4" title="">                </div>                <div class="image-caption">4</div>            </figure><h5 id="ParNew收集器"><a href="#ParNew收集器" class="headerlink" title="ParNew收集器"></a>ParNew收集器</h5><p>ParNew回收器是<code>新生代</code>垃圾回收器, 就是serial的多线程版本 其它基本上serial差不多的，在ps回收器没有出来之前parNew+cms是服务器端首选</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/5.png" alt="5" title="">                </div>                <div class="image-caption">5</div>            </figure><h5 id="Parallel-Scavenge收集器"><a href="#Parallel-Scavenge收集器" class="headerlink" title="Parallel Scavenge收集器"></a>Parallel Scavenge收集器</h5><p>常说的<code>ps</code> 收集器就算它，ps是一个新生代收集器采用复制算法，多线程并行收集。是jdk8的默认新生代回收器。</p><p>看起来和parNew有点一样 反正性能就是比它要强，在应用吞吐量方面更优秀。ps一般是和Parallel Old配合使用</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/6.png" alt="6" title="">                </div>                <div class="image-caption">6</div>            </figure><h5 id="Serial-Old收集器"><a href="#Serial-Old收集器" class="headerlink" title="Serial Old收集器"></a>Serial Old收集器</h5><p>Serial Old收集器是Serial的老年代版本，同样它也是单线程收集，基于标记-整理算法，工作原理可以参考serial。</p><h5 id="Parallel-Old收集器"><a href="#Parallel-Old收集器" class="headerlink" title="Parallel Old收集器"></a>Parallel Old收集器</h5><p>parallel old收集器是ps的老年代版本 是多线程收集器 基于标记-整理算法 弥补了serial old单线程的不足，工作原理参考ps收集器工作流程图。ps+po是jdk8默认的组合 也是我在项目中实践最多的组合。</p><h5 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h5><p>cms从jdk1.4开始引入,算是里程碑GC产品,开启了Java领域并发<em>(注意并发与并行parallel的区别 并发是指回收垃圾的时候和用户线程一起干活，并行是指多个GC线程同时回收 )</em>回收的方案。是一个优秀的老年代垃圾回收器。</p><p>cms从名字就能看出来是基于并发的 <code>标记-清除算法</code>实现的回收器，它的回收流程分为 <code>初始标记</code>-<code>并发标记</code>-<code>重新标记</code>-<code>并发清除</code> 4个阶段。</p><ol><li>初始标记 (initial mark)<br>只是标记GC Roots 根对象 会stw 但是由于只是标记了gc roots 所以会很快</li><li>并发标记<br>根据第1阶段的结果继续往下标记 这个阶段是并发的 不影响用户线程</li><li>重新标记<br>为什么会有重新标记这个阶段？是因为并发标记的时候 由于用户线程还在运行 可能产生了新的垃圾 所以需要在标记一次,当然由于第2阶段标记过一次了，这一次理论上会很快 这个阶段会STW</li><li>并发清除<br>清理需要回收的对象 不影响用户线程使用。cms有个开关(<code>-XX:CMSFullGCsBeforeCompaction=0</code>)默认是开启碎片整理，由于cms清理后的空间也是有碎片存在的，所以一次清理就会整理一次碎片。此阶段用户线程同样会产生新的垃圾 目前没有解决清除 网上叫为<code>浮动垃圾</code>。</li></ol><p>所以cms只有在并发标记和并发清除阶段是不影响用户线程停顿的。初始标记 和 重新标记 也是划分的区域标记的，总体上能够控制gc停顿时间 提高用户体验，工作原理如下</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/7.png" alt="7" title="">                </div>                <div class="image-caption">7</div>            </figure><p>当老年代内存使用到92%<code>(-XX:CMSInitiatingOccupancyFraction=92)</code>之后出触发cms回收一次，如果cms在回收期间中 剩余的内存不够用户工作线程使用了<code>(报异常Concurrent Mode Fail)</code> 那么serial old回收器就成了紧急替补队员立即进行回收一次，当然停顿的时间就更长了。由于cms部分阶段是用户线程和gc线程一起工作，如果启动阈值设置得太高，容易导致用户工作线程不够用触发cmf异常，性能反而降低。</p><h5 id="G1收集器"><a href="#G1收集器" class="headerlink" title="G1收集器"></a>G1收集器</h5><p>G1垃圾回收器可以同时支持年轻代、老年代，G1并没有在物理分区隔离，上面的提到的垃圾回收器都是物理上进行分区的，G1是由一块一块大小相同的<code>region</code>组成，虽然没有物理上进行分区，但是依然保留了年轻代 老年代的概念。回收流程有点类似cms。也是分为<code>初始标记</code>、<code>并发标记</code>、<code>最终标记</code>、<code>筛选回收</code> 4个阶段。</p><p>Region的大小可以通过G1HeapRegionSize参数进行设置，其必须是2的幂，范围允许为1Mb到32Mb。基于堆内存的初始值和最大值的平均数计算分区的尺寸，平均的堆尺寸会分出约2000个Region。分区大小一旦设置，则启动之后不会再变化。region之间采用复制算法，因此不容易产生内存碎片。每个Region都有一个Remembered Set。当对引用进行写操作的时候，G1检查该引用的对象是否在别的region中，是的话，则通过CardTable把相关引用信息存到被引用对象的Remembered Set中。当进行内存回收时，把RememberSet加入到GC Roots根节点的枚举范围。这样就可以保证不全堆扫描也不会有遗漏。 内存结构如下</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-10-19/9.png" alt="9" title="">                </div>                <div class="image-caption">9</div>            </figure><ol><li>Survivor regions(年轻代-Survivor区)</li><li>Old regions（老年代）</li><li>Humongous regions（巨型对象区域） 占用了Region容量的50%以上对象 巨型对象比较大 一般在并发标记阶段如果可以回收就直接回收了。</li><li>Free resgions（未分配区域，也会叫做可用分区）-上图中空白的区域</li></ol><p>G1之所以这里厉害在于它用到了一些数据结构的技巧</p><p>TLAB(Thread Local Allocation Buffer)本地线程缓冲区</p><p>PLAB(Promotion Local Allocation Buffer) 晋升本地分配缓冲区</p><p>Collecion Sets(CSets)待收集集合</p><p>Card Table 卡表</p><p>Remembered Sets(RSets)已记忆集合</p><p>回收流程大致如下</p><ol><li><p>初始标记</p><p>只是标记GC Roots根对象 会stw </p></li><li><p>并发标记</p><p>从上一步标记的GC Roots开始计算可达性分析并标记 这阶段耗时但是是并发的 不影响用户线程使用</p></li><li><p>最终标记<br>上一步执行的过程中产出的变动再一次计算和标记 会stw 短暂的停顿，JVM将这段时间对象变化记录到Remembered Set Log中，在最终标记阶段把Remembered Set Log合并到Remembered Set中。</p></li><li><p>筛选回收<br>为什么多了一步筛选再回收，在于G1在收集的时候会优先回收比较有价值的region区域，垃圾对象比较多 存活对象比较少的region就算是有价值的 这样就能有效的提高回收效率。因为优先回收掉有价值的region而不是一下全部把堆中的全部垃圾回收完，所以回收的时间基本上能够把控。这个阶段是并行操作但是会有短暂的STW基本感知不到。</p></li></ol><p>JDK10 之前的G1中的GC只有YoungGC,MixedGC。FullGC处理会交给单线程的Serial Old垃圾收集器。</p><h5 id="zgc收集器"><a href="#zgc收集器" class="headerlink" title="zgc收集器"></a>zgc收集器</h5><h5 id="Shenandoah"><a href="#Shenandoah" class="headerlink" title="Shenandoah"></a>Shenandoah</h5><p>参考 <a href="https://zhuanlan.zhihu.com/p/444564414" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/444564414</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;常用的垃圾回收算法&quot;&gt;&lt;a href=&quot;#常用的垃圾回收算法&quot; class=&quot;headerlink&quot; title=&quot;常用的垃圾回收算法&quot;&gt;&lt;/a&gt;常用的垃圾回收算法&lt;/h4&gt;&lt;h5 id=&quot;标记-清除&quot;&gt;&lt;a href=&quot;#标记-清除&quot; class=&quot;header
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="JVM" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/JVM/"/>
    
    
      <category term="java" scheme="https://peachyy.gitee.io/tags/java/"/>
    
      <category term="jvm" scheme="https://peachyy.gitee.io/tags/jvm/"/>
    
      <category term="gc" scheme="https://peachyy.gitee.io/tags/gc/"/>
    
  </entry>
  
  <entry>
    <title>认识RocketMQ4.x架构设计</title>
    <link href="https://peachyy.gitee.io/2022/09/23/rocketmq-framework-des/"/>
    <id>https://peachyy.gitee.io/2022/09/23/rocketmq-framework-des/</id>
    <published>2022-09-22T16:00:00.000Z</published>
    <updated>2022-09-23T08:03:35.397Z</updated>
    
    <content type="html"><![CDATA[<h4 id="消息模型"><a href="#消息模型" class="headerlink" title="消息模型"></a>消息模型</h4><h5 id="单体的消息模型"><a href="#单体的消息模型" class="headerlink" title="单体的消息模型"></a>单体的消息模型</h5><p> RocketMQ消息模型跟其他的消息队列一样 都是 producer - &gt; topic-&gt;consumer</p><p>producer 生产消息 也就是发送者</p><p>topic 消息主题  按topic发送消息 以后消息的存储 分片等都是基于topic做业务处理的</p><p>consumer 消息消费者 也是基于topic来进行消息的消费 支持推和拉模式(其实内部都是pull模式的变种)。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-09-23-/1.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure> <h5 id="扩展集群消息模型"><a href="#扩展集群消息模型" class="headerlink" title="扩展集群消息模型"></a>扩展集群消息模型</h5><p>  为了支持高并发、提高可扩展性、提高消息堆积能力。</p><p>一个topic可以有多个队列 而且还可以在不同的物理机器，这就为高吞吐、水平扩展支持打了基础。</p><p>在消费端consumer支持组(group)概念。一组consumer里面有多个消费者实例，一组consumer来消费某个topic 这样消费能力就得到了水平扩展</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-09-23-/2.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure> <p>consumer组支持<code>集群消费模式</code>、<code>广播消费模式</code> </p><ul><li><p>集群消费下同组consumer实例会去拉取对应topic的不同队列上数据进行消费。‘</p></li><li><p>广播模式是每个消费者都会拉取对应topic中所有队列的消息来消费。</p></li></ul><h4 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h4><p>  <code>RocketMQ</code>总体最组件分为 <code>NameServer</code>  <code>Broker</code> <code>Porducer</code> <code>Consumer</code> </p><p><img src="/images/2022-09-23-/3.png" alt="3"> </p><h5 id="NameServer-名称服务"><a href="#NameServer-名称服务" class="headerlink" title="NameServer 名称服务"></a>NameServer 名称服务</h5><p>  NameServer类似于Zookeeper这种角色 负责管理集群组件，简单来说NameServer可以查询到Broker有哪些、Topic在哪些Broker机器上 队列是如何分布的，它就像一颗大脑 管理者 收集者。相当于是一个topic路由管理中心，NameServer可以多实例分别独立部署、相互之间不产出数据交换，每个Broker在启动的时候会向所有的NameServer上报信息，所以他们之间可以相互独立，完全无状态。就算挂掉1个也不影响集群。</p><h5 id="Broker-消息存储代理服务"><a href="#Broker-消息存储代理服务" class="headerlink" title="Broker 消息存储代理服务"></a>Broker 消息存储代理服务</h5><p><code>Broker</code>才是真正托管消费存储、投递查询的服务，这个是非常核心的服务，大部分的性能优化都是针对这个服务进行。Broker分为<code>master</code> <code>slave</code>角色 在配置文件中brokerId=0表示Master  不为0表示slave。</p><p>broker启动后和NameServer建立了长连接 定期向NameServer上报Topic信息自身信息。</p><h5 id="producer-生产者"><a href="#producer-生产者" class="headerlink" title="producer 生产者"></a>producer 生产者</h5><p>  生产/发送消息服务，一般是程序自己编写的业务发送消息端，启动后首先会和NameServer建立连接，定时从NameServer获取Topic路由信息，定时查询Broker服务信息 同时会和Broker <code>master</code>角色建立长连接。producer 也是无状态的。</p><h5 id="consumer-消费者"><a href="#consumer-消费者" class="headerlink" title="consumer 消费者"></a>consumer 消费者</h5><p> 消费者服务 一般是由自己业务程序编写实现。启动后和NameServer建立连接 定时从NameServer获取topic信息和Broker信息，获取到Broker的信息后会和broker中的master salve角色也建立长连接  所有consumer中可以订阅master和slave。</p><p>只有非常懂IO的人 才能写得出来这么优秀的框架 里面有太多值的学习和借鉴的设计和思想 后面再慢慢精研。</p><p>参考<a href="https://rocketmq.apache.org/docs/%E4%BB%8B%E7%BB%8D/03whatis" target="_blank" rel="noopener">https://rocketmq.apache.org/docs/%E4%BB%8B%E7%BB%8D/03whatis</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;消息模型&quot;&gt;&lt;a href=&quot;#消息模型&quot; class=&quot;headerlink&quot; title=&quot;消息模型&quot;&gt;&lt;/a&gt;消息模型&lt;/h4&gt;&lt;h5 id=&quot;单体的消息模型&quot;&gt;&lt;a href=&quot;#单体的消息模型&quot; class=&quot;headerlink&quot; title=&quot;单体的
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="rocketmq" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/rocketmq/"/>
    
    
      <category term="rocketmq" scheme="https://peachyy.gitee.io/tags/rocketmq/"/>
    
  </entry>
  
  <entry>
    <title>62进制在短链接场景的妙用</title>
    <link href="https://peachyy.gitee.io/2022/09/21/62radix_using/"/>
    <id>https://peachyy.gitee.io/2022/09/21/62radix_using/</id>
    <published>2022-09-20T16:00:00.000Z</published>
    <updated>2022-09-21T09:53:32.124Z</updated>
    
    <content type="html"><![CDATA[<p>假如要生成6位的字符 如何才能可靠的生成更多数据。</p><p>10进制 最大只能生成 10 ^ 6 - 1 =<strong>999999</strong>个<br>16进制 最大只能生成 16 ^ 6 - 1 =<strong>16777215</strong>个<br> <em>16进制里面已经包含了 A B C D E F 这几个字母</em><br>62进制 最大竟能生成 62 ^ 6 - 1 =<strong>56800235583</strong>个 基本上够玩了吧。<br> <em>A-Z a-z 0-9</em>刚好等于62位<br> <em>64进制 因为包含了特殊字段 用于短链接有点特殊 所以现在大部分都是使用62进制或者其他的算法。 </em></p><p>接下来将使用原有的编码串传为62进制即可嫁接到现有业务中去 仅需少许改动。<br>如果原有的id是10进制数字 那么就可以可以把10进制转换为62进制即可。<br>如果原有的id是字符串或者其他标识 可以用先获取到hashcode后 当作是做个10进制数再进行62进制转换。<br>10进制转换62进制的逻辑就是 一直循环用62取余 然后倒序。代码如下</p> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String chars = <span class="string">"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> scale = <span class="number">62</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> minlen = <span class="number">6</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">base62Encode</span><span class="params">(<span class="keyword">long</span> num)</span> </span>&#123;</span><br><span class="line">    StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    <span class="keyword">int</span> remainder;</span><br><span class="line">    <span class="keyword">while</span> (num &gt; scale - <span class="number">1</span>) &#123;<span class="comment">//大于62-1才计算 小于就直接是自身即可</span></span><br><span class="line">        remainder = Long.valueOf(num % scale).intValue();</span><br><span class="line">        sb.append(chars.charAt(remainder));</span><br><span class="line">        num = num / scale;</span><br><span class="line">    &#125;</span><br><span class="line">    sb.append(chars.charAt(Long.valueOf(num).intValue()));</span><br><span class="line">    String value = sb.reverse().toString();</span><br><span class="line">    <span class="keyword">return</span> StringUtils.leftPad(value, minlen, <span class="string">'0'</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    System.out.println( base62Encode(<span class="number">9000000000L</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 上面程序输出 <code>9p558K</code> 这么大的数值就用这几个字符表达就能完成了。可想这个玩意还能用于很多场景 比如id 用少量的字符表示更大的数据、临时转码等场景<br> 在短链接领域我知道是 B站 抖音 估计都是用的62进制。</p><p> 用随便一个转换工具网站 转换一个地址 如  <a href="http://m6z.cn/5X6an7" target="_blank" rel="noopener">http://m6z.cn/5X6an7</a>  看起来也像是62进制。</p><p> 上面的<code>chars</code> 还能调整顺序 变为自己的base62编码。这样的玩法还可以变通为58进制等。</p><p> 如果你的业务线很大 还可以为62进制编码加业务编码前缀。如 推荐系统的规则为88开头，客户系统为99开头。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;假如要生成6位的字符 如何才能可靠的生成更多数据。&lt;/p&gt;
&lt;p&gt;10进制 最大只能生成 10 ^ 6 - 1 =&lt;strong&gt;999999&lt;/strong&gt;个&lt;br&gt;16进制 最大只能生成 16 ^ 6 - 1 =&lt;strong&gt;16777215&lt;/strong&gt;个&lt;b
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="短链接" scheme="https://peachyy.gitee.io/tags/%E7%9F%AD%E9%93%BE%E6%8E%A5/"/>
    
      <category term="62进制" scheme="https://peachyy.gitee.io/tags/62%E8%BF%9B%E5%88%B6/"/>
    
      <category term="进制转换" scheme="https://peachyy.gitee.io/tags/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
    
  </entry>
  
  <entry>
    <title>二进制转换与位运算</title>
    <link href="https://peachyy.gitee.io/2022/09/09/code_radix/"/>
    <id>https://peachyy.gitee.io/2022/09/09/code_radix/</id>
    <published>2022-09-08T16:00:00.000Z</published>
    <updated>2022-12-20T04:58:28.921Z</updated>
    
    <content type="html"><![CDATA[<p>在应用程序常用的进制包含 <code>二进制</code> <code>八进制</code> <code>十进制</code> <code>十六进制</code></p><table><thead><tr><th>进制数</th><th>前缀</th><th>示例</th><th>进位规则</th></tr></thead><tbody><tr><td>二进制</td><td>0b</td><td>0b100</td><td>包含0 1 逢2进1   符号位中0表示正数  1 表示负数</td></tr><tr><td>八进制</td><td>0</td><td>0100</td><td>0-7 逢8进位</td></tr><tr><td>十进制</td><td>无</td><td>100 表示100</td><td>0-9</td></tr><tr><td>十六进制</td><td>0x</td><td>0x100</td><td>0-9 a(10) b(11) c(12) d(13) e(14) f(15)  逢16进位</td></tr></tbody></table><h4 id="二进制和十进制快速状态-8421法则"><a href="#二进制和十进制快速状态-8421法则" class="headerlink" title="二进制和十进制快速状态 8421法则"></a>二进制和十进制快速状态 8421法则</h4><p>二进制  1        1        1        1        1        1        1        1</p><p>十进制   128    64    32        16     8        4        2        1</p><p>具体使用方法如 二进制数 11011 快速转换为十进制  1+2+0+8+16=27</p><p>从右边往左数 位数值如果是1则加上对于的8421法则中的十进制数据 1(第一位是1 对应值1)+2(第二位是1对应值2)+0(第三位不是1 那么值就为0)+8(第四位是1 对应值为8)+16(第五位为1 对应值为16)=27 所有合计等于27。这个二进制数就快速的转换为十进制了。</p><p>以下数字位数都是以Java为例子  java int是占4byte 1byte占用8bit 所以占32位。不同的类型占用的位数也不同  如果你问数字8是怎么存储的就不专业了，应该是数字8在32位下是怎么存储的 在64位是怎么存储的 比如java里面long类型就是64位。它和32位的存储肯定不一样的。</p><p>计算机中有符号的数据都是按补码的形式进行存储的。</p><p>正数的<code>原码</code> <code>反码</code> <code>补码</code> 都是一样的。</p><p>负数的转换  原码 -&gt;反码-&gt;补码</p><p><code>原码</code> <em>符号位+数值位数</em></p><p><code>反码</code> <em>除符号位不变 其他位全部取反 1变0 0变1</em></p><p><code>补码</code> <em>在反码的基础上+1就是补码</em></p><p>比如 +9  存储为原码=反码=补码<code>0b00000000000000000000000000001001</code></p><p>比如-9   就相对复杂一些  存储的补码转换原理为</p><p>原码 0b00000000000000000000000000001001</p><p>反码 0b11111111111111111111111111110110</p><p>补码 0b11111111111111111111111111110111</p><h4 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h4><p>位运算的操作数都是以二进制类型而且是补码形式进行计算的,在看原码的时候经常看到这类运算符。</p><table><thead><tr><th>符号</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td>&amp;</td><td>按位与 2个位数值都为1 返回1</td><td>3&amp;4</td></tr><tr><td>&#124;</td><td>按位或 2个位数值其中1个位1 返回1</td><td>3&#124;4</td></tr><tr><td>^</td><td>按位异或 2个位数中不相同返回1</td><td></td></tr><tr><td>~</td><td>按位取反 位数中的1变0，0变1</td><td></td></tr><tr><td>&lt;&lt;</td><td>左移 操作数乘以2的n(移动位数)次幂</td><td></td></tr><tr><td>&gt;&gt;</td><td>右移 操作数除以2的n(移动位数)次幂 用原符号位填充</td><td></td></tr><tr><td>&gt;&gt;&gt;</td><td>无符号右移  操作数除以2的n(移动位数)次幂 符号位用0填充</td></tr></tbody></table><h5 id="amp-位与运算"><a href="#amp-位与运算" class="headerlink" title="&amp;位与运算"></a>&amp;位与运算</h5><p>&amp; 位与  2个操作二进制位数中所有位数值都相等就</p><p>  3&amp;4=0</p><p>3二进制 0b00000000000000000000000000000011</p><p>4二进制 0b00000000000000000000000000000100</p><p>​             =0b00000000000000000000000000000000</p><h5 id="位或运算"><a href="#位或运算" class="headerlink" title="|位或运算"></a>|位或运算</h5><p> 2个位数值其中1个位1 返回1</p><p>3|4=7</p><p>3二进制 0b00000000000000000000000000000011</p><p>4二进制 0b00000000000000000000000000000100</p><p>​             =0b00000000000000000000000000000111</p><h5 id="异或运算"><a href="#异或运算" class="headerlink" title="^异或运算"></a>^异或运算</h5><p> 2个位数中不相同返回1</p><p>3&amp;4=7</p><p>3二进制 0b00000000000000000000000000000011</p><p>4二进制 0b00000000000000000000000000000100</p><p>​             =0b00000000000000000000000000000111</p><p>一个数据对相同的数据异或2次 值不变 ,在加密场景中比较常见。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a=<span class="number">3</span>;<span class="keyword">int</span> b=<span class="number">4</span>;</span><br><span class="line">System.out.println(a^b^b);<span class="comment">//值输出3</span></span><br></pre></td></tr></table></figure><p>用异或实现2个数据交换</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">        <span class="keyword">int</span> a=<span class="number">3</span>;<span class="keyword">int</span> b=<span class="number">4</span>;</span><br><span class="line">        a=a^b;</span><br><span class="line">        b=a^b;</span><br><span class="line">        a=a^b;</span><br><span class="line">        System.out.println(<span class="string">"a="</span>+a+<span class="string">",b="</span>+b);</span><br><span class="line"><span class="comment">//输出a=4,b=3</span></span><br></pre></td></tr></table></figure><h5 id="按位取反运算符"><a href="#按位取反运算符" class="headerlink" title="~按位取反运算符"></a>~按位取反运算符</h5><p>位数位1 变0 ，位数位0变1</p><p>~3=-4</p><p>3二进制 0b00000000000000000000000000000011</p><p>​             =0b11111111111111111111111111111100  这个数是补码</p><h5 id="lt-lt-左移"><a href="#lt-lt-左移" class="headerlink" title="&lt;&lt;左移"></a>&lt;&lt;左移</h5><p>操作数乘以2的n(移动位数)次幂</p><p> 3&lt;&lt;4 = 48 </p><p>3的二进制0b00000000000000000000000000000011</p><p>  左移4位=0b00000000000000000000000000110000</p><p>相当于是 3x2^4=48</p><h5 id="gt-gt-右移"><a href="#gt-gt-右移" class="headerlink" title="&gt;&gt;右移"></a>&gt;&gt;右移</h5><p>操作数除以2的n(移动位数)次幂 往右移位的时候左边会空出来，补充的数位符号位 0则用0填充 1 则用1填充</p><p>32&gt;&gt;4=2</p><p>32的二进制0b0000000000000000000000000100000</p><p>​    右移4位=0b0000000000000000000000000000010</p><p>相当于是32/2^4=2</p><h5 id="gt-gt-gt-无符号右移"><a href="#gt-gt-gt-无符号右移" class="headerlink" title="&gt;&gt;&gt;无符号右移"></a>&gt;&gt;&gt;无符号右移</h5><p>操作数除以2的n(移动位数)次幂 往右移位的时候左边会空出来，补充的数位符位<code>0</code>这也是和有符号右移的区别 。正数无符号右移和有符号右移的值一致。</p><p>32&gt;&gt;&gt;4=2</p><p>32的二进制0b0000000000000000000000000100000</p><p>​    右移4位=0b0000000000000000000000000000010</p><p>相当于是32/2^4=2</p><p>-32&gt;&gt;&gt;4=268435454</p><p>-32的二进制补码位0b11111111111111111111111111100000</p><p>​                 右移4位=0b00001111111111111111111111111110</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在应用程序常用的进制包含 &lt;code&gt;二进制&lt;/code&gt; &lt;code&gt;八进制&lt;/code&gt; &lt;code&gt;十进制&lt;/code&gt; &lt;code&gt;十六进制&lt;/code&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;进制数&lt;/th&gt;
&lt;th&gt;前缀&lt;/th&gt;
&lt;th&gt;示
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="进制转换" scheme="https://peachyy.gitee.io/tags/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
    
      <category term="java基础" scheme="https://peachyy.gitee.io/tags/java%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>记一次用arthas排查jvm中CPU占用过高问题</title>
    <link href="https://peachyy.gitee.io/2022/08/31/jvm_cpu_arthas_check/"/>
    <id>https://peachyy.gitee.io/2022/08/31/jvm_cpu_arthas_check/</id>
    <published>2022-08-30T16:00:00.000Z</published>
    <updated>2022-08-31T14:44:51.437Z</updated>
    
    <content type="html"><![CDATA[<p>记一次使用<code>arthas</code>排查jvm中CPU占用过高问题。这工具屌爆了 碾压我目前使用的全部JVM工具。</p><h4 id="安装-小试"><a href="#安装-小试" class="headerlink" title="安装 小试"></a>安装 小试</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -O https://arthas.aliyun.com/arthas-boot.jar</span><br><span class="line">java -jar arthas-boot.jar --repo-mirror aliyun --use-http</span><br></pre></td></tr></table></figure><p>jar后面的参数也可以不加 加上只是为了下载速度更快</p><p>接下来<code>arthas</code> 控制台中显示了当前机器上jvm进程列表 输入需要排查的jvm进程号即可进入监控命令模式</p><h4 id="找出CPU的元凶"><a href="#找出CPU的元凶" class="headerlink" title="找出CPU的元凶"></a>找出CPU的元凶</h4><p>处理问题之前 <em>先想想如何去找到问题的原因</em> 这个是解决问题个人觉得最重要的一步。</p><p>当前的现状是jvm启动后 cpu直接飙升到<code>80+%</code>。而内存是正常的，可以认为大概率是某个线程占用了计算资源 导致的。所以第一步需要先把占用过高线程给揪出来。</p><p>这次使用<code>arthas</code>排查。也顺便提一下以前记录过用<code>top -Hp</code>的方法找出占用资源的线程PID 方法 <a href="/2020/12/11/find_jvm_cpu_max_thread/">top -Hp方法参考</a>  。</p><p>输入命令 <code>thread</code> 查看所有线程信息 默认是按照cpu资源占用排名的</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/2022-08-31-jvm_cpu_arthas_check/1.PNG" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p>可以看到当前线程<code>lettuce-nioEventLoop-4-1</code> 占用cpu高达47.75。其实这个线程名称已经能定位到具体某个方向的问题了，所以线程名称的定义需要有意义 为了方便排查问题。</p><p>可以看出因为我们程序使用了<code>lettuce</code>做redis的客户端，主要是使用了<code>redis stream</code> </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StreamMessageListenerContainer.StreamMessageListenerContainerOptions&lt;String, ObjectRecord&lt;String, String&gt;&gt; containerOptions =</span><br><span class="line">        StreamMessageListenerContainer.StreamMessageListenerContainerOptions.builder()</span><br><span class="line">                .batchSize(<span class="number">10</span>) <span class="comment">// 一次性最多拉取多少条消息</span></span><br><span class="line">                .targetType(String.class) <span class="comment">// 目标类型。统一使用 String</span></span><br><span class="line">                .executor(mqConsumerExecutor)</span><br><span class="line">                .pollTimeout(Duration.ZERO)<span class="comment">//0不超时</span></span><br><span class="line">                .build();</span><br></pre></td></tr></table></figure><p>把<code>.pollTimeout(Duration.ZERO)</code>这一句改为 <code>.pollTimeout(Duration.ofMillis(10))</code>cpu就正常了。原因就是设置了永不超时 资源得不到释放。改为指定时间超时后 程序一点问题都没有了。</p><h5 id="查看线程栈的参数"><a href="#查看线程栈的参数" class="headerlink" title="查看线程栈的参数"></a>查看线程栈的参数</h5><p>可以直接使用<code>thread pid</code> 上图占用最高的id为22 则输入 <code>thread 22</code> 能看到类似<code>jstack</code>的功能</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">"lettuce-nioEventLoop-4-1"</span> Id=<span class="number">22</span> RUNNABLE</span><br><span class="line">    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)</span><br><span class="line">    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:<span class="number">269</span>)</span><br><span class="line">    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:<span class="number">93</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:<span class="number">86</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:<span class="number">97</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:<span class="number">101</span>)</span><br></pre></td></tr></table></figure><p>还有一个更好用的命令 <code>-n</code>参数能显示top-n-threads  比上面一种更详细 </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">"lettuce-nioEventLoop-4-1"</span> Id=<span class="number">22</span> cpuUsage=<span class="number">49.51</span>% deltaTime=<span class="number">99</span>ms time=<span class="number">392976</span>ms RUNNABLE</span><br><span class="line">    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)</span><br><span class="line">    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:<span class="number">269</span>)</span><br><span class="line">    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:<span class="number">93</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:<span class="number">86</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:<span class="number">97</span>)</span><br><span class="line">    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:<span class="number">101</span>)</span><br></pre></td></tr></table></figure><p>可以看出使用<code>arthas</code>排除这类问题 比使用<code>top -Hp</code>方便太多。当然这只是它的一个小功能而已。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;记一次使用&lt;code&gt;arthas&lt;/code&gt;排查jvm中CPU占用过高问题。这工具屌爆了 碾压我目前使用的全部JVM工具。&lt;/p&gt;
&lt;h4 id=&quot;安装-小试&quot;&gt;&lt;a href=&quot;#安装-小试&quot; class=&quot;headerlink&quot; title=&quot;安装 小试&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="arthas" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/arthas/"/>
    
    
      <category term="arthas" scheme="https://peachyy.gitee.io/tags/arthas/"/>
    
  </entry>
  
  <entry>
    <title>kafka listener配置解决Server与消费端不在同一网络问题</title>
    <link href="https://peachyy.gitee.io/2022/05/24/kafka-listeners-advertised/"/>
    <id>https://peachyy.gitee.io/2022/05/24/kafka-listeners-advertised/</id>
    <published>2022-05-23T16:00:00.000Z</published>
    <updated>2022-08-24T09:26:24.522Z</updated>
    
    <content type="html"><![CDATA[<p>在<code>kubernetes</code>容器环境下 kafka会默认把主机名注册到zookeeper。这个时候消费端部署在不同的命名空间或者不同的集群中会出现无法访问的情况。用<code>advertised.listeners</code>配置可以重写默认注册的地址。</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><h5 id="listeners"><a href="#listeners" class="headerlink" title="listeners"></a>listeners</h5><p>  listeners 配置的是kafka Server 的tcp侦听ip地址。</p><h5 id="advertised-listeners"><a href="#advertised-listeners" class="headerlink" title="advertised.listeners"></a>advertised.listeners</h5><p>  该配置主要是用于把Broker的ip地址信息发布到Zookeeper中，简而言之就是配置的kafka的broker ip。如果你的消费端需要不同集群/网段的访问 需要确保改地址该消费端可访问的地址</p><p>其他这个也不一定是在容器环境下会存在 常规的机器环境下也会出现这个问题 如果broker的ip消费端访问不到的情况下 像下面这个异常 可以查一下这个问题。  </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">java.net.UnknownHostException: cep-kafka</span><br><span class="line">        at java.net.InetAddress.getAllByName0(InetAddress.java:<span class="number">1281</span>)</span><br><span class="line">        at java.net.InetAddress.getAllByName(InetAddress.java:<span class="number">1193</span>)</span><br><span class="line">        at java.net.InetAddress.getAllByName(InetAddress.java:<span class="number">1127</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在&lt;code&gt;kubernetes&lt;/code&gt;容器环境下 kafka会默认把主机名注册到zookeeper。这个时候消费端部署在不同的命名空间或者不同的集群中会出现无法访问的情况。用&lt;code&gt;advertised.listeners&lt;/code&gt;配置可以重写默认注册的地
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kafka" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/kafka/"/>
    
    
      <category term="kafka" scheme="https://peachyy.gitee.io/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>使用certbot制作免费Lets encrypt SSL证书</title>
    <link href="https://peachyy.gitee.io/2022/04/07/letsencrypt-certbot-ssl/"/>
    <id>https://peachyy.gitee.io/2022/04/07/letsencrypt-certbot-ssl/</id>
    <published>2022-04-06T16:00:00.000Z</published>
    <updated>2022-04-07T03:58:56.283Z</updated>
    
    <content type="html"><![CDATA[<p>利用<code>certbot</code>软件包可以免费制作SSL证书 这对小网站和测试项目太有用了，下面记录一下制作证书的流程和方法。以备后用。以centos7系统为例 其他系统类似。</p><h4 id="安装certbot"><a href="#安装certbot" class="headerlink" title="安装certbot"></a>安装certbot</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y certbot</span><br></pre></td></tr></table></figure><h4 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h4><p> 制作证书前需要先准备好域名的访问环境，因为制作证书的时候需要确认域名和服务器的所有权。</p><p>  1、dns验证</p><pre><code>dns验证需要加参数 --preferred-challenges dns 来定义，主要就是配置域名的txt记录即可。 下面主要是用单机验证方式。</code></pre><p>  2、服务器文件验证</p><pre><code>需要服务器开放80端口、配置nginx的静态文件访问目录。但是需要制定 webroot参数来路径，会生成一个文件,然后访问这个文件是否能成功访问到。 成功则验证通过</code></pre><p>  3、单机生成</p><pre><code>不需要额外的支持 命令加--standalone来指定 需要关闭nginx或者apache才能执行。</code></pre><h4 id="创建证书"><a href="#创建证书" class="headerlink" title="创建证书"></a>创建证书</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">certbot certonly --standalone -d xxx.test.com -m taoxxx@foxmail.com --agree-tos</span><br></pre></td></tr></table></figure><p>这一步可能有环境问题报错的情况 自行百度解决。<br>如果出现 <code>Problem binding to port 80: Could not bind to IPv4 or IPv6.</code> 这种错误 可以把nginx或者apache关了再重新执行上面生成证书的命令</p><p> 生成成功后会输入下面提示，打印了证书的路径在<code>/etc/letsencrypt/live/xxx.test.com/</code>，过期时间为90天，以及续期的命令。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">IMPORTANT NOTES:</span><br><span class="line"> - Congratulations! Your certificate and chain have been saved at:</span><br><span class="line">   /etc/letsencrypt/live/xxx.test.com/fullchain.pem</span><br><span class="line">   Your key file has been saved at:</span><br><span class="line">   /etc/letsencrypt/live/xxx.test.com/privkey.pem</span><br><span class="line">   Your certificate will expire on 2022-07-06. To obtain a new or</span><br><span class="line">   tweaked version of this certificate in the future, simply run</span><br><span class="line">   certbot again. To non-interactively renew *all* of your</span><br><span class="line">   certificates, run "certbot renew"</span><br><span class="line"> - If you like Certbot, please consider supporting our work by:</span><br><span class="line"></span><br><span class="line">   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate</span><br><span class="line">   Donating to EFF:                    https://eff.org/donate-le</span><br></pre></td></tr></table></figure><h4 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">        listen 443 ssl http2;</span><br><span class="line">        server_name  xxx.test.com;</span><br><span class="line">        client_max_body_size 1024M;</span><br><span class="line">        proxy_connect_timeout       600;</span><br><span class="line">        proxy_send_timeout          600;</span><br><span class="line">        proxy_read_timeout          600;</span><br><span class="line">        send_timeout                600;</span><br><span class="line">        keepalive_timeout 4800;</span><br><span class="line">        index             index.html;</span><br><span class="line">       ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;</span><br><span class="line">       ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;</span><br><span class="line">       ssl_prefer_server_ciphers on;</span><br><span class="line">       ssl_session_cache shared:SSL:10m;</span><br><span class="line">       ssl_session_timeout 10m;</span><br><span class="line">       ssl_certificate /etc/letsencrypt/live/xxx.test.com/fullchain.pem;</span><br><span class="line">       ssl_certificate_key /etc/letsencrypt/live/xxx.test.com/privkey.pem;</span><br><span class="line">       ....省略</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重启nginx 用https访问服务可以看见浏览器的一个小锁就表示https证书部署成功了。</p><h4 id="续期"><a href="#续期" class="headerlink" title="续期"></a>续期</h4><p>因为这个免费证书只有90天的有效期，到了就需要续期才能继续使用，目前只能手动续期  <code>执行命令 certbot renew</code>。但是可以用定时任务的方式每天续费一次 好像也可以一劳永逸。</p><p>crontab -e</p><pre><code class="shell">0 */6 * * * certbot renew --quiet &amp;&amp; nginx -s reload</code></pre><h4 id="其他证书操作"><a href="#其他证书操作" class="headerlink" title="其他证书操作"></a>其他证书操作</h4><p>1、查看已经生成的证书</p><pre><code>`certbot certificates`</code></pre><p>2、吊销证书</p><p>   <code>certbot revoke --cert-path &quot;/etc/letsencrypt/live/xxx.test.com/cert.pem&quot;</code></p><p>由于环境的不同 会遇到各种坑 用docker的方式来创建和续期是可复制性最高的。</p><p>参考<br><a href="https://github.com/wmnnd/nginx-certbot" target="_blank" rel="noopener">https://github.com/wmnnd/nginx-certbot</a><br><a href="https://github.com/JonasAlfredsson/docker-nginx-certbot" target="_blank" rel="noopener">https://github.com/JonasAlfredsson/docker-nginx-certbot</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;利用&lt;code&gt;certbot&lt;/code&gt;软件包可以免费制作SSL证书 这对小网站和测试项目太有用了，下面记录一下制作证书的流程和方法。以备后用。以centos7系统为例 其他系统类似。&lt;/p&gt;
&lt;h4 id=&quot;安装certbot&quot;&gt;&lt;a href=&quot;#安装certbot
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="ssl" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/ssl/"/>
    
    
      <category term="certbot" scheme="https://peachyy.gitee.io/tags/certbot/"/>
    
      <category term="Lets encrypt" scheme="https://peachyy.gitee.io/tags/Lets-encrypt/"/>
    
  </entry>
  
  <entry>
    <title>MySql SSL CA证书JDBC配置</title>
    <link href="https://peachyy.gitee.io/2022/01/26/mysql-ssl-ca-jdbc/"/>
    <id>https://peachyy.gitee.io/2022/01/26/mysql-ssl-ca-jdbc/</id>
    <published>2022-01-25T16:00:00.000Z</published>
    <updated>2022-01-26T06:43:29.953Z</updated>
    
    <content type="html"><![CDATA[<p>开启MySql数据库SSL证书以后 如何在<code>jdbc</code>中配置证书访问呢？<br>关于数据库如何配置SSL证书自行百度  这里演示客户端如何利用证书来进行数据通讯。<br>开启证书jdbc认证后 肯定是有一定的性能开销的，个人觉得内网环境无需配置CA证书校验。</p><p>下面用一个示例来演示如何配置</p><p>未配置证书访问前</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">spring.datasource.url=jdbc:mysql:<span class="comment">//127.0.0.1:3306/sslcatestdb?zeroDateTimeBehavior=convertToNull&amp;characterEncoding=utf-8</span></span><br></pre></td></tr></table></figure><p>配置了证书访问后</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">spring.datasource.url=jdbc:mysql:<span class="comment">//127.0.0.1:3306/sslcatestdb?zeroDateTimeBehavior=convertToNull&amp;characterEncoding=utf-8useSSL=true&amp;trustCertificateKeyStoreUrl=file:/证书路径&amp;trustCertificateKeyStoreType=证书类型&amp;trustCertificateKeyStorePassword=证书密码&amp;</span></span><br><span class="line">clientCertificateKeyStoreUrl=file:/证书路径&amp;clientCertificateKeyStoreType=证书类型&amp;clientCertificateKeyStorePassword=证书密码&amp;verifyServerCertificate=<span class="keyword">true</span></span><br></pre></td></tr></table></figure><p>证书相关配置属性</p><ul><li>useSSL  开启ssl</li><li>trustCertificateKeyStoreUrl    服务端证书路径</li><li>trustCertificateKeyStoreType  服务端证书类型</li><li>trustCertificateKeyStorePassword  服务端证书密码</li><li>clientCertificateKeyStoreUrl  客户端证书路径</li><li>clientCertificateKeyStoreType  客户端证书类型 </li><li>clientCertificateKeyStorePassword 客户端证书密码</li><li>verifyServerCertificate 信任验证服务器证书</li></ul><p>参考 <a href="https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-connp-props-security.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-connp-props-security.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;开启MySql数据库SSL证书以后 如何在&lt;code&gt;jdbc&lt;/code&gt;中配置证书访问呢？&lt;br&gt;关于数据库如何配置SSL证书自行百度  这里演示客户端如何利用证书来进行数据通讯。&lt;br&gt;开启证书jdbc认证后 肯定是有一定的性能开销的，个人觉得内网环境无需配置CA证书
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="mysql" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/mysql/"/>
    
    
      <category term="mysql" scheme="https://peachyy.gitee.io/tags/mysql/"/>
    
      <category term="sslca" scheme="https://peachyy.gitee.io/tags/sslca/"/>
    
  </entry>
  
  <entry>
    <title>jvm容器化内存感知实践</title>
    <link href="https://peachyy.gitee.io/2021/12/28/dockerjvmarg_action/"/>
    <id>https://peachyy.gitee.io/2021/12/28/dockerjvmarg_action/</id>
    <published>2021-12-27T16:00:00.000Z</published>
    <updated>2021-12-28T09:02:35.608Z</updated>
    
    <content type="html"><![CDATA[<p><code>docker</code>容器本身需要设置容器的最大可使用内存(防止单个容器消耗节点大量的资源)，跑在容器中的<code>jvm</code>进程也需要设置内存，防止内存占用过大被容器<code>Kill</code>,所以如何优雅的在容器化中设置内存是一个很有必要了解的话题。</p><ul><li><code>jdk 8u131+</code> <code>java 9+</code> 使用参数开启实验性功能 <code>-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap</code>。 开启容器化支持功能。</li><li><code>java 8u191+</code> <code>java10+</code> 使用参数<code>UseContainerSupport</code> 开启容器化感知支持功能。</li><li><code>-XX:MaxRAMPercentage</code> 限制最大<code>heap</code>内存占比 。</li><li><code>-XX:InitialRAMPercentage</code> 设置初始<code>heap</code>内存占比，此参数如果和<code>MaxRAMPercentage</code>设置一样表示jvm最大与最小一致  jvm不会去伸缩内存 这也是一种普遍使用的方式。其值介于0.0到100.0之间，默认值为25。</li></ul><p>上面的几个参数可以让jvm读取<code>cgroup</code>的一些数据，并进行相应的适配，这样容器内jvm超时最大内存 就自己会<code>OOM</code>而不是被容器<code>Kill</code>。关于被<code>OOM</code>后怎么怎么拉取以及存储<code>OOM</code>文件参考 <a href="/2021/11/11/k8s-jvm-dumpcollect">在k8s中收集jvm异常dump文件到OSS</a></p><h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><p>以下案例已设置了容器最大可实现内存<code>4G</code> CPU <code>1核</code></p><p>使用参数 限制<code>heap</code>最大内存为80%</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">java  -server -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMPercentage=80.0 ....</span><br></pre></td></tr></table></figure><p>使用jmap查看heap内存情况 显示<code>MaxHeapSize</code>为3278mb 刚好为(4*1021)/0.8 说明jvm能感知到容器最大内存为4g 且只能分配80%的内存给<code>heap</code>。剩余的20%供其他的进程使用。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">jmap -heap 19  </span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line">   MinHeapFreeRatio         = 0</span><br><span class="line">   MaxHeapFreeRatio         = 100</span><br><span class="line">   MaxHeapSize              = 3437232128 (3278.0MB)</span><br><span class="line">   NewSize                  = 22020096 (21.0MB)</span><br><span class="line">   MaxNewSize               = 1145569280 (1092.5MB)</span><br><span class="line">   OldSize                  = 45088768 (43.0MB)</span><br><span class="line">   NewRatio                 = 2</span><br><span class="line">   SurvivorRatio            = 8</span><br><span class="line">   MetaspaceSize            = 21807104 (20.796875MB)</span><br><span class="line">   CompressedClassSpaceSize = 1073741824 (1024.0MB)</span><br><span class="line">   MaxMetaspaceSize         = 17592186044415 MB</span><br><span class="line">   G1HeapRegionSize         = 0 (0.0MB)</span><br></pre></td></tr></table></figure><p>JDK8+可以使用-XX:MetaspaceSize和-XX:MaxMetaspaceSize设置元空间初始大小以及最大可分配大小。默认情况下，元空间最大的大小是系统内存的大小，该参数一般默认也无所谓 一般不会因为这个太大导致<code>OOM</code>。<br>这也证明了在容器中获取到的内存是宿主机的内存大小而不是设置了容器限制后的大小。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;docker&lt;/code&gt;容器本身需要设置容器的最大可使用内存(防止单个容器消耗节点大量的资源)，跑在容器中的&lt;code&gt;jvm&lt;/code&gt;进程也需要设置内存，防止内存占用过大被容器&lt;code&gt;Kill&lt;/code&gt;,所以如何优雅的在容器化中设置内存是一个很有
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="docker" scheme="https://peachyy.gitee.io/tags/docker/"/>
    
      <category term="jvm" scheme="https://peachyy.gitee.io/tags/jvm/"/>
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="k8s" scheme="https://peachyy.gitee.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>ingress传递头信息</title>
    <link href="https://peachyy.gitee.io/2021/12/22/k8s-ingress-annotation1/"/>
    <id>https://peachyy.gitee.io/2021/12/22/k8s-ingress-annotation1/</id>
    <published>2021-12-21T16:00:00.000Z</published>
    <updated>2023-03-25T06:01:41.585Z</updated>
    
    <content type="html"><![CDATA[<p>在ningx-ingress中内置提供一些<code>annotation</code> 在不手动手动改<code>ingress-controller</code>的情况下可以提供一些方便的操作。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">kubectl.kubernetes.io/last-applied-configuration:</span> <span class="string">""</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/proxy-body-size:</span> <span class="number">50</span><span class="string">m</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/service-weight:</span> <span class="string">'show-admin: 100</span></span><br><span class="line"><span class="string">    nginx.ingress.kubernetes.io/server-snippet: |</span></span><br><span class="line"><span class="string">      set sub_domain "";</span></span><br><span class="line"><span class="string">      if ( host ~* (.*)-admin.* )&#123;</span></span><br><span class="line"><span class="string">         set sub_domain saas1;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    nginx.ingress.kubernetes.io/configuration-snippet: |</span></span><br><span class="line"><span class="string">         more_set_input_headers "auth-com: saas$1";</span></span><br><span class="line"><span class="string">  generation: 4</span></span><br><span class="line"><span class="string">  name: test-ingress</span></span><br><span class="line"><span class="string">  namespace: default</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  rules:</span></span><br><span class="line"><span class="string">  - host: test.domain.com</span></span><br><span class="line"><span class="string">    http:</span></span><br><span class="line"><span class="string">      paths:</span></span><br><span class="line"><span class="string">      - backend:</span></span><br><span class="line"><span class="string">          serviceName: test-api</span></span><br><span class="line"><span class="string">          servicePort: 80</span></span><br><span class="line"><span class="string">        path: /</span></span><br><span class="line"><span class="string">status:</span></span><br><span class="line"><span class="string">  loadBalancer: &#123;&#125;</span></span><br></pre></td></tr></table></figure><ul><li>more_set_headers 用于添加、修改、清除响应头</li><li>more_clear_headers 用于清除响应头</li><li>more_set_input_headers 用于添加、修改、清除请求头</li><li>more_clear_input_headers 用于清除请求头</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在ningx-ingress中内置提供一些&lt;code&gt;annotation&lt;/code&gt; 在不手动手动改&lt;code&gt;ingress-controller&lt;/code&gt;的情况下可以提供一些方便的操作。&lt;/p&gt;
&lt;figure class=&quot;highlight yml&quot;&gt;&lt;ta
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/tags/kubernetes/"/>
    
      <category term="ingress" scheme="https://peachyy.gitee.io/tags/ingress/"/>
    
  </entry>
  
  <entry>
    <title>在k8s中收集jvm异常dump文件到OSS</title>
    <link href="https://peachyy.gitee.io/2021/11/11/k8s-jvm-dumpcollect/"/>
    <id>https://peachyy.gitee.io/2021/11/11/k8s-jvm-dumpcollect/</id>
    <published>2021-11-10T16:00:00.000Z</published>
    <updated>2023-03-25T06:01:37.757Z</updated>
    
    <content type="html"><![CDATA[<h4 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h4><p>  加参数 <code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/test.dump</code> 可以实现在<code>jvm</code>发生内存错误后 会生成dump文件 方便开发人员分析异常原因。</p><p>  当运行在k8s中，如果进程发生错误 导出dump文件后 ，k8s会重启dokcer容器，上一次崩溃生成的dump文件就没有了。如果应用并没有完全崩溃 此时极其不稳定 最好也能通知到技术人员来处理。这样不方便我们排查原因 所有写了一个小工具。大概原理如下</p><p>  1、 <code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/test.dump</code>   当发生内存错误的时候 导出堆文件<br>  2、 <code>-XX:OnOutOfMemoryError=./dumpError.sh</code>   当发生内存溢出的时候，让JVM调用一个shell脚本 这个shell脚本可以做一些资源整理操作 比如kill掉当前进程并重启</p><p>  依赖上面2点<code>jvm</code>特性 就能做到把dump文件收集起来 是通知技术人员也好(比如发送订单、短信报警等)、然后再把dump文件上传到<code>OSS</code> 或者其他的文件存储中。 需要值得注意的是<code>-XX:OnOutOfMemoryError=xx.sh</code> 执行的脚本不能传脚本参数，所以尽可能把参数都封装在另一个脚本中。</p><h4 id="方案实现"><a href="#方案实现" class="headerlink" title="方案实现"></a>方案实现</h4><p>基于<code>Go</code>简单的写了一个上传阿里OSS的方法  这里用其他任何语言都可以的，至于用GO的原因很简单,有第三方库可以调用、运行的机器上也不用安装sdk、比较轻量。<br>大致逻辑如下</p><p><code>jvmdump.go</code></p><p>init获取程序的输入参数</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">fmt.Println(<span class="string">"init...."</span>)</span><br><span class="line">flag.StringVar(&amp;env, <span class="string">"env"</span>, <span class="string">"test"</span>, <span class="string">"test"</span>) <span class="comment">//用于区分环境 </span></span><br><span class="line">flag.StringVar(&amp;ddtoken, <span class="string">"ddtoken"</span>, <span class="string">""</span>, <span class="string">"ddtoken"</span>) <span class="comment">//用于报警用的 钉钉机器人TOKEN</span></span><br><span class="line">flag.StringVar(&amp;dumpFile, <span class="string">"dfile"</span>, <span class="string">""</span>, <span class="string">"dfile"</span>) <span class="comment">// dump文件的地址</span></span><br><span class="line">flag.StringVar(&amp;pod, <span class="string">"pod"</span>, <span class="string">""</span>, <span class="string">"pod"</span>) <span class="comment">//k8s中的pod  只是记录一下 方便排查 </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>main函数逻辑</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"start invoke dump..."</span>)</span><br><span class="line">flag.Parse() <span class="comment">//解析输入参数</span></span><br><span class="line">fmt.Printf(<span class="string">"dumpFile %s ,env %s token %s\n"</span>,dumpFile,env,ddtoken)</span><br><span class="line">exist, err := FileExists(dumpFile) <span class="comment">//验证dump文件是否存在 只有存在的时候才去处理收集dump文件逻辑</span></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">"验证文件是否存在发生错误![%v]\n"</span>, err)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> exist &#123;</span><br><span class="line"><span class="comment">//https://help.aliyun.com/document_detail/88604.html</span></span><br><span class="line"><span class="keyword">var</span> url=uploadOSS(dumpFile) <span class="comment">//上传阿里oss</span></span><br><span class="line">fmt.Printf(<span class="string">"OSS上传完成 %s\n"</span>, url)</span><br><span class="line"><span class="keyword">if</span> enabledd&#123;</span><br><span class="line"><span class="comment">//钉钉群机器人发送工具 https://github.com/braumye/grobot </span></span><br><span class="line">notifyDD(url) <span class="comment">//通知钉钉群机器人</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">fmt.Printf(<span class="string">"dump文件不存在 %s\n"</span>,dumpFile)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构建可执行文件</p><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">set GOOS=linux</span><br><span class="line"><span class="keyword">go</span> build -ldflags <span class="string">"-w -s"</span></span><br></pre></td></tr></table></figure><p>测试 验证go脚本是否正确 </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> <span class="built_in">echo</span> <span class="string">"ffff"</span>&gt;/opt/ttt.dump</span><br><span class="line">./jvmdump -env <span class="built_in">test</span> -dfile /opt/ttt.dump</span><br></pre></td></tr></table></figure><p>如果能成功上传 就可以集成到jvm上跑了，不能成功上传的话 就需要调一下go了。</p><p>另外分享一个<code>-XX:OnOutOfMemoryError=./dumpError.sh</code> 参考。</p><p>有这个shell的原因是因为 由于<code>jvm</code>中<code>OnOutOfMemoryError</code>目前没有找到可以传递脚本参数的方法。 所有不能调用<code>./jvmdump</code>文件 故包装一下，把参数都封装在dempError.sh中 ，把所有生成的dump文件 后缀命名都设置为.dump，主要是为了方便查找。放在一个独立的目录也是可以的。</p><p><code>dumpError.sh</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#循环目录</span></span><br><span class="line">traverse_dir()</span><br><span class="line">&#123;</span><br><span class="line">    filepath=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> `ls -a <span class="variable">$filepath</span>`</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="keyword">if</span> [ -d <span class="variable">$&#123;filepath&#125;</span>/<span class="variable">$file</span> ]</span><br><span class="line">        <span class="keyword">then</span></span><br><span class="line">            <span class="keyword">if</span> [[ <span class="variable">$file</span> != <span class="string">'.'</span> &amp;&amp; <span class="variable">$file</span> != <span class="string">'..'</span> ]]</span><br><span class="line">            <span class="keyword">then</span></span><br><span class="line">                <span class="comment">#递归</span></span><br><span class="line">                traverse_dir <span class="variable">$&#123;filepath&#125;</span>/<span class="variable">$file</span></span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="comment">#调用查找指定后缀文件</span></span><br><span class="line">            check_suffix <span class="variable">$&#123;filepath&#125;</span>/<span class="variable">$file</span></span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="comment">#看需要 可以kill掉进程，避免jvm没有完全崩溃 k8s不会重启pod的情况 造成应用假死问题。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#查找指定后缀的文件 这里在k8s环境里一般只会有一个dump文件，如果可能存在多个的dump文件文件的情况 可能需要变更一下逻辑</span></span><br><span class="line">check_suffix()</span><br><span class="line">&#123;</span><br><span class="line">    file=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果找到dump就调用go写的jvmdump脚本 </span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;file##*.&#125;</span>"</span>x = <span class="string">"dump"</span>x ];<span class="keyword">then</span></span><br><span class="line">        lib/jvmdump -e <span class="built_in">test</span> -dfile <span class="variable">$file</span> -pod <span class="variable">$HOSTNAME</span> -ddtoken xxx</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line">traverse_dir /opt/logs</span><br></pre></td></tr></table></figure><p>完整代码参考</p><p><a href="https://github.com/peachyy/jvmdump2k8s.git" target="_blank" rel="noopener">https://github.com/peachyy/jvmdump2k8s.git</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;现状&quot;&gt;&lt;a href=&quot;#现状&quot; class=&quot;headerlink&quot; title=&quot;现状&quot;&gt;&lt;/a&gt;现状&lt;/h4&gt;&lt;p&gt;  加参数 &lt;code&gt;-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/test
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="jvm" scheme="https://peachyy.gitee.io/tags/jvm/"/>
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/tags/kubernetes/"/>
    
      <category term="alpine" scheme="https://peachyy.gitee.io/tags/alpine/"/>
    
      <category term="dump" scheme="https://peachyy.gitee.io/tags/dump/"/>
    
  </entry>
  
  <entry>
    <title>基于alpine构建jdk镜像遇到的坑</title>
    <link href="https://peachyy.gitee.io/2021/11/10/alpinejdkimage/"/>
    <id>https://peachyy.gitee.io/2021/11/10/alpinejdkimage/</id>
    <published>2021-11-09T16:00:00.000Z</published>
    <updated>2021-11-10T10:13:26.016Z</updated>
    
    <content type="html"><![CDATA[<p><code>alpine</code>常用于作为<code>docker</code>的基础镜像，因为它很小，功能精简，基本上没有啥漏洞，记录一下最近用<code>alpine</code>作为基础镜像构建<code>java 8</code>镜像 下面的问题在<code>oracle jdk</code> <code>openjdk</code>都会出现 。</p><h4 id="错误一"><a href="#错误一" class="headerlink" title="错误一"></a>错误一</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.NoClassDefFoundError: Could not initialize <span class="class"><span class="keyword">class</span> <span class="title">sun</span>.<span class="title">awt</span>.<span class="title">X11FontManager</span></span></span><br></pre></td></tr></table></figure><p>这个错误一般出现在生成验证码绘制的时候，这个错误大概原因就是由于在<code>alpine</code>上太过于精简了，导致初始化<code>FontManagerFactory</code>工厂初始化失败，那么解决办法就是安装<code>glibc</code>。<br>网上有很多博主都只讲安装了<code>glib.apk</code> 核心包就行，其实这里需要安装3个包 以<code>2.3.0</code>为例 需要安装的包为</p><ul><li><a href="https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk" target="_blank" rel="noopener">https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk</a></li><li><a href="https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk" target="_blank" rel="noopener">https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk</a></li><li><a href="https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk" target="_blank" rel="noopener">https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk</a></li></ul><p>安装命令如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line">   apk --no-cache add libstdc++ ca-certificates bash  wget</span><br><span class="line">wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub</span><br><span class="line">wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk</span><br><span class="line">wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk</span><br><span class="line">wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk</span><br><span class="line">apk add glibc-2.30-r0.apk &amp;&amp; apk add glibc-bin-2.30-r0.apk &amp;&amp; apk add glibc-i18n-2.30-r0.apk</span><br></pre></td></tr></table></figure><p>安装完后就没有问题了，测试方法 可以写一个main方法在容器中验证是否能执行通过<code>Class.forName(&quot;sun.awt.X11FontManager&quot;);</code>,当在验证码不可行环境的时候 报错的消息为 </p><p><code>/usr/local/jdk1.8.0_301/jre/lib/amd64/libfontmanager.so: libgcc_s.so.1: cann......</code>。</p><p>还有就是可以进入在运行中的容器直接安装 安装完成了之后基本上就没有问题了。</p><h4 id="错误二"><a href="#错误二" class="headerlink" title="错误二"></a>错误二</h4><p>   该错误在openJDK中出现过，OracleJDK没有出现。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">error while loading shared libraries: libz.so.1: cannot open shared object file:</span><br></pre></td></tr></table></figure><p>解决方式就安装zlib 安装命令如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">curl -Ls https://archive.archlinux.org/packages/z/zlib/zlib-1%3A1.2.9-1-x86_64.pkg.tar.xz -o libz.tar.xz &amp;&amp; mkdir -p libz &amp;&amp; tar -xf libz.tar.xz -C libz</span><br><span class="line"></span><br><span class="line">mv libz/usr/lib/libz.so* /usr/glibc-compat/lib</span><br><span class="line"></span><br><span class="line">rm -rf libz.tar.xz</span><br></pre></td></tr></table></figure><p>安装好后 没有问题了</p><h4 id="dragonwell-openjdk-Dockerfile"><a href="#dragonwell-openjdk-Dockerfile" class="headerlink" title="dragonwell openjdk Dockerfile"></a>dragonwell openjdk Dockerfile</h4><p>另贴上基于<code>alpine</code>的阿里<code>dragonwell openjdk</code>的Dockerfile</p><p>dragonwell JDK Dockerfile</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">FROM alpine:3.8</span><br><span class="line">LABEL maintainer="xstao"</span><br><span class="line">ENV TZ=Asia/Shanghai</span><br><span class="line">RUN ln -snf /usr/share/zoneinfo/$&#123;TZ&#125; /etc/localtime &amp;&amp; \</span><br><span class="line">    echo $&#123;TZ&#125; &gt; /etc/timezone</span><br><span class="line"><span class="meta">#</span><span class="bash">mirrons aliun</span></span><br><span class="line">RUN echo http://mirrors.aliyun.com/alpine/v3.10/main/ &gt; /etc/apk/repositories &amp;&amp; \</span><br><span class="line">    echo http://mirrors.aliyun.com/alpine/v3.10/community/ &gt;&gt; /etc/apk/repositories</span><br><span class="line">    RUN apk update &amp;&amp; apk upgrade</span><br><span class="line"><span class="meta">#</span><span class="bash">install glibc</span></span><br><span class="line">RUN apk --no-cache add libstdc++ ca-certificates bash  wget curl  &amp;&amp; \</span><br><span class="line">    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub  &amp;&amp; \</span><br><span class="line">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk &amp;&amp; \</span><br><span class="line">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk &amp;&amp; \</span><br><span class="line">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk &amp;&amp; \</span><br><span class="line">    apk add glibc-2.30-r0.apk &amp;&amp; apk add glibc-bin-2.30-r0.apk &amp;&amp; apk add glibc-i18n-2.30-r0.apk &amp;&amp; \</span><br><span class="line">    curl -Ls https://archive.archlinux.org/packages/z/zlib/zlib-1%3A1.2.9-1-x86_64.pkg.tar.xz -o libz.tar.xz &amp;&amp; mkdir -p libz &amp;&amp; tar -xf libz.tar.xz -C libz &amp;&amp; \</span><br><span class="line">    mv libz/usr/lib/libz.so* /usr/glibc-compat/lib &amp;&amp; \</span><br><span class="line">    rm glibc-2.30-r0.apk &amp;&amp; rm glibc-bin-2.30-r0.apk &amp;&amp; rm glibc-i18n-2.30-r0.apk &amp;&amp; rm -rf /var/cache/apk/* &amp;&amp; rm -rf libz/* &amp;&amp;  rm -rf libz.tar.xz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RUN apk add --update font-adobe-100dpi ttf-dejavu fontconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ENV JAVA_VERSION="jdk8u302-b01"</span><br><span class="line">ENV JAVA_HOME="/usr/local/$&#123;JAVA_VERSION&#125;"</span><br><span class="line"></span><br><span class="line">ENV PATH="$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125;"</span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">WORKDIR /opt</span><br><span class="line">RUN wget https://dragonwell.oss-cn-shanghai.aliyuncs.com/8.8.9/Alibaba_Dragonwell_8.8.9_x64_linux.tar.gz</span><br><span class="line">RUN tar -zxf Alibaba_Dragonwell_8.8.9_x64_linux.tar.gz</span><br><span class="line">RUN mv $&#123;JAVA_VERSION&#125; /usr/local</span><br><span class="line">RUN rm -rf Alibaba_Dragonwell_8.8.9_x64_linux.tar.gz</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;alpine&lt;/code&gt;常用于作为&lt;code&gt;docker&lt;/code&gt;的基础镜像，因为它很小，功能精简，基本上没有啥漏洞，记录一下最近用&lt;code&gt;alpine&lt;/code&gt;作为基础镜像构建&lt;code&gt;java 8&lt;/code&gt;镜像 下面的问题在&lt;code&gt;
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="alpine" scheme="https://peachyy.gitee.io/tags/alpine/"/>
    
      <category term="jdk" scheme="https://peachyy.gitee.io/tags/jdk/"/>
    
  </entry>
  
  <entry>
    <title>docker删除&lt;none&gt;标签镜像</title>
    <link href="https://peachyy.gitee.io/2021/08/23/dockerimage-prune/"/>
    <id>https://peachyy.gitee.io/2021/08/23/dockerimage-prune/</id>
    <published>2021-08-22T16:00:00.000Z</published>
    <updated>2021-08-23T08:42:31.705Z</updated>
    
    <content type="html"><![CDATA[<p>被打上<code>&lt;none&gt;</code>标签的镜像指的是没有标签并且没有被容器使用的镜像。<br>如果不清理这种镜像会大量占用机器磁盘。记录2种自身工作中常用的删除方法。</p><h4 id="第一种删除方式"><a href="#第一种删除方式" class="headerlink" title="第一种删除方式"></a>第一种删除方式</h4><p>执行下面shell 并输入<code>y</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker image prune</span><br></pre></td></tr></table></figure><h4 id="第二种方式删除"><a href="#第二种方式删除" class="headerlink" title="第二种方式删除"></a>第二种方式删除</h4><p> 利用<code>awk</code>来获取镜像id 执行<code>docker rmi</code>删除</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker rmi $(docker images | grep "none" | awk '&#123;print $3&#125;')</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;被打上&lt;code&gt;&amp;lt;none&amp;gt;&lt;/code&gt;标签的镜像指的是没有标签并且没有被容器使用的镜像。&lt;br&gt;如果不清理这种镜像会大量占用机器磁盘。记录2种自身工作中常用的删除方法。&lt;/p&gt;
&lt;h4 id=&quot;第一种删除方式&quot;&gt;&lt;a href=&quot;#第一种删除方式&quot; cla
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="docker" scheme="https://peachyy.gitee.io/tags/docker/"/>
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes之pod</title>
    <link href="https://peachyy.gitee.io/2021/08/09/k8s-pod/"/>
    <id>https://peachyy.gitee.io/2021/08/09/k8s-pod/</id>
    <published>2021-08-08T16:00:00.000Z</published>
    <updated>2021-08-09T05:52:10.939Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/tags/kubernetes/"/>
    
      <category term="pod" scheme="https://peachyy.gitee.io/tags/pod/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes-kubeadm创建集群</title>
    <link href="https://peachyy.gitee.io/2021/08/05/k8s-kubeadm-init-2/"/>
    <id>https://peachyy.gitee.io/2021/08/05/k8s-kubeadm-init-2/</id>
    <published>2021-08-04T16:00:00.000Z</published>
    <updated>2021-08-05T05:40:56.172Z</updated>
    
    <content type="html"><![CDATA[<p>这一节基本上会遇到很多异常错误信息，需要耐心的去解决它，跟环境等很多因素有关系。</p><h4 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h4><p>在master 机器上初始化集群 会自动拉取相关的镜像 需要等待一下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm init --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.213</span><br></pre></td></tr></table></figure><p>正常情况下 这里会报错，[ERROR ImagePull]: failed to pull image registry.aliyuncs.com/google_containers/coredns:v1.8.0: output: Error response from daemon: manifest for registry.aliyuncs.com/google_containers/coredns:v1.8.0 not found: manifest unknown: manifest unknown</p><p>原因是 期望自动下载的镜像为 <code>registry.aliyuncs.com/google_containers/coredns:v1.8.0</code>，然后仓库中并这个容器镜像，查了资料可以手动下载指定版本号的时候把<code>v</code>去掉即可，下载后并重命名一下版本号</p><p>手动拉取镜像</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">下载</span><br><span class="line"><span class="meta">#</span><span class="bash">docker pull registry.aliyuncs.com/google_containers/coredns:1.8.0</span></span><br><span class="line">重命名</span><br><span class="line"><span class="meta">#</span><span class="bash">docker tag registry.aliyuncs.com/google_containers/coredns:1.8.0 registry.aliyuncs.com/google_containers/coredns:v1.8.0</span></span><br></pre></td></tr></table></figure><p>然后再执行 <code>kubeadm init --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.213</code> 就不会报错了。执行完成后打印<br>执行完成后打印<code>Your Kubernetes control-plane has initialized successfully!</code>表示已经成功初始化。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><p>在初始化结果日志中还打印了加入集群的令牌(token),令牌用于控制平面节点和加入节点之间的相互身份验证。 这里包含的令牌是密钥。确保它的安全， 因为拥有此令牌的任何人都可以将经过身份验证的节点添加到你的集群中。</p><h4 id="节点加入集群"><a href="#节点加入集群" class="headerlink" title="节点加入集群"></a>节点加入集群</h4><p>在work机器上执行加入节点到机器操作 要保证work机器上要能和master网络保持畅通,直接复制init 命令日志中最后一段话命令就行。<br>加入的时候要保证work节点上的docker服务是开启的。不然要报错。<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.0.213:6443 --token 5aqi11.werqxkrz4e46vnih --discovery-token-ca-cert-hash sha256:4794a2e13e2c566070d6b289981abb267a0fce1dbf78d60c21db618719d764e7</span><br></pre></td></tr></table></figure></p><p>加入成功后在master上执行<code>kubectl get nodes</code>会发现多了一个节点 但是状态是NotReady，这是不同的机器上容器内部网络不互通 接下来就来整一下网络。</p><h4 id="网络模型插件"><a href="#网络模型插件" class="headerlink" title="网络模型插件"></a>网络模型插件</h4><p> 目前<code>Kubernetes</code>比较常用的网络组建 主要是<code>flannel</code>、<code>Calico</code> 这里我们选用<code>flannel</code>做网络模型。安装方法也就是允许容器 还是比较方便。需要在<code>master</code>上执行</p><p> 下载yml文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><p>在集群中运行容器<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply  -f kube-flannel.yml</span><br></pre></td></tr></table></figure></p><p>这里可能会遇到很多问题，安装好网络插件了 怎么节点还是NotReady状态呢？这些就要对问题进行进一步排查了。这个命令可以看到node上一些问题<code>journalctl -u kubelet -n 300</code>.<br>节点还是依然处理NotReady，就可能是环境有什么问题了，在Master上执行<code>kubectl describe node test1</code> test1为状态异常的节点名称，就能看到这个节点当前的调度操作日志。比如这次有一台work机器日志显示为<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Normal  Starting                 18s                kubelet  Starting kubelet.</span><br><span class="line">Normal  NodeHasSufficientPID     1s                 kubelet  Node test1 status is now: NodeHasSufficientPID</span><br><span class="line">Normal  Starting                 1s                 kubelet  Starting kubelet.</span><br><span class="line">Normal  NodeHasSufficientMemory  1s                 kubelet  Node test1 status is now: NodeHasSufficientMemory</span><br><span class="line">Normal  NodeHasNoDiskPressure    1s                 kubelet  Node test1 status is now: NodeHasNoDiskPressure</span><br></pre></td></tr></table></figure></p><p> 能看到一些有用的信息 如 磁盘空间不足。</p><p> 出现了异常 看哪些命令没有启动成功 可以参考以下的命令日志</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">journalctl -l -u kube-apiserver</span><br><span class="line">journalctl -l -u kube-controller-manager</span><br><span class="line">journalctl -l -u kube-scheduler</span><br><span class="line">journalctl -l -u kubelet</span><br><span class="line">journalctl -l -u kube-proxy</span><br></pre></td></tr></table></figure><p>如果节点状态都为<code>Ready</code> 那真是太幸运了。安装好网络插件后 一般要等待1-2分钟才会变为Ready，接下来就可能把应用部署在k8s集群中去。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这一节基本上会遇到很多异常错误信息，需要耐心的去解决它，跟环境等很多因素有关系。&lt;/p&gt;
&lt;h4 id=&quot;初始化集群&quot;&gt;&lt;a href=&quot;#初始化集群&quot; class=&quot;headerlink&quot; title=&quot;初始化集群&quot;&gt;&lt;/a&gt;初始化集群&lt;/h4&gt;&lt;p&gt;在master 机器
      
    
    </summary>
    
      <category term="技术" scheme="https://peachyy.gitee.io/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="技术" scheme="https://peachyy.gitee.io/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="kubernetes" scheme="https://peachyy.gitee.io/tags/kubernetes/"/>
    
  </entry>
  
</feed>
