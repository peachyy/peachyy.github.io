[{"title":"kafka listener配置解决Server与消费端不在同一网络问题","date":"2022-05-23T16:00:00.000Z","path":"2022/05/24/kafka-listeners-advertised/","text":"在kubernetes容器环境下 kafka会默认把主机名注册到zookeeper。这个时候消费端部署在不同的命名空间或者不同的集群中会出现无法访问的情况。用advertised.listeners配置可以重写默认注册的地址。 定义listeners listeners 配置的是kafka Server 的tcp侦听ip地址。 advertised.listeners 该配置主要是用于把Broker的ip地址信息发布到Zookeeper中，简而言之就是配置的kafka的broker ip。如果你的消费端需要不同集群/网段的访问 需要确保改地址该消费端可访问的地址 其他这个也不一定是在容器环境下会存在 常规的机器环境下也会出现这个问题 如果broker的ip消费端访问不到的情况下 像下面这个异常 可以查一下这个问题。 java.net.UnknownHostException: cep-kafka at java.net.InetAddress.getAllByName0(InetAddress.java:1281) at java.net.InetAddress.getAllByName(InetAddress.java:1193) at java.net.InetAddress.getAllByName(InetAddress.java:1127)","tags":[{"name":"kafka","slug":"kafka","permalink":"https://blog.gitee.io/tags/kafka/"}]},{"title":"使用certbot制作免费Lets encrypt SSL证书","date":"2022-04-06T16:00:00.000Z","path":"2022/04/07/letsencrypt-certbot-ssl/","text":"利用certbot软件包可以免费制作SSL证书 这对小网站和测试项目太有用了，下面记录一下制作证书的流程和方法。以备后用。以centos7系统为例 其他系统类似。 安装certbotyum install -y epel-releaseyum install -y certbot 准备环境 制作证书前需要先准备好域名的访问环境，因为制作证书的时候需要确认域名和服务器的所有权。 1、dns验证 dns验证需要加参数 --preferred-challenges dns 来定义，主要就是配置域名的txt记录即可。 下面主要是用单机验证方式。 2、服务器文件验证 需要服务器开放80端口、配置nginx的静态文件访问目录。但是需要制定 webroot参数来路径，会生成一个文件,然后访问这个文件是否能成功访问到。 成功则验证通过 3、单机生成 不需要额外的支持 命令加--standalone来指定 需要关闭nginx或者apache才能执行。 创建证书certbot certonly --standalone -d xxx.test.com -m taoxxx@foxmail.com --agree-tos 这一步可能有环境问题报错的情况 自行百度解决。如果出现 Problem binding to port 80: Could not bind to IPv4 or IPv6. 这种错误 可以把nginx或者apache关了再重新执行上面生成证书的命令 生成成功后会输入下面提示，打印了证书的路径在/etc/letsencrypt/live/xxx.test.com/，过期时间为90天，以及续期的命令。 IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/xxx.test.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/xxx.test.com/privkey.pem Your certificate will expire on 2022-07-06. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 配置nginxserver &#123; listen 443 ssl http2; server_name xxx.test.com; client_max_body_size 1024M; proxy_connect_timeout 600; proxy_send_timeout 600; proxy_read_timeout 600; send_timeout 600; keepalive_timeout 4800; index index.html; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_prefer_server_ciphers on; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_certificate /etc/letsencrypt/live/xxx.test.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/xxx.test.com/privkey.pem; ....省略&#125; 重启nginx 用https访问服务可以看见浏览器的一个小锁就表示https证书部署成功了。 续期因为这个免费证书只有90天的有效期，到了就需要续期才能继续使用，目前只能手动续期 执行命令 certbot renew。但是可以用定时任务的方式每天续费一次 好像也可以一劳永逸。 crontab -e 0 */6 * * * certbot renew --quiet &amp;&amp; nginx -s reload 其他证书操作1、查看已经生成的证书 `certbot certificates` 2、吊销证书 certbot revoke --cert-path &quot;/etc/letsencrypt/live/xxx.test.com/cert.pem&quot; 由于环境的不同 会遇到各种坑 用docker的方式来创建和续期是可复制性最高的。 参考https://github.com/wmnnd/nginx-certbothttps://github.com/JonasAlfredsson/docker-nginx-certbot","tags":[{"name":"certbot","slug":"certbot","permalink":"https://blog.gitee.io/tags/certbot/"},{"name":"Lets encrypt","slug":"Lets-encrypt","permalink":"https://blog.gitee.io/tags/Lets-encrypt/"}]},{"title":"MySql SSL CA证书JDBC配置","date":"2022-01-25T16:00:00.000Z","path":"2022/01/26/mysql-ssl-ca-jdbc/","text":"开启MySql数据库SSL证书以后 如何在jdbc中配置证书访问呢？关于数据库如何配置SSL证书自行百度 这里演示客户端如何利用证书来进行数据通讯。开启证书jdbc认证后 肯定是有一定的性能开销的，个人觉得内网环境无需配置CA证书校验。 下面用一个示例来演示如何配置 未配置证书访问前 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/sslcatestdb?zeroDateTimeBehavior=convertToNull&amp;characterEncoding=utf-8 配置了证书访问后 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/sslcatestdb?zeroDateTimeBehavior=convertToNull&amp;characterEncoding=utf-8useSSL=true&amp;trustCertificateKeyStoreUrl=file:/证书路径&amp;trustCertificateKeyStoreType=证书类型&amp;trustCertificateKeyStorePassword=证书密码&amp;clientCertificateKeyStoreUrl=file:/证书路径&amp;clientCertificateKeyStoreType=证书类型&amp;clientCertificateKeyStorePassword=证书密码&amp;verifyServerCertificate=true 证书相关配置属性 useSSL 开启ssl trustCertificateKeyStoreUrl 服务端证书路径 trustCertificateKeyStoreType 服务端证书类型 trustCertificateKeyStorePassword 服务端证书密码 clientCertificateKeyStoreUrl 客户端证书路径 clientCertificateKeyStoreType 客户端证书类型 clientCertificateKeyStorePassword 客户端证书密码 verifyServerCertificate 信任验证服务器证书 参考 https://dev.mysql.com/doc/connector-j/8.0/en/connector-j-connp-props-security.html","tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.gitee.io/tags/mysql/"},{"name":"sslca","slug":"sslca","permalink":"https://blog.gitee.io/tags/sslca/"}]},{"title":"jvm容器化内存感知实践","date":"2021-12-27T16:00:00.000Z","path":"2021/12/28/dockerjvmarg_action/","text":"docker容器本身需要设置容器的最大可使用内存(防止单个容器消耗节点大量的资源)，跑在容器中的jvm进程也需要设置内存，防止内存占用过大被容器Kill,所以如何优雅的在容器化中设置内存是一个很有必要了解的话题。 jdk 8u131+ java 9+ 使用参数开启实验性功能 -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap。 开启容器化支持功能。 java 8u191+ java10+ 使用参数UseContainerSupport 开启容器化感知支持功能。 -XX:MaxRAMPercentage 限制最大heap内存占比 。 -XX:InitialRAMPercentage 设置初始heap内存占比，此参数如果和MaxRAMPercentage设置一样表示jvm最大与最小一致 jvm不会去伸缩内存 这也是一种普遍使用的方式。其值介于0.0到100.0之间，默认值为25。 上面的几个参数可以让jvm读取cgroup的一些数据，并进行相应的适配，这样容器内jvm超时最大内存 就自己会OOM而不是被容器Kill。关于被OOM后怎么怎么拉取以及存储OOM文件参考 在k8s中收集jvm异常dump文件到OSS 案例以下案例已设置了容器最大可实现内存4G CPU 1核 使用参数 限制heap最大内存为80% java -server -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMPercentage=80.0 .... 使用jmap查看heap内存情况 显示MaxHeapSize为3278mb 刚好为(4*1021)/0.8 说明jvm能感知到容器最大内存为4g 且只能分配80%的内存给heap。剩余的20%供其他的进程使用。 jmap -heap 19 Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 3437232128 (3278.0MB) NewSize = 22020096 (21.0MB) MaxNewSize = 1145569280 (1092.5MB) OldSize = 45088768 (43.0MB) NewRatio = 2 SurvivorRatio = 8 MetaspaceSize = 21807104 (20.796875MB) CompressedClassSpaceSize = 1073741824 (1024.0MB) MaxMetaspaceSize = 17592186044415 MB G1HeapRegionSize = 0 (0.0MB) JDK8+可以使用-XX:MetaspaceSize和-XX:MaxMetaspaceSize设置元空间初始大小以及最大可分配大小。默认情况下，元空间最大的大小是系统内存的大小，该参数一般默认也无所谓 一般不会因为这个太大导致OOM。这也证明了在容器中获取到的内存是宿主机的内存大小而不是设置了容器限制后的大小。","tags":[{"name":"docker","slug":"docker","permalink":"https://blog.gitee.io/tags/docker/"},{"name":"jvm","slug":"jvm","permalink":"https://blog.gitee.io/tags/jvm/"},{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"k8s","slug":"k8s","permalink":"https://blog.gitee.io/tags/k8s/"}]},{"title":"ingress传递头信息","date":"2021-12-21T16:00:00.000Z","path":"2021/12/22/k8s-ingress-annotation1/","text":"在ningx-ingress中内置提供一些annotation 在不手动手动改ingress-controller的情况下可以提供一些方便的操作。 apiVersion: extensions/v1beta1kind: Ingressmetadata: annotations: kubectl.kubernetes.io/last-applied-configuration: \"\" nginx.ingress.kubernetes.io/proxy-body-size: 50m nginx.ingress.kubernetes.io/service-weight: 'show-admin: 100 nginx.ingress.kubernetes.io/server-snippet: | set sub_domain \"\"; if ( host ~* (.*)-admin.* )&#123; set sub_domain saas1; &#125; nginx.ingress.kubernetes.io/configuration-snippet: | more_set_input_headers \"auth-com: saas$1\"; generation: 4 name: test-ingress namespace: defaultspec: rules: - host: test.domain.com http: paths: - backend: serviceName: test-api servicePort: 80 path: /status: loadBalancer: &#123;&#125; more_set_headers 用于添加、修改、清除响应头 more_clear_headers 用于清除响应头 more_set_input_headers 用于添加、修改、清除请求头 more_clear_input_headers 用于清除请求头","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"k8s","slug":"k8s","permalink":"https://blog.gitee.io/tags/k8s/"},{"name":"ingress","slug":"ingress","permalink":"https://blog.gitee.io/tags/ingress/"}]},{"title":"在k8s中收集jvm异常dump文件到OSS","date":"2021-11-10T16:00:00.000Z","path":"2021/11/11/k8s-jvm-dumpcollect/","text":"现状 加参数 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/test.dump 可以实现在jvm发生内存错误后 会生成dump文件 方便开发人员分析异常原因。 当运行在k8s中，如果进程发生错误 导出dump文件后 ，k8s会重启dokcer容器，上一次崩溃生成的dump文件就没有了。如果应用并没有完全崩溃 此时极其不稳定 最好也能通知到技术人员来处理。这样不方便我们排查原因 所有写了一个小工具。大概原理如下 1、 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=logs/test.dump 当发生内存错误的时候 导出堆文件 2、 -XX:OnOutOfMemoryError=./dumpError.sh 当发生内存溢出的时候，让JVM调用一个shell脚本 这个shell脚本可以做一些资源整理操作 比如kill掉当前进程并重启 依赖上面2点jvm特性 就能做到把dump文件收集起来 是通知技术人员也好(比如发送订单、短信报警等)、然后再把dump文件上传到OSS 或者其他的文件存储中。 需要值得注意的是-XX:OnOutOfMemoryError=xx.sh 执行的脚本不能传脚本参数，所以尽可能把参数都封装在另一个脚本中。 方案实现基于Go简单的写了一个上传阿里OSS的方法 这里用其他任何语言都可以的，至于用GO的原因很简单,有第三方库可以调用、运行的机器上也不用安装sdk、比较轻量。大致逻辑如下 jvmdump.go init获取程序的输入参数 func init()&#123; fmt.Println(\"init....\") flag.StringVar(&amp;env, \"env\", \"test\", \"test\") //用于区分环境 flag.StringVar(&amp;ddtoken, \"ddtoken\", \"\", \"ddtoken\") //用于报警用的 钉钉机器人TOKEN flag.StringVar(&amp;dumpFile, \"dfile\", \"\", \"dfile\") // dump文件的地址 flag.StringVar(&amp;pod, \"pod\", \"\", \"pod\") //k8s中的pod 只是记录一下 方便排查 &#125; main函数逻辑 func main() &#123; fmt.Println(\"start invoke dump...\") flag.Parse() //解析输入参数 fmt.Printf(\"dumpFile %s ,env %s token %s\\n\",dumpFile,env,ddtoken) exist, err := FileExists(dumpFile) //验证dump文件是否存在 只有存在的时候才去处理收集dump文件逻辑 if err != nil &#123; fmt.Printf(\"验证文件是否存在发生错误![%v]\\n\", err) return &#125; if exist &#123; //https://help.aliyun.com/document_detail/88604.html var url=uploadOSS(dumpFile) //上传阿里oss fmt.Printf(\"OSS上传完成 %s\\n\", url) if enabledd&#123; //钉钉群机器人发送工具 https://github.com/braumye/grobot notifyDD(url) //通知钉钉群机器人 &#125; &#125;else&#123; fmt.Printf(\"dump文件不存在 %s\\n\",dumpFile) &#125;&#125; 构建可执行文件 set GOOS=linuxgo build -ldflags \"-w -s\" 测试 验证go脚本是否正确 echo \"ffff\"&gt;/opt/ttt.dump./jvmdump -env test -dfile /opt/ttt.dump 如果能成功上传 就可以集成到jvm上跑了，不能成功上传的话 就需要调一下go了。 另外分享一个-XX:OnOutOfMemoryError=./dumpError.sh 参考。 有这个shell的原因是因为 由于jvm中OnOutOfMemoryError目前没有找到可以传递脚本参数的方法。 所有不能调用./jvmdump文件 故包装一下，把参数都封装在dempError.sh中 ，把所有生成的dump文件 后缀命名都设置为.dump，主要是为了方便查找。放在一个独立的目录也是可以的。 dumpError.sh #!/bin/bash#循环目录traverse_dir()&#123; filepath=$1 for file in `ls -a $filepath` do if [ -d $&#123;filepath&#125;/$file ] then if [[ $file != '.' &amp;&amp; $file != '..' ]] then #递归 traverse_dir $&#123;filepath&#125;/$file fi else #调用查找指定后缀文件 check_suffix $&#123;filepath&#125;/$file fi done #看需要 可以kill掉进程，避免jvm没有完全崩溃 k8s不会重启pod的情况 造成应用假死问题。&#125;#查找指定后缀的文件 这里在k8s环境里一般只会有一个dump文件，如果可能存在多个的dump文件文件的情况 可能需要变更一下逻辑check_suffix()&#123; file=$1 #如果找到dump就调用go写的jvmdump脚本 if [ \"$&#123;file##*.&#125;\"x = \"dump\"x ];then lib/jvmdump -e test -dfile $file -pod $HOSTNAME -ddtoken xxx fi&#125;traverse_dir /opt/logs 完整代码参考 https://github.com/peachyy/jvmdump2k8s.git","tags":[{"name":"jvm","slug":"jvm","permalink":"https://blog.gitee.io/tags/jvm/"},{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"alpine","slug":"alpine","permalink":"https://blog.gitee.io/tags/alpine/"},{"name":"k8s","slug":"k8s","permalink":"https://blog.gitee.io/tags/k8s/"},{"name":"dump","slug":"dump","permalink":"https://blog.gitee.io/tags/dump/"}]},{"title":"基于alpine构建jdk镜像遇到的坑","date":"2021-11-09T16:00:00.000Z","path":"2021/11/10/alpinejdkimage/","text":"alpine常用于作为docker的基础镜像，因为它很小，功能精简，基本上没有啥漏洞，记录一下最近用alpine作为基础镜像构建java 8镜像 下面的问题在oracle jdk openjdk都会出现 。 错误一java.lang.NoClassDefFoundError: Could not initialize class sun.awt.X11FontManager 这个错误一般出现在生成验证码绘制的时候，这个错误大概原因就是由于在alpine上太过于精简了，导致初始化FontManagerFactory工厂初始化失败，那么解决办法就是安装glibc。网上有很多博主都只讲安装了glib.apk 核心包就行，其实这里需要安装3个包 以2.3.0为例 需要安装的包为 https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk 安装命令如下 apk --no-cache add libstdc++ ca-certificates bash wgetwget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pubwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apkwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apkwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apkapk add glibc-2.30-r0.apk &amp;&amp; apk add glibc-bin-2.30-r0.apk &amp;&amp; apk add glibc-i18n-2.30-r0.apk 安装完后就没有问题了，测试方法 可以写一个main方法在容器中验证是否能执行通过Class.forName(&quot;sun.awt.X11FontManager&quot;);,当在验证码不可行环境的时候 报错的消息为 /usr/local/jdk1.8.0_301/jre/lib/amd64/libfontmanager.so: libgcc_s.so.1: cann......。 还有就是可以进入在运行中的容器直接安装 安装完成了之后基本上就没有问题了。 错误二 该错误在openJDK中出现过，OracleJDK没有出现。 error while loading shared libraries: libz.so.1: cannot open shared object file: 解决方式就安装zlib 安装命令如下 curl -Ls https://archive.archlinux.org/packages/z/zlib/zlib-1%3A1.2.9-1-x86_64.pkg.tar.xz -o libz.tar.xz &amp;&amp; mkdir -p libz &amp;&amp; tar -xf libz.tar.xz -C libzmv libz/usr/lib/libz.so* /usr/glibc-compat/librm -rf libz.tar.xz 安装好后 没有问题了 dragonwell openjdk Dockerfile另贴上基于alpine的阿里dragonwell openjdk的Dockerfile dragonwell JDK Dockerfile FROM alpine:3.8LABEL maintainer=\"xstao\"ENV TZ=Asia/ShanghaiRUN ln -snf /usr/share/zoneinfo/$&#123;TZ&#125; /etc/localtime &amp;&amp; \\ echo $&#123;TZ&#125; &gt; /etc/timezone#mirrons aliunRUN echo http://mirrors.aliyun.com/alpine/v3.10/main/ &gt; /etc/apk/repositories &amp;&amp; \\ echo http://mirrors.aliyun.com/alpine/v3.10/community/ &gt;&gt; /etc/apk/repositories RUN apk update &amp;&amp; apk upgrade#install glibcRUN apk --no-cache add libstdc++ ca-certificates bash wget curl &amp;&amp; \\ wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-2.30-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-bin-2.30-r0.apk &amp;&amp; \\ wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.30-r0/glibc-i18n-2.30-r0.apk &amp;&amp; \\ apk add glibc-2.30-r0.apk &amp;&amp; apk add glibc-bin-2.30-r0.apk &amp;&amp; apk add glibc-i18n-2.30-r0.apk &amp;&amp; \\ curl -Ls https://archive.archlinux.org/packages/z/zlib/zlib-1%3A1.2.9-1-x86_64.pkg.tar.xz -o libz.tar.xz &amp;&amp; mkdir -p libz &amp;&amp; tar -xf libz.tar.xz -C libz &amp;&amp; \\ mv libz/usr/lib/libz.so* /usr/glibc-compat/lib &amp;&amp; \\ rm glibc-2.30-r0.apk &amp;&amp; rm glibc-bin-2.30-r0.apk &amp;&amp; rm glibc-i18n-2.30-r0.apk &amp;&amp; rm -rf /var/cache/apk/* &amp;&amp; rm -rf libz/* &amp;&amp; rm -rf libz.tar.xzRUN apk add --update font-adobe-100dpi ttf-dejavu fontconfigENV JAVA_VERSION=\"jdk8u302-b01\"ENV JAVA_HOME=\"/usr/local/$&#123;JAVA_VERSION&#125;\"ENV PATH=\"$&#123;JAVA_HOME&#125;/bin:$&#123;PATH&#125;\"# WORKDIR /optRUN wget https://dragonwell.oss-cn-shanghai.aliyuncs.com/8.8.9/Alibaba_Dragonwell_8.8.9_x64_linux.tar.gzRUN tar -zxf Alibaba_Dragonwell_8.8.9_x64_linux.tar.gzRUN mv $&#123;JAVA_VERSION&#125; /usr/localRUN rm -rf Alibaba_Dragonwell_8.8.9_x64_linux.tar.gz","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"alpine","slug":"alpine","permalink":"https://blog.gitee.io/tags/alpine/"},{"name":"jdk","slug":"jdk","permalink":"https://blog.gitee.io/tags/jdk/"}]},{"title":"docker删除<none>标签镜像","date":"2021-08-22T16:00:00.000Z","path":"2021/08/23/dockerimage-prune/","text":"被打上&lt;none&gt;标签的镜像指的是没有标签并且没有被容器使用的镜像。如果不清理这种镜像会大量占用机器磁盘。记录2种自身工作中常用的删除方法。 第一种删除方式执行下面shell 并输入y docker image prune 第二种方式删除 利用awk来获取镜像id 执行docker rmi删除 docker rmi $(docker images | grep \"none\" | awk '&#123;print $3&#125;')","tags":[{"name":"docker","slug":"docker","permalink":"https://blog.gitee.io/tags/docker/"},{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"}]},{"title":"kubernetes之pod","date":"2021-08-08T16:00:00.000Z","path":"2021/08/09/k8s-pod/","text":"","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://blog.gitee.io/tags/kubernetes/"},{"name":"pod","slug":"pod","permalink":"https://blog.gitee.io/tags/pod/"}]},{"title":"kubernetes-kubeadm创建集群","date":"2021-08-04T16:00:00.000Z","path":"2021/08/05/k8s-kubeadm-init-2/","text":"这一节基本上会遇到很多异常错误信息，需要耐心的去解决它，跟环境等很多因素有关系。 初始化集群在master 机器上初始化集群 会自动拉取相关的镜像 需要等待一下 kubeadm init --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.213 正常情况下 这里会报错，[ERROR ImagePull]: failed to pull image registry.aliyuncs.com/google_containers/coredns:v1.8.0: output: Error response from daemon: manifest for registry.aliyuncs.com/google_containers/coredns:v1.8.0 not found: manifest unknown: manifest unknown 原因是 期望自动下载的镜像为 registry.aliyuncs.com/google_containers/coredns:v1.8.0，然后仓库中并这个容器镜像，查了资料可以手动下载指定版本号的时候把v去掉即可，下载后并重命名一下版本号 手动拉取镜像 下载#docker pull registry.aliyuncs.com/google_containers/coredns:1.8.0重命名#docker tag registry.aliyuncs.com/google_containers/coredns:1.8.0 registry.aliyuncs.com/google_containers/coredns:v1.8.0 然后再执行 kubeadm init --image-repository registry.aliyuncs.com/google_containers --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.213 就不会报错了。执行完成后打印执行完成后打印Your Kubernetes control-plane has initialized successfully!表示已经成功初始化。 mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 在初始化结果日志中还打印了加入集群的令牌(token),令牌用于控制平面节点和加入节点之间的相互身份验证。 这里包含的令牌是密钥。确保它的安全， 因为拥有此令牌的任何人都可以将经过身份验证的节点添加到你的集群中。 节点加入集群在work机器上执行加入节点到机器操作 要保证work机器上要能和master网络保持畅通,直接复制init 命令日志中最后一段话命令就行。加入的时候要保证work节点上的docker服务是开启的。不然要报错。kubeadm join 192.168.0.213:6443 --token 5aqi11.werqxkrz4e46vnih --discovery-token-ca-cert-hash sha256:4794a2e13e2c566070d6b289981abb267a0fce1dbf78d60c21db618719d764e7 加入成功后在master上执行kubectl get nodes会发现多了一个节点 但是状态是NotReady，这是不同的机器上容器内部网络不互通 接下来就来整一下网络。 网络模型插件 目前Kubernetes比较常用的网络组建 主要是flannel、Calico 这里我们选用flannel做网络模型。安装方法也就是允许容器 还是比较方便。需要在master上执行 下载yml文件 wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml 在集群中运行容器kubectl apply -f kube-flannel.yml 这里可能会遇到很多问题，安装好网络插件了 怎么节点还是NotReady状态呢？这些就要对问题进行进一步排查了。这个命令可以看到node上一些问题journalctl -u kubelet -n 300.节点还是依然处理NotReady，就可能是环境有什么问题了，在Master上执行kubectl describe node test1 test1为状态异常的节点名称，就能看到这个节点当前的调度操作日志。比如这次有一台work机器日志显示为Normal Starting 18s kubelet Starting kubelet.Normal NodeHasSufficientPID 1s kubelet Node test1 status is now: NodeHasSufficientPIDNormal Starting 1s kubelet Starting kubelet.Normal NodeHasSufficientMemory 1s kubelet Node test1 status is now: NodeHasSufficientMemoryNormal NodeHasNoDiskPressure 1s kubelet Node test1 status is now: NodeHasNoDiskPressure 能看到一些有用的信息 如 磁盘空间不足。 出现了异常 看哪些命令没有启动成功 可以参考以下的命令日志 journalctl -l -u kube-apiserverjournalctl -l -u kube-controller-managerjournalctl -l -u kube-schedulerjournalctl -l -u kubeletjournalctl -l -u kube-proxy 如果节点状态都为Ready 那真是太幸运了。安装好网络插件后 一般要等待1-2分钟才会变为Ready，接下来就可能把应用部署在k8s集群中去。","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://blog.gitee.io/tags/kubernetes/"}]},{"title":"kubernetes-kubeadm安装","date":"2021-08-03T16:00:00.000Z","path":"2021/08/04/k8s-kubeadm-1/","text":"kubeadm是目前官方最推荐的安装方式，既可以用于安装学习玩一下，也可以用来安装高可用集群。这里的操作系统都是以centos7为例 其他系统类似。 环境准备 master 192.168.0.213work 192.168.0.212work 192.168.0.211 需要在3台服务器上执行一下配置更改。 cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.confbr_netfilterEOF cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1EOF 将 SELinux 设置为 permissive 模式（相当于将其禁用） sudo setenforce 0sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config 关闭swap sed -ri 's/.*swap.*/#&amp;/' /etc/fstab swapoff -a 导入yum源 用aliyun的镜像地址，默认是google 国内根本就下载不了。 cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF 执行安装并启用操作，等待下载安装完成。 sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetessudo systemctl enable --now kubelet 执行如果没有出错 差不多就安装完成了，如果遇到错误可以查阅故障排除资料 https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"kubernetes","slug":"kubernetes","permalink":"https://blog.gitee.io/tags/kubernetes/"}]},{"title":"找出JVM中最耗cpu的线程","date":"2020-12-10T16:00:00.000Z","path":"2020/12/11/find_jvm_cpu_max_thread/","text":"1、top命令查找出cpu最高的java进程pid 2、top -Hp 命令找出进程内最耗线程的pid top -Hp 22293 3、获取到上一步线程的pid后 将pid 16进制输出 # printf '%x\\n' 228015911 4 使用jstack命令找出线程信息 jstack 进程pid |grep 16进制后的线程号 # jstack 22293|grep 5911\"DubboServerHandler-192.168.0.11:20880-thread-345\" #474 daemon prio=5 os_prio=0 tid=0x00007f74940dc800 nid=0x5911 waiting on condition [0x00007f745c873000] 这样就很直观的看到 线程名称为DubboServerHandler的线程占用最高。 通常如果是FullGC频繁的话 这里的线程应该是GC回收线程。 GC总体内存概述 使用jstat命令可以快速查看 jstat -gcutil 进程pid 滚动时间可不设置 jstat -gcutil 22293 3000S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.62 34.27 21.19 92.31 88.54 495 10.072 4 0.733 10.8050.00 85.62 35.71 21.19 92.31 88.54 495 10.072 4 0.733 10.805 如果是FullGC次数太频繁 需要查一下内存中是哪些对象不能回收导致的 查询前20个大对象 根据大对象的ClassName大概率知道是哪些原因导致的问题 jmap -histo:live pid|head -n 20 ``` dump堆栈的快照信息 这个操作在操作过程中会导致应用暂停 线上系统需要谨慎操作``` shelljmap -dump:format=b,live,file=0623.dump pid live 参数表示 只导出活动的对象 可以去掉file 导出路径format 导出格式 指定为format=b就行","tags":[{"name":"jvm","slug":"jvm","permalink":"https://blog.gitee.io/tags/jvm/"},{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"}]},{"title":"更好用 更简单的Java缓存框架 jscache","date":"2020-08-20T16:00:00.000Z","path":"2020/08/21/jscache/","text":"比Spring Cache 更好用 更简单的缓存工具 jscache 取名意义为 java simple cache，基于AOP实现，支持注解到接口 自定义单个缓存过期时间配置 ttl，轻松扩展缓存实现，默认实现了jedis,spring-data-redis,还有一个基于本地内存的map。 源码仓库 https://github.com/peachyy/jscache.git 注解API@Cacheable 设置/获取缓存 如果当前KEY对应的缓存存在就直接返回，不存在则调用服务后 再对结果进行缓存。 配置项 prefix 缓存前缀 key key 是 el 表达式 默认生成后的缓存key为 prefix+key ttl 缓存存活时间(过期时间) 需要具体的缓存实现支持 如常用的redis是支持的 argCondition 前置条件过滤 针对参数过滤 满足则执行表达式逻辑 returnCondition 后置条件过滤 只有前置条件为true的情况下才能到达后置过滤 为true才会把结果放入缓存中 allowNullValue 返回值为空的情况下是否缓存 防止缓存穿透可以支持为true @Cacheable(prefix = \"user:\",key = \"#p0\",ttl = 60,returnCondition = \"#result!=null\") public User getUserById(Integer userId) &#123; User user=new User(); user.setId(userId); user.setName(\"xxx\"); log.info(\"GET getUserById\"); return user; &#125; @CachePut 只是设置(put)缓存 无论缓存是否存在 这里支持设置(put)多个缓存 配置项 与 cacheable类似 prefix 缓存前缀 key key 是 el 表达式 默认生成后的缓存key为 prefix+key ttl 缓存存活时间(过期时间) 需要具体的缓存实现支持 如常用的redis是支持的 argCondition 前置条件过滤 针对参数过滤 满足则执行表达式逻辑 returnCondition 后置条件过滤 只有前置条件为true的情况下才能到达后置过滤 为true才会把结果放入缓存中 allowNullValue 返回值为空的情况下是否缓存 防止缓存穿透可以支持为true @CachePut(prefix = \"user:\",key = \"#p0\")@CachePut(prefix = \"members:\",key = \"#p0\")public User getUserById(Integer userId) &#123; User user=new User(); user.setId(userId); user.setName(\"xxx\"); log.info(\"GET getUserById\"); return user;&#125; @CacheEvict 删除缓存 支持删除多个缓存 配置项 prefix 缓存前缀 key key 是 el 表达式 默认生成后的缓存key为 prefix+key argCondition 前置条件过滤 针对参数过滤 满足则执行表达式逻辑 @CacheEvict(prefix = \"members:\",key = \"#p0\")@CacheEvict(prefix = \"user:\",key = \"#p0\",argCondition = \"#p0==100\")public User getUserById(Integer userId) &#123; User user=new User(); user.setId(userId); user.setName(\"xxx\"); log.info(\"GET getUserById\"); return user;&#125; 开始使用缓存 如springboot中 标注@EnableCache注解 表示缓存功能启用 只要标注了注解的就会生效。 引入jar &lt;dependency&gt; &lt;groupId&gt;com.peachyy&lt;/groupId&gt; &lt;artifactId&gt;jscache-core&lt;/artifactId&gt;&lt;version&gt;$&#123;last.jscache.version&#125;&lt;/version&gt; &lt;/dependency&gt; 启用缓存 并配置一个缓存实现。@SpringBootApplication@EnableCache()public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; @Bean public JedisCache cache()&#123; Properties properties=new Properties(); properties.put(\"hosts\",\"192.168.0.2:6379\"); properties.put(\"password\",\"bac123\"); properties.put(\"database\",\"0\"); return new JedisCache(properties,null); &#125; 这里有一个基于springboot的例子 https://github.com/peachyy/jscache/tree/master/jscache-springmvc-example 更多适配 主要是用于针对部分rpc 如dubbo 当使用@Reference注解 实例没有被spring ioc管理到 就不能到框架AOP 所以提供一些简单的支持 目前仅实现了dubbo的这种情况 模块 jscache-annotation 只是注解包 比如标注在接口上 而这个接口需要给其它地方引用 就只需要引用这个jar就好，免得过多产生过多的依赖 jscache-core 核心功能实现 jscache-dubbo 针对没有被spring管理dubbo service的适配 基于filter实现 jscache-springmvc-example 一个springboot 简单例子 序列化以及其它扩展序列化 序列化只针对值 key默认为String字符，方便监控查看。自定义序列化需要实现 com.peachyy.jscache.core.serialize.Serializer接口。默认的实现有fastJson,jackson,java 自定义的直接传自定义的全类名就行。 如 扩展了一个com.xxx.myJacksonSerializer序列化方式 设置的方式大概就是这样 @EnableCache(serializer=\"com.xxx.myJacksonSerializer\") 扩展缓存实现 扩展缓存需要实现com.peachyy.jscache.core.Cache接口，加入spring容器就完事了。不需要复杂的实现 @Beanpublic JedisCache cache()&#123; Properties properties=new Properties(); properties.put(\"hosts\",\"192.168.0.2:6379\"); properties.put(\"password\",\"bac123\"); properties.put(\"database\",\"0\"); return new JedisCache(properties,null);&#125; 和spring cache比起来使用上的功能大部分有，一些设计也参考了它，使用上明显的差别就是支持了ttl过期时间，去掉了cacheManager设计，但是仅不止如此 开发者更易驾驭，一个系统中一般保持一套缓存规范就够了。总之适合就是最好的。","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"jscache","slug":"jscache","permalink":"https://blog.gitee.io/tags/jscache/"}]},{"title":"Neo4j入门教程","date":"2019-08-22T16:00:00.000Z","path":"2019/08/23/neo4j_study/","text":"第一章：介绍Neo4j是什么Neo4j是一个高性能的,NOSQL图形数据库，它将结构化数据存储在网络上而不是表中。它是一个嵌入式的、基于磁盘的、具备完全的事务特性的Java持久化引擎，但是它将结构化数据存储在网络(从数学角度叫做图)上而不是表中。Neo4j也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。程序员工作在一个面向对象的、灵活的网络结构下而不是严格、静态的表中——但是他们可以享受到具备完全的事务特性、企业级的数据库的所有好处。 Neo4j的特点SQL就像简单的查询语言Neo4j CQL它遵循属性图数据模型它通过使用Apache Lucence支持索引它支持UNIQUE约束它它包含一个用于执行CQL命令的UI：Neo4j数据浏览器它支持完整的ACID（原子性，一致性，隔离性和持久性）规则它采用原生图形库与本地GPE（图形处理引擎）它支持查询的数据导出到JSON和XLS格式它提供了REST API，可以被任何编程语言（如Java，Spring，Scala等）访问它提供了可以通过任何UI MVC框架（如Node JS）访问的Java脚本它支持两种Java API：Cypher API和Native Java API来开发Java应用程序 Neo4j的优点它很容易表示连接的数据检索/遍历/导航更多的连接数据是非常容易和快速的它非常容易地表示半结构化数据Neo4j CQL查询语言命令是人性化的可读格式，非常容易学习它使用简单而强大的数据模型它不需要复杂的连接来检索连接的/相关的数据，因为它很容易检索它的相邻节点或关系细节没有连接或索引 第二章：安装1.环境Centos 7.4 neo4j-community-3.4.1.tar.gz 2.下载下载地址 https://neo4j.com/download/other-releases/ 下载 wget https://neo4j.com/artifact.php?name=neo4j-community-3.4.1-unix.tar.gz解压 tar -zxvf neo4j-community-3.4.1.tar.gz 3.开启远程访问一、对于3.0以前的版本 在安装目录的 $NEO4J_HOME/conf/neo4j.conf 文件内，找到下面一行，将注释#号去掉就可以了 #dbms.connector.https.address=localhost:7473 改为 dbms.connector.https.address=0.0.0.0:7473 这样，远程其他电脑可以用本机的IP或者域名后面跟上7474 端口就能打开web界面了 如： https://:7473 当然，你的操作系统的防火墙也要确保开放了7474端口才行，防火墙怎样开放请自行针对自己的操作系统查找文档 二、对于3.1及以后的版本 在安装目录的 $NEO4J_HOME/conf/neo4j.conf 文件内，找到下面一行，将注释#号去掉就可以了 dbms.connectors.default_listen_address=0.0.0.0 4.测试在bin目录下，执行命令：./neo4j start启动，其他命令 { console | start | stop | restart | status } 访问http://IP地址:7474/, 出现下图即代表安装成功，顶部的$输入框用来执行下面的CQL语句。 第三章：CQL1.CQL简介CQL代表Cypher查询语言。 像Oracle数据库具有查询语言SQL，Neo4j具有CQL作为查询语言。 Neo4j CQL - 它是Neo4j图形数据库的查询语言。 它是一种声明性模式匹配语言 它遵循SQL语法。 它的语法是非常简单且人性化、可读的格式。 如Oracle SQL - Neo4j CQL 命令来执行数据库操作。 Neo4j CQL 支持多个子句像在哪里，顺序等，以非常简单的方式编写非常复杂的查询。 NNeo4j CQL 支持一些功能，如字符串，Aggregation.In 加入他们，它还支持一些关系功能。 2.Neo4j CQL命令/条款常用的Neo4j CQL命令/条款如下： CREATE 创建节点，关系和属性 MATCH 检索有关节点，关系和属性数据 RETURN 返回查询结果 WHERE 提供条件过滤检索数据 DELETE 删除节点和关系 REMOVE 删除节点和关系的属性 ORDER BY ORDER BY以…排序 排序检索数据 SET 添加或更新标签 3.Neo4j CQL 函数以下是常用的Neo4j CQL函数： String 字符串 它们用于使用String字面量。 Aggregation 聚合 它们用于对CQL查询结果执行一些聚合操作。 Relationship 关系 他们用于获取关系的细节，如startnode，endnode等。 我们将在后面的章节中详细讨论所有Neo4j CQL命令，子句和函数语法，用法和示例。 4.Neo4j CQL数据类型这些数据类型与Java语言类似。 它们用于定义节点或关系的属性 Neo4j CQL支持以下数据类型： No. CQL数据类型 用法 1. boolean 用于表示布尔文字：true，false。 2. byte 用于表示8位整数。 3. short 用于表示16位整数。 4. int 用于表示32位整数。 5. long 用于表示64位整数。 6. float 用于表示32位浮点数。 7. double 用于表示64位浮点数。 8. char 用于表示16位字符。 9. String 用于表示字符串。 第四章：命令1.CREATE创建Neo4j CQL创建一个没有属性的节点 CREATE (:)语法说明 规范说法是节点标签名称，其实相当于Mysql数据库中的表名，而是节点名称，其实代指创建的此行数据。 示例 CREATE (emp:Employee)或者 CREATE (:Employee)Neo4j CQL创建具有属性的节点 Neo4j CQL“CREATE”命令用于创建带有属性的节点。 它创建一个具有一些属性（键值对）的节点来存储数据。 CREATE ( &lt;node-name&gt;:&lt;label-name&gt; { &lt;key&gt;:&lt;Value&gt; ........ &lt;n-key&gt;:&lt;n-Value&gt; } ) 示例 CREATE (dept:Dept { deptno:10,dname:”Accounting”,location:”Hyderabad” })创建多个标签到节点 语法： CREATE (::…..:)示例 CREATE (m:Movie:Cinema:Film:Picture) 2.MATCH查询Neo4j CQL MATCH命令用于 从数据库获取有关节点和属性的数据从数据库获取有关节点，关系和属性的数据MATCH命令语法： MATCH ( &lt;node-name&gt;:&lt;label-name&gt; ) 示例 MATCH (dept:Dept)但是执行后会报错： Neo.ClientError.Statement.SyntaxError:Query cannot conclude with MATCH(must be RETURN or an update clause) (line 1, column 1 (offset: 0))如果你观察到错误消息，它告诉我们，我们可以使用MATCH命令与RETURN子句或UPDATA子句。 3.RETURN返回Neo4j CQL RETURN子句用于 - 检索节点的某些属性检索节点的所有属性检索节点和关联关系的某些属性检索节点和关联关系的所有属性RETURN命令语法： RETURN &lt;node-name&gt;.&lt;property1-name&gt;, ........ &lt;node-name&gt;.&lt;propertyn-name&gt; 示例 MATCH (e:Employee) RETURN e或 MATCH (dept: Dept)RETURN dept.deptno,dept.dname,dept.location 4.关系基础Neo4j图数据库遵循属性图模型来存储和管理其数据。 根据属性图模型，关系应该是定向的。 否则，Neo4j将抛出一个错误消息。 基于方向性，Neo4j关系被分为两种主要类型。 单向关系双向关系使用新节点创建关系 示例 CREATE (e:Employee)-[r:DemoRelation]-&gt;(c:Employee)这句会创建节点e，节点c，以及e -&gt; c的关系r，这里需要注意方向，比如双向是 CREATE (e:Employee)&lt;-[r:DemoRelation]-&gt;(c:Employee)使用已知节点创建带属性的关系： MATCH (&lt;node1-label-name&gt;:&lt;node1-name&gt;),(&lt;node2-label-name&gt;:&lt;node2-name&gt;) CREATE (&lt;node1-label-name&gt;)-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt; {&lt;define-properties-list&gt;}]-&gt;(&lt;node2-label-name&gt;) RETURN &lt;relationship-label-name&gt; 还是一系列键值对 示例 MATCH (cust:Customer),(cc:CreditCard) CREATE (cust)-[r:DO_SHOPPING_WITH{shopdate:\"12/12/2014\",price:55000}]-&gt;(cc) RETURN r 检索关系节点的详细信息： MATCH (&lt;node1-label-name&gt;)-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt;]-&gt;(&lt;node2-label-name&gt;) RETURN &lt;relationship-label-name&gt; 示例 MATCH (cust)-[r:DO_SHOPPING_WITH]-&gt;(cc) RETURN cust,cc 5.WHERE子句像SQL一样，Neo4j CQL在CQL MATCH命令中提供了WHERE子句来过滤MATCH查询的结果。 简单WHERE子句语法 WHERE 语法说明： No. 语法元素 描述 1 WHERE 它是一个Neo4j CQL关键字。 2 &lt;属性名称&gt; 它是节点或关系的属性名称。 3 &lt;比较运算符&gt; 它是Neo4j CQL比较运算符之一。 4 &lt;值&gt; 它是一个字面值，如数字文字，字符串文字等。 Neo4j CQL中的比较运算符Neo4j 支持以下的比较运算符，在 Neo4j CQL WHERE 子句中使用来支持条件 No. 比较运算符 描述 1. = 它是Neo4j CQL“等于”运算符。 2. &lt;&gt; 它是一个Neo4j CQL“不等于”运算符。 3. &lt; 它是一个Neo4j CQL“小于”运算符。 4. &gt; 它是一个Neo4j CQL“大于”运算符。 5. &lt;= 它是一个Neo4j CQL“小于或等于”运算符。 6. = 它是一个Neo4j CQL“大于或等于”运算符。 我们可以使用布尔运算符在同一命令上放置多个条件。 Neo4j CQL中的布尔运算符Neo4j支持以下布尔运算符在Neo4j CQL WHERE子句中使用以支持多个条件。 No. 布尔运算符 描述 1 AND 它是一个支持AND操作的Neo4j CQL关键字。 2 OR 它是一个Neo4j CQL关键字来支持OR操作。 3 NOT 它是一个Neo4j CQL关键字支持NOT操作。 4 XOR 它是一个支持XOR操作的Neo4j CQL关键字。 示例 MATCH (emp:Employee)WHERE emp.name = ‘Abc’ OR emp.name = ‘Xyz’RETURN emp 利用WHERE创建指定关系节点： MATCH (cust:Customer),(cc:CreditCard)WHERE cust.id = “1001” AND cc.id= “5001”CREATE (cust)-[r:DO_SHOPPING_WITH{shopdate:”12/12/2014”,price:55000}]-&gt;(cc)RETURN r有必要补充一下，可以不使用WHERE达到WHERE的一些效果，比如 MATCH p=(m:Bot{id:123})&lt;-[:BotRelation]-&gt;(:Bot) RETURN p 6.DELETE删除Neo4j使用CQL DELETE子句 删除节点。删除节点及相关节点和关系。DELETE节点子句语法 DELETE 示例 MATCH (e: Employee) DELETE eDELETE节点和关系子句语法 DELETE ,,示例 MATCH (cc: CreditCard)-[rel]-(c:Customer)DELETE cc,c,rel 7.REMOVE删除有时基于我们的客户端要求，我们需要向现有节点或关系添加或删除属性。 我们使用Neo4j CQL SET子句向现有节点或关系添加新属性。 我们使用Neo4j CQL REMOVE子句来删除节点或关系的现有属性。 Neo4j CQL REMOVE命令用于 删除节点或关系的标签删除节点或关系的属性Neo4j CQL DELETE和REMOVE命令之间的主要区别 - DELETE操作用于删除节点和关联关系。REMOVE操作用于删除标签和属性。Neo4j CQL DELETE和REMOVE命令之间的相似性 - 这两个命令不应单独使用。两个命令都应该与MATCH命令一起使用。 1.REMOVE属性子句语法REMOVE &lt;node-name&gt;.&lt;property1-name&gt;,&lt;node-name&gt;.&lt;property2-name&gt; 语法说明： node-name 它是节点的名称。 property1-name 它是节点的属性名称。 示例 MATCH (dc:DebitCard)REMOVE dc.cvvRETURN dc 2.REMOVE一个Label子句语法：REMOVE &lt;label-name-list&gt; 2.它是一个标签列表，用于永久性地从节点或关系中删除它。语法 &lt; node-name &gt;:&lt; label2-name &gt;, .... &lt; node-name &gt;:&lt; labeln-name &gt; 示例 1.我们创建一个含有两个标签的节点： CREATE (m:Movie:Pic)2.查询该节点 MATCH (n:Movie) RETURN n 3.删除标签 MATCH (m:Movie)REMOVE m:Pic4.再次查询 8.SET子句有时，根据我们的客户端要求，我们需要向现有节点或关系添加新属性。 要做到这一点，Neo4j CQL提供了一个SET子句。 Neo4j CQL已提供SET子句来执行以下操作。 向现有节点或关系添加新属性添加或更新属性值SET子句语法 SET &lt;node-label-name&gt;.&lt;property1-name&gt;,...&lt;node-laben-name&gt;.&lt;propertyn-name&gt;语法说明： node-label-name &lt;节点标签名称&gt;这是一个节点的标签名称。 property1-name &lt;属性名称&gt; 它是一个节点的属性名。 示例 MATCH (dc:DebitCard)SET dc.atm_pin = 3456RETURN dc 9.ORDER BY排序Neo4j CQL ORDER BY子句 Neo4j CQL在MATCH命令中提供了“ORDER BY”子句，对MATCH查询返回的结果进行排序。 我们可以按升序或降序对行进行排序。 默认情况下，它按升序对行进行排序。 如果我们要按降序对它们进行排序，我们需要使用DESC子句。 ORDER BY子句语法 ORDER BY &lt;property-name-list&gt; [DESC]语法： &lt;node-label-name&gt;.&lt;property1-name&gt;,&lt;node-label-name&gt;.&lt;property2-name&gt;,....&lt;node-label-name&gt;.&lt;propertyn-name&gt; node-label-name 它是节点的标签名称。 property1-name 它是节点的属性名称。 示例 MATCH (emp:Employee)RETURN emp.empid,emp.name,emp.salary,emp.deptnoORDER BY emp.name10.UNION子句与SQL一样，Neo4j CQL有两个子句，将两个不同的结果合并成一组结果 UNIONUNION ALLUNION子句 它将两组结果中的公共行组合并返回到一组结果中。 它不从两个节点返回重复的行。 限制： 结果列类型和来自两组结果的名称必须匹配，这意味着列名称应该相同，列的数据类型应该相同。 10 UNION子句语法&lt;MATCH Command1&gt; UNION&lt;MATCH Command2&gt; 注意 - 如果这两个查询不返回相同的列名和数据类型，那么它抛出一个错误。 示例 MATCH (cc:CreditCard) RETURN cc.id,cc.numberUNIONMATCH (dc:DebitCard) RETURN dc.id,dc.numberUNION ALL子句 它结合并返回两个结果集的所有行成一个单一的结果集。它还返回由两个节点重复行。 限制 结果列类型，并从两个结果集的名字必须匹配，这意味着列名称应该是相同的，列的数据类型应该是相同的。 UNION ALL子句语法&lt;MATCH Command1&gt;UNION ALL&lt;MATCH Command2&gt;示例 MATCH (cc:CreditCard) RETURN cc.id,cc.numberUNION ALLMATCH (dc:DebitCard) RETURN dc.id,dc.number 11.LIMIT和SKIP子句Neo4j CQL已提供LIMIT子句和SKIP来过滤或限制查询返回的行数。 简单来说：LIMIT返回前几行，SKIP返回后几行。 LIMIT 示例 MATCH (emp:Employee)RETURN empLIMIT 2它只返回Top的两个结果，因为我们定义了limit = 2。这意味着前两行。 SKIP示例 MATCH (emp:Employee)RETURN empSKIP 2它只返回来自Bottom的两个结果，因为我们定义了skip = 2。这意味着最后两行。 12.MERGE命令Neo4j使用CQL MERGE命令 - 创建节点，关系和属性为从数据库检索数据MERGE命令是CREATE命令和MATCH命令的组合。 MERGE = CREATE + MATCHNeo4j CQL MERGE命令在图中搜索给定模式，如果存在，则返回结果 如果它不存在于图中，则它创建新的节点/关系并返回结果。 Neo4j CQL MERGE语法 MERGE (&lt;node-name&gt;:&lt;label-name&gt;{ &lt;key&gt;:&lt;1-Value&gt; ….. &lt;n-key&gt;:&lt;n-Value&gt;})注意 - Neo4j CQL MERGE命令语法与CQL CREATE命令类似。 我们将使用这两个命令执行以下操作 - 创建具有一个属性的配置文件节点：Id，名称创建具有相同属性的同一个Profile节点：Id，Name检索所有Profile节点详细信息并观察结果我们将使用CREATE命令执行这些操作： MERGE (gp2:GoogleProfile2{ Id: 201402,Name:”Nokia”})MERGE (gp2:GoogleProfile2{ Id: 201402,Name:”Nokia”})MATCH (gp1:GoogleProfile1)RETURN gp1.Id,gp1.Name如果我们观察上面的查询结果，它只显示一行，因为CQL MERGE命令检查该节点在数据库中是否可用。 如果它不存在，它创建新节点。 否则，它不创建新的。 通过观察这些结果，我们可以说，CQL MERGE命令将新的节点添加到数据库，只有当它不存在。 13.NULL值Neo4j CQL将空值视为对节点或关系的属性的缺失值或未定义值。 当我们创建一个具有现有节点标签名称但未指定其属性值的节点时，它将创建一个具有NULL属性值的新节点。 让我们用一个例子来看这个。 MATCH (e:Employee)WHERE e.id IS NOT NULLRETURN e.id,e.name,e.sal,e.deptno提供了一个WHERE子句来过滤该行，即Id属性不应该包含NULL值。 MATCH (e:Employee)WHERE e.id IS NULLRETURN e.id,e.name,e.sal,e.deptno这里我们使用IS操作符来仅返回NULL行。 14.IN操作符与SQL一样，Neo4j CQL提供了一个IN运算符，以便为CQL命令提供值的集合。 IN操作符语法 IN[&lt;Collection-of-values&gt;]它是由逗号运算符分隔的值的集合。 示例 MATCH (e:Employee)WHERE e.id IN [123,124]RETURN e.id,e.name,e.sal,e.deptno 15.INDEX索引Neo4j SQL支持节点或关系属性上的索引，以提高应用程序的性能。 我们可以为具有相同标签名称的所有节点的属性创建索引。 我们可以在MATCH或WHERE或IN运算符上使用这些索引列来改进CQL Command的执行。 Neo4J索引操作 Create Index 创建索引Drop Index 丢弃索引我们将在本章中用示例来讨论这些操作。 创建索引的语法： CREATE INDEX ON :&lt;label_name&gt; (&lt;property_name&gt;)注意：- 冒号（:)运算符用于引用节点或关系标签名称。 上述语法描述它在节点或关系的的上创建一个新索引。 示例 CREATE INDEX ON :Customer (name)删除索引的语法： DROP INDEX ON :&lt;label_name&gt; (&lt;property_name&gt;)示例 DROP INDEX ON :Customer (name) 16.UNIQUE约束在Neo4j数据库中，CQL CREATE命令始终创建新的节点或关系，这意味着即使您使用相同的值，它也会插入一个新行。 根据我们对某些节点或关系的应用需求，我们必须避免这种重复。 然后我们不能直接得到这个。 我们应该使用一些数据库约束来创建节点或关系的一个或多个属性的规则。 像SQL一样，Neo4j数据库也支持对NODE或Relationship的属性的UNIQUE约束 UNIQUE约束的优点 避免重复记录。强制执行数据完整性规则创建唯一约束语法 CREATE CONSTRAINT ON (&lt;label_name&gt;)ASSERT &lt;property_name&gt; IS UNIQUE语法说明： No. 语法元素 描述 1。 CREATE CONSTRAINT ON 它是一个Neo4j CQL关键字。 2。 label_name 它是节点或关系的标签名称。 3。 ASSERT 它是一个Neo4j CQL关键字。 4。 property_name 它是节点或关系的属性名称。 5。 IS UNIQUE 它是一个Neo4j CQL关键字，通知Neo4j数据库服务器创建一个唯一约束。 注意：- 上述语法描述了只需要 节点或关系就可以创造一个独特的约束。 示例 CREATE CONSTRAINT ON (cc:CreditCard)ASSERT cc.number IS UNIQUE注意 如果创建约束时节点属性有重复值，Neo4j DB服务器将会抛出一个错误，表示无法创建。 删除UNIQUE约束语法： DROP CONSTRAINT ON (&lt;label_name&gt;)ASSERT &lt;property_name&gt; IS UNIQUE示例 DROP CONSTRAINT ON (cc:CreditCard)ASSERT cc.number IS UNIQUE17.DISTINCT独特这个函数的用法就像SQL中的distinct关键字，返回的是所有不同值。 示例 MATCH (n:Movie) RETURN Distinct(n.name) 第五章：管理员 数据备份/恢复1.数据库备份在对Neo4j数据进行备份、还原、迁移的操作时，首先要关闭neo4j; cd %NEO4J_HOME%/bin./neo4j stop数据备份到文件 ./neo4j-admin dump –database=graph.db –to=/home/2018.dump之后，进行数据还原，将生成的存储文件拷贝到另一个相同版本的环境中。 2.数据库恢复还原、迁移之前 ，关闭neo4j服务。操作同上； 数据导入： ./neo4j-admin load –from=/home/2016-10-02.dump –database=graph.db –force重启服务： ./neo4j start 参考 https://cloud.tencent.com/developer/article/1336299","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"neo4j","slug":"neo4j","permalink":"https://blog.gitee.io/tags/neo4j/"}]},{"title":"thymeleaf自定义dialect","date":"2019-07-21T16:00:00.000Z","path":"2019/07/22/custom-thymeleaf-dealect/","text":"有时候thymeleaf自带的模板方言有点不够用的时候 可以支持自定义，最近遇到一个在thymeleaf模板中显示订单状态的需求。当然也可以使用 switch case的方式,但是如果很多的页面都要使用的时候你得一直复制代码 很麻烦 而且中途如果修改了某个状态码含义 你得全部修改一遍。这当然不是我们得正确使用姿势。状态码含义如下 9 待支付定金10 待停车(已支付定金)11 停车中12 停车结束(待支付尾款)13 订单完成(已支付尾款) 定义处理tag得解析器 这里我们定义一个名为orderstatus的属性(attributeName),表示遇到这个属性会调用doProcess方法中的代码 public class ParkingOrderStatusTagProcessor extends AbstractAttributeTagProcessor &#123; protected ParkingOrderStatusTagProcessor(String dialectPrefix) &#123; super(TemplateMode.HTML, dialectPrefix, null, false, \"orderstatus\", true, 1000, true); &#125; @Override protected void doProcess(ITemplateContext context, IProcessableElementTag tag, AttributeName attributeName, String attributeValue, IElementTagStructureHandler structureHandler) &#123; final IStandardExpressionParser expressionParser = StandardExpressions .getExpressionParser(context.getConfiguration()); final IStandardExpression expression = expressionParser.parseExpression(context, attributeValue); Object val=expression.execute(context); if(val!=null &amp;&amp; val instanceof Number)&#123; structureHandler.setBody( HtmlEscape.escapeHtml5(getOrderStatus((Integer) val)), false); &#125; &#125; private static String getOrderStatus(Integer status)&#123; if(status== 9)&#123; return \"待支付定金\"; &#125;else if(status==10)&#123; return \"待停车(已支付定金)\"; &#125;else if(status==11)&#123; return \"停车中\"; &#125;else if(status==12)&#123; return \"停车结束(待支付尾款)\"; &#125;else if(status==13)&#123; return \"订单完成(已支付尾款)\"; &#125;else&#123; return \"未知状态\"; &#125; &#125;&#125; 定义方言 创建一个方言 因为thymeleaf模板引擎需要先添加方言(Dealect),而这个方言中又可以添加多个tag属性解析器,这里设置了一个名为park的前缀，并添加了上面的ParkingOrderStatusTagProcessor属性解析器。 在模板中就可以使用&lt;div park:orderstatus=&quot;${order.status}&quot;&gt;&lt;/div&gt; public class ParkDealect extends AbstractProcessorDialect &#123; public ParkDealect() &#123; super(\"parkingDealect\", \"park\", 1001); &#125; @Override public Set&lt;IProcessor&gt; getProcessors(String dialectPrefix) &#123; final Set&lt;IProcessor&gt; processors = new HashSet&lt;IProcessor&gt;(); processors.add(new ParkingOrderStatusTagProcessor(dialectPrefix)); return processors; &#125;&#125; 添加方言到模板引擎中@Beanpublic SpringTemplateEngine templateEngine(@Autowired ITemplateResolver resolver)&#123; SpringTemplateEngine templateEngine = new SpringTemplateEngine(); templateEngine.setEnableSpringELCompiler(true); templateEngine.setTemplateResolver(resolver); templateEngine.addDialect(new ParkDealect());//把定义好的方言添加进去 return templateEngine;&#125; 最后在模板中设置一下park的xmlns,我自己测试了一下 这个xmlns的文件不创建也没关系，但最好还是建好。 &lt;html lang=\"zh\" xmlns:th=\"http://www.thymeleaf.org\" xmlns:park=\"http://www.peachyy.com/thymeleaf/park\"&gt; 其实自定义方言就相当于JSP中的自定义标签。更多xmlns文件的细节后面在更新了","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"thymeleaf","slug":"thymeleaf","permalink":"https://blog.gitee.io/tags/thymeleaf/"}]},{"title":"elasticsearch中短语匹配match_phrase","date":"2019-05-06T16:00:00.000Z","path":"2019/05/07/es-match-phrase/","text":"现有业务中很少用到match_phrase这个搜索，最近在实现基于elasticsearch的日志搜集 并自助告警一个业务，因为日志的不规范 所以需要用到对某个日志短语进行搜索，不能像match做全文检索。 比如需要精确寻找日志中的请求第三方CAKA服务器失败 GET /filebeat*/_search&#123;\"query\": &#123; \"match_phrase\": &#123; \"message\": \"请求第三方CAKA服务器失败\" &#125;&#125;&#125; 查询结果中就完全包含了这句短语。不会进行分词搜索。","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"https://blog.gitee.io/tags/elasticsearch/"}]},{"title":"认识go语言与环境搭建","date":"2019-03-25T16:00:00.000Z","path":"2019/03/26/go_install/","text":"go编程语言是一个由Google开源的编程语言项目，它具有很强的表达能力、简洁高效，对并发特别友好，它是一个快速的、静态类型的编译型语言，感觉却像动态类型的解释型语言。 安装安装一般可以选择源码安装、官方提供的可执行文件安装，一般在不修改源码的情况话 直接选择下载官方提供的可执行文件或者直接下载二进制压缩包安装即可。 window 如果是可执行文件安装方式 引导用户安装成功的 会自动配置好go的环境变量 在命令行输入go 就能看到go命令行的帮助提示。 解压二进制文件安装方式 需要手动配置好go环境变量 运行go命令如下 $ goGo is a tool for managing Go source code.Usage: go &lt;command&gt; [arguments]The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages linux linux系统 下载并解压二进制之后需要手动设置go的环境变量 如go文件解压到目录/usr/local/go export GOROOT=/usr/local/goexport PATH=$PATH:$GOROOT/bin 此时就能使用go命令 看到帮助提示 说明安装成功。 命令行认识 go get 从远程下载package 需要安装与远程包匹配的代码管理工具，如 Git、SVN、HG 等 go run 运行go文件 go build 编译go文件 如果代码有误或者语法不正确会报错 go fmt 格式化代码格式 go install 编码包文件和整个程序 go test 运行测试文件 go语言中 xxx_test.go 以下划线test.go结束的文件名为测试文件 go doc 文件查看 go clean 删除缓存文件 godoc -http=:6060 可在本地启动一个文档服务器 和官方网站的一样哦，方便网络不好的情况下在本地浏览器打开http://localhost:6060 就能浏览文档。","tags":[{"name":"技术","slug":"技术","permalink":"https://blog.gitee.io/tags/技术/"},{"name":"go","slug":"go","permalink":"https://blog.gitee.io/tags/go/"}]},{"title":"再见2018 再见昨天","date":"2019-01-14T16:00:00.000Z","path":"2019/01/15/todo2018/","text":"自己逼自己回首一下过往 实在写不出东西来了 那么就随便写点流水账啦 ^_^ 2018年真滴过完啦 这一切似乎就在昨天、所有的景象就在眼前，今年是很特别的一年 因为在这一年完成了人生中的大事有那么几件。 这是在雾都(重庆)的第9个年头了 依稀记得刚来的时候和几个兄弟伙朝夕挤在一张不足1.5米宽的床上，没日没夜玩着电脑游戏，就连白天饭都顾不上吃 晚上只能去楼下夜市买冒菜吃，这种日子过得轻松(邋遢)了点，但是确实过得很开心 无忧无虑 自由自在的，可惜呀 再也回不去了。 后来工作了，每天都是早出晚归的，上班下班，忙得事情可多了，本身干这一行过得相当无趣，有那么一段时间甚至觉得都得了抑郁症了，比较有意义的是每天都会研究或者发明一些小玩意，当然不限于小软件之类的东西，以至于坚持到了现在，陆陆续续的换掉了几份工作 总体来说还是跟着自己的意向在进步，在这段时光里机缘巧合的情况下 遇到了我心爱老婆(也就是前女友)，是她让我在这个冰冷的城市有了归宿感，也是她让我有了努力的理由，虽然我们的日子过得很平凡，但是内心多了一份踏实和牵挂，在我们的共同努力下也装修好了我们的第一套房屋，也算是暂时告别了租房生涯啦！上帝把时间同时共享给了世间的每一个人，我们在一天天的变老，有的亲人也在一天天离开我们，每次回到老家总觉得少点什么。 这一年是到目前为止 技术生涯最颓废的一年，就像我以前一个同事(庚)说的，一直在“吃老本”，可能这也是技术人的一个通病，基本上我的工作上已经不涉及前端了，想想之前唯一能吹就是前端了，没想到计划不如变化 竟然…。不过虽然没有专门研究前端了，但是我却收获到了其他的领域的东西，最后还是夸一下自己吧 通过这几年的历程，终究还是能够把自己养得一般般~~ 不畏过去不畏将来^_^。 最后18年没有太多想说的了，时常多陪陪亲人朋友 毕竟人生只有这么短短几十年。 希望大家都身体/心理健康、每天多开心一点，其次再是努力生活，努力工作，努力玩！","tags":[{"name":"随笔","slug":"随笔","permalink":"https://blog.gitee.io/tags/随笔/"}]},{"title":"svn版本控制迁移到git","date":"2018-11-26T16:00:00.000Z","path":"2018/11/27/svnToGit/","text":"获得原 SVN 仓库使用的作者名字列表 因为导入到git需要配置原作者(svn提交人)和git账户的映射关系 其格式为： vim authors-transform.txt taoxs = xsTao &lt;xsTao@xxx.com&gt;lh1 = lh1 &lt;lhl@xxx.com&gt; 利用 git svn 克隆 SVN 仓库 新建一个目录作为 Git 项目的根目标，并进入到该目录中，把前面创建的authors-transform.txt用户映射关系复制到这个目录中，执行下面的命令： git svn clone $&#123;SVN REP URL &#125; --no-metadata -A authors-transform.txt 如果SVN的体积/文件有点大得话，那么该过程会持续较长时间。耐心等待 执行完成后基本上就OK了，把SVN版本库搬到git上来了，但是这个时候还需要提交到远程仓库 提交GIT版本库到远程仓库进入刚刚生成的版本库中 用下面的命令查看分支列表 有不需要的可以删除 git show-ref 将refs/remotes 下剩余的引用移动为本地分支 cp -Rf .git/refs/remotes/* .git/refs/heads/rm -Rf .git/refs/remotes 为本地仓库添加远程仓库地址 就可以commit/push了 git remote add origin ''http://192.168.1.3:8090/osTeam/test.git' 现在就完美从SVN迁移到GIT了 并保留了原SVN的提交版本记录信息。","tags":[{"name":"svn","slug":"svn","permalink":"https://blog.gitee.io/tags/svn/"},{"name":"git","slug":"git","permalink":"https://blog.gitee.io/tags/git/"}]},{"title":"让mysql支持emoji表情","date":"2018-10-21T16:00:00.000Z","path":"2018/10/22/mysql_emoji_support/","text":"什么是emoji emoji就是表情符号 emoji的创造者是日本人栗田穰崇(Shigetaka Kurita) 在数据库的编码不为utf8mb4，利用java mysql驱动保存含有表情符号的数据会出现异常java.sql.SQLException: Incorrect string value: &#39;\\xF0\\x9F\\x94\\xA5&#39; for column mysql中存储emoji表情符号 以前做应用软件的时候 通常把mysql的字符编码设置为utf-8，但是这个编码却不支持emoji表情 是因为utf-8编码的一个字符最多只能存储3个字节，但一个emoji表情为4个字节，所以utf8不支持存储emoji表情。 mysql中的utf8mb4却能支持emoji表情符号 所以我们只需要更改mysql的数据库编码格式为utf8mb4就能支持了。当然了表和字段也需要是这个编码的，在不手动设置表/字段编码的情况下，会默认继承数据库的编码格式。如果手动修改为字段或者表的编码 也需要手动把表和字段修改为utf8mb4 物理机安装的数据库数据字符编码修改方式修改mysql的配置文件/etc/mysql/my.cnf 并重启数据库 如果是编译安装 有可能不是这个目录噢~ [mysql]default-character-set=utf8mb4 云数据库 如阿里云的RDS 修改数据库编码方式 找到指定库的参数设置中找到character_set_server修改为utf8mb4并重启数据库 客户端驱动连接的URLjdbc:mysql://rr-xxxxx40.mysql.rds.aliyuncs.com:3306/db_test?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;characterEncoding=utf-8 这样就能在mysql中存储emoji表情符号了,utf8mb4是utf-8的超集 意味着反正utf8mb4也能兼容utf-8 在不考虑存储大小的情况下 可以直接把库设置为utf8mb4以免后续烦恼。 当前测试的数据版本为RDS mysql 5.6.16JAVA驱动版本为5.1.30","tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.gitee.io/tags/mysql/"},{"name":"emoji","slug":"emoji","permalink":"https://blog.gitee.io/tags/emoji/"},{"name":"mysql支持emoji表情","slug":"mysql支持emoji表情","permalink":"https://blog.gitee.io/tags/mysql支持emoji表情/"}]},{"title":"springCloud feign使用/优化总结","date":"2018-09-29T16:00:00.000Z","path":"2018/09/30/springcloud-feign/","text":"基于springCloud Dalston.SR3版本 1.当接口参数是多个的时候 需要指定@RequestParam 中的value来明确一下。/** * 用户互扫 * @param uid 被扫人ID * @param userId 当前用户ID * @return */@PostMapping(REQ_URL_PRE + \"/qrCodeReturnUser\")UserQrCode qrCodeReturnUser(@RequestParam(\"uid\") String uid,@RequestParam(\"userId\") Integer userId); 2.接口参数为对象的时候 需要使用@RequestBody注解 并采用POST方式。3.如果接口是简单的数组/列表参数 这里需要使用Get请求才行@GetMapping(REQ_URL_PRE + \"/getUserLevels\")Map&lt;Integer, UserLevel&gt; getUserLevels(@RequestParam(\"userIds\") List&lt;Integer&gt; userIds); 4.直接可以在@FeignClient中配置降级处理方式 对于一些不重要的业务 自定义处理很有帮助@FeignClient(value = \"cloud-user\", fallback = IUsers.UsersFallback.class) 5.feign默认只有HystrixBadRequestException异常不会走熔断，其它任何异常都会进入熔断，需要重新实现一下ErrorDecoder包装业务异常 示例：https://github.com/peachyy/feign-support 6. feign HTTP请求方式选择feign默认使用的是基于JDK提供的URLConnection调用HTTP接口，不具备连接池。所以资源开销上有点影响，经测试JDK的URLConnection比Apache HttpClient快很多倍。但是Apache HttpClient和okhttp都支持配置连接池功能。具体选择需要权衡 7.默认不启用hystrix 需要手动指定feign.hystrix.enabled=true 开启熔断8.启用压缩也是一种有效的优化方式feign.compression.request.enabled=truefeign.compression.response.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/json 9.参数相关调优hystrix线程数设置设置参数hystrix.threadpool.default.coreSize 来指定熔断隔离的线程数 这个数需要调优，经测试 线程数我们设置为和提供方的容器线程差不多，吞吐量高许多。 第一次访问服务出错的问题启用Hystrix后，很多服务当第一次访问的时候都会失败 是因为初始化负载均衡一系列操作已经超出了超时时间了 默认的超时时间为1S，设置参数超时时间hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=30000 可解决这个问题。 负载均衡参数设置设置了Hystrix的超时参数会 还需设置一下ribbon的相关参数 这些参数和Hystrix的超时参数有一定的逻辑关系请求处理的超时时间 ribbon.ReadTimeout=120000请求连接的超时时间 ribbon.ConnectTimeout=30000","tags":[{"name":"feign","slug":"feign","permalink":"https://blog.gitee.io/tags/feign/"},{"name":"springCloud","slug":"springCloud","permalink":"https://blog.gitee.io/tags/springCloud/"}]},{"title":"rocketmq4.x批量消息投递","date":"2018-08-01T16:00:00.000Z","path":"2018/08/02/rocketmq_batch_message/","text":"批量发送消息可提高传递小消息的性能。同时也需要满足以下特征 批量消息要求必要具有同一topic、相同消息配置 不支持延时消息 建议一个批量消息最好不要超过1MB大小 示例 小于1MB String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"Order1\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"Order2\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"Order3\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 大于1MB也可以使用分割消息的方式进行多次批量发送。","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"rocketmq4.x延时消息","date":"2018-07-31T16:00:00.000Z","path":"2018/08/01/rocketmq_delay_message/","text":"rocketmq提供一种延时消息的解决方案，就是在特定的时间到了，消息才会被投递出去供consumer消费。总体来是简单的场景是满足了，但是需要注意的是延时的时间是需要按照默认配置的延时级别去配置的，而不是随意设置消息的延时时间。 如果想不受延时级别的约束 可以参考之前的一遍文章http://blog.seoui.com/2017/08/19/delayqueue/ 默认的延迟级别 messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 这个配置下标从1开始 比如级别2是延时5秒、级别5是延时1分钟。默认配置在不满足需求的情况下，可以在broker配置文件加入messageDelayLevel参数覆盖默认的延时级别配置。 示例和普通的消息不同之处在于Producer在发送消息的时候 需要设置message.setDelayTimeLevel();延迟级别方法。其他参数和消费端的写法并与不同之处。 Producerpublic class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); //延时的级别为3 对应的时间为10s 就是发送后延时10S在把消息投递出去 message.setDelayTimeLevel(3); producer.send(message); &#125; producer.shutdown(); &#125;&#125; Consumerpublic class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\"); consumer.subscribe(\"TestTopic\", \"*\"); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for (MessageExt message : messages) &#123; System.out.println(\"ok!\"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); &#125;&#125;","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"rocketmq有序消息","date":"2018-07-23T16:00:00.000Z","path":"2018/07/24/rocketmq_ordered_message/","text":"RocketMQ提供的顺序消费消息实现是使用的FIFO 先进先出算法 Producer消息发送 public class Producer &#123; public static void main(String[] args) throws UnsupportedEncodingException &#123; try &#123; MQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.start(); String[] tags = new String[] &#123;\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"&#125;; for (int i = 0; i &lt; 100; i++) &#123; int orderId = i % 10; Message msg = new Message(\"TopicTestjjj\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.printf(\"%s%n\", sendResult); &#125; producer.shutdown(); &#125; catch (MQClientException | RemotingException | MQBrokerException | InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Consumer消息消费public class Consumer { public static void main(String[] args) throws MQClientException { DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() { AtomicLong consumeTimes = new AtomicLong(0); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) { context.setAutoCommit(false); System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); this.consumeTimes.incrementAndGet(); if ((this.consumeTimes.get() % 2) == 0) { return ConsumeOrderlyStatus.SUCCESS; } else if ((this.consumeTimes.get() % 3) == 0) { return ConsumeOrderlyStatus.ROLLBACK; } else if ((this.consumeTimes.get() % 4) == 0) { return ConsumeOrderlyStatus.COMMIT; } else if ((this.consumeTimes.get() % 5) == 0) { context.setSuspendCurrentQueueTimeMillis(3000); return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; } return ConsumeOrderlyStatus.SUCCESS; } }); consumer.start(); System.out.printf(\"Consumer Started.%n\"); } }","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"rocketmq简单消息发送","date":"2018-07-23T16:00:00.000Z","path":"2018/07/24/rocketmq_simple_message/","text":"有以下3种方式发送RocketMQ消息 可靠同步发送 reliable synchronous 可靠异步发送 reliable asynchronous 单向发送 one-way transmission 可靠同步发送 主要运用在比较重要一点消息传递/通知等业务 public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"test\"); producer.start(); for (int i = 0; i &lt; 100; i++) &#123; Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); //Call send message to deliver message to one of brokers. SendResult sendResult = producer.send(msg); System.out.printf(\"%s%n\", sendResult); &#125; //Shut down once the producer instance is not longer in use. producer.shutdown(); &#125;&#125; 可靠异步发送 通常用于对发送消息响应时间要求更高/更快的场景 public class AsyncProducer { public static void main( String[] args) throws MQClientException, InterruptedException, UnsupportedEncodingException { DefaultMQProducer producer = new DefaultMQProducer(\"Jodie_Daily_test\"); producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 10000000; i++) { try { final int index = i; Message msg = new Message(\"Jodie_topic_1023\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); //重点在这里 异步发送回调 producer.send(msg, new SendCallback() { @Override public void onSuccess(SendResult sendResult) { System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); } @Override public void onException(Throwable e) { System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); } }); } catch (Exception e) { e.printStackTrace(); } } producer.shutdown(); } } 单向发送适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。 只发送消息，不等待服务器响应，只发送请求不等待应答。此方式发送消息的过程耗时非常短，一般在微秒级别。 public class OnewayProducer { public static void main(String[] args) throws Exception{ DefaultMQProducer producer = new DefaultMQProducer(\"Test\"); producer.start(); for (int i = 0; i &lt; 100; i++) { //Create a message instance, specifying topic, tag and message body. Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); //Call send message to deliver message to one of brokers. producer.sendOneway(msg); } //Shut down once the producer instance is not longer in use. producer.shutdown(); } }","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"rocketmq广播消息","date":"2018-07-23T16:00:00.000Z","path":"2018/07/24/rocketmq_broadcast_message/","text":"发布与模式实现。广播就是向一个主题的所有订阅者发送同一条消息。 在发送消息的时候和普通的消息并与不同之处，只是在消费端做一些配置即可。 Consumer消息消费public class BroadcastConsumer { public static void main(String[] args) throws MQClientException { DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); //设置为广播模式 默认为CLUSTERING模式 consumer.setMessageModel(MessageModel.BROADCASTING); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() { AtomicLong consumeTimes = new AtomicLong(0); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) { context.setAutoCommit(false); System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeOrderlyStatus.SUCCESS; } }); consumer.start(); System.out.printf(\"Consumer Started.%n\"); } }","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"rocketmq4.x快速入门指南","date":"2018-07-23T16:00:00.000Z","path":"2018/07/24/rocketmqinstall/","text":"以下采用的是apache rocketmq 4.2.0版本 相关文档如下 快速体验： http://blog.seoui.com/2018/07/24/rocketmqinstall/ rocketmq简单消息发送： http://blog.seoui.com/2018/07/24/rocketmq_simple_message/ rocketmq有序消息： http://blog.seoui.com/2018/07/24/rocketmq_ordered_message/ rocketmq广播消息： http://blog.seoui.com/2018/07/24/rocketmq_broadcast_message/ rocketmq延时消息： http://blog.seoui.com/2018/08/01/rocketmq_delay_message/ rocketmq批量消息： http://blog.seoui.com/2018/08/02/rocketmq_batch_message/下载源码并编译 #downloadwget http://mirrors.hust.edu.cn/apache/rocketmq/4.2.0/rocketmq-all-4.2.0-source-release.zip unzip rocketmq-all-4.2.0-source-release.zipcd rocketmq-all-4.2.0/mvn -Prelease-all -DskipTests clean install -Ucd distribution/target/apache-rocketmq 目录 distribution/target/apache-rocketmq 是编译后的产出 可复制这个目录安装MQ的机器上,这里复制到/usr/local/ 共享一份编译后的文件方便以后再次使用 https://pan.baidu.com/s/1ZyUOKFm-t8cJDQuH68QydQ 启动NameServercd /usr/local/apache-rocketmqnohup sh bin/mqnamesrv &amp; 查看日志tail -f ~/logs/rocketmqlogs/namesrv.log 启动成功后打印The Name Server boot success… 启动Broker这里需要注意一下就是 如果当前机器上有多张网卡的情况,最好指定一个IP, 有可能消费端正好就和MQ选择的网卡不通 vim conf/broker.conf 指定IP 访问多网卡的情况 并配置好nameserver的地址 也可以使用mqbroker启动参数-n指定nameserver地址 brokerIP1=192.168.1.2namesrvAddr=192.168.1.3:9876 启动broker -c参数指定配置文件 nohup sh bin/mqbroker -c config/broker.properties &amp; 查看一下集群列表 sh bin/mqadmin clusterList -n localhost:9876 发送/接收消息Producer export NAMESRV_ADDR=localhost:9876sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 能发送表示OK Consumer export NAMESRV_ADDR=localhost:9876sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 能接收到之前发送的消息表示OK 关闭MQ sh bin/mqshutdown brokersh bin/mqshutdown namesrv","tags":[{"name":"rocketmq","slug":"rocketmq","permalink":"https://blog.gitee.io/tags/rocketmq/"}]},{"title":"jenkins环境搭建","date":"2018-06-21T16:00:00.000Z","path":"2018/06/22/jenkinsinstall/","text":"Jenkins是基于JVM开发的，所以安装之前需要先确保装好JVM的运行环境JRE 这里采用TOMCAT的部署方式安装。 下载WAR wget http://mirrors.jenkins.io/war-stable/2.121.1/jenkins.war 然后复制到tomcat的webapps目录中 执行bin/startup.sh启动 ，bin/shutdown.sh 关闭。 首次启动访问的时候会提示你安装插件 选中推荐的一些插件就基本够用了。也可以在系统设置-&gt;插件管理中手动安装。 参考 https://jenkins.io/doc/","tags":[{"name":"jenkins","slug":"jenkins","permalink":"https://blog.gitee.io/tags/jenkins/"}]},{"title":"nexus3.X环境搭建","date":"2018-06-21T16:00:00.000Z","path":"2018/06/22/nexusinstall/","text":"nexus3比以前的版本相比 多支持了管理不同的格式 比如Docker npm NuGet maven …等 下载编译好的二进制安装 wget https://sonatype-download.global.ssl.fastly.net/repository/repositoryManager/3/nexus-3.12.1-01-unix.tar.gz tar -zxf nexus-3.12.1-01-unix.tar.gz cd nexus-3.12.1-01/ bin/nexus start 默认的端口号为8081 nexus3.x和以前的版本界面都有很大的改变 需要注意一下。 其他默认配置在文件etc/nexus-default.properties中 需要修改的关注一下。 参考 https://www.sonatype.com/","tags":[{"name":"nexus3","slug":"nexus3","permalink":"https://blog.gitee.io/tags/nexus3/"}]},{"title":"gitlab环境搭建","date":"2018-06-21T16:00:00.000Z","path":"2018/06/22/gitlabinstall/","text":"操作系统：centos7gitlab： gitlab-ee 如果是其他环境 安装过程类似 安装必要依赖 sudo yum install -y curl policycoreutils-python openssh-serversudo systemctl enable sshdsudo systemctl start sshdsudo firewall-cmd --permanent --add-service=httpsudo systemctl reload firewalld 安装postfix依赖 用来发送邮件 不需要可以省略 sudo yum install postfixsudo systemctl enable postfixsudo systemctl start postfix 获取并安装GitLab包 添加package curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | sudo bash 执行安装操作 设置一个EXTERNAL_URL表示安装后的gitlab地址,如果需要HTTPS 那么需求安装好之后额外配置 sudo EXTERNAL_URL=\"http://172.30.34.6/\" yum install -y gitlab-ee 如果没有报错信息 就可以使用前面配置的EXTERNAL_URL参数在浏览器上打开GITLAB了，当前配置的URL为:http://172.30.34.6/ 安装之后首次访问设置 安装好之后默认需要使用root账户登录，这个时候浏览器会重定向到为root设置初次密码的页面，跟着操作做就对了。 Gitlab安装好之后提供了一系列的命令工具如：gitlab-ctl等等。 更多设置请参考官方文档 参考 https://about.gitlab.com/installation/#centos-7","tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://blog.gitee.io/tags/gitlab/"}]},{"title":"base64文件大小计算","date":"2018-05-08T16:00:00.000Z","path":"2018/05/09/base64_file_size/","text":"有时候图片被base64之后需要计算图片大小，因为被编码后全是字符，计算文件大小可以反序列化成文件之后再获取大小，但是会比较麻烦。简单介绍一种利用base64编码原理计算大小的方法。 编码原理要求把3个8位字节（3*8=24）转化为4个6位的字节（4*6=24），之后在6位的前面补两个0，形成8位一个字节的形式。 如果剩下的字符不足3个字节，用0填充，输出字符使用’=’，因此编码后输出的文本末尾可能会出现1或2个’=’ 示例找一张图片文件https://www.baidu.com/img/bd_logo1.png 下载到本地base64编码之后的图片显示结果如下 去掉base64编码中的前缀 data:image/png;base64, var baseStr=document.getElementById(\"imgcase\").getAttribute(\"src\"),tag=\"base64,\";baseStr=baseStr.substring(baseStr.indexOf(tag)+tag.length); 去掉base64编码中的=号 var eqTagIndex=baseStr.indexOf(\"=\");baseStr=eqTagIndex!=-1?baseStr.substring(0,eqTagIndex):baseStr; 计算文件流大小 var strLen=baseStr.length;var fileSize=strLen-(strLen/8)*2alert(\"文件大小:\"+fileSize); 完整代码：https://demohubs.github.io/frontendLab/baseimgfileSize.html","tags":[{"name":"base64","slug":"base64","permalink":"https://blog.gitee.io/tags/base64/"}]},{"title":"JVM远程调试功能","date":"2018-04-17T16:00:00.000Z","path":"2018/04/18/jvmremote-debug/","text":"有时候想调试线上的程序 可以启用远程调试功能 在本地调试远程代码。 远程JVM启用调试模式 /usr/local/jdk/bin/java -server -Xms256m -Xmx256m -XX:PermSize=64m -XX:MaxPermSize=128m -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=1506 -jar /home/web/api-1.0-SNAPSHOT/lib/api-1.0-SNAPSHOT.jar --spring.config.location=file:/home/web/api-1.0-SNAPSHOT/conf/ -XDebug 表示虚拟机启用调试功能-Xrunjdwp 加载JDWPtransport 调试程序JVM使用的进程之间通讯方式dt_socket socket通讯server=y/n JVM是否需要作为调试服务器执行address 调试服务器监听的端口号suspend=y/n 调试客户端建立连接之后启动虚拟机 JVM启动之后用验证监听的端口号是否生效了 netstat -anp | grep 1506 tcp 0 0 0.0.0.0:1506 0.0.0.0:* LISTEN 4841/java 本地调试配置 然后debug启动 访问远程服务器某个服务 在本地就支持打断点调试了。","tags":[{"name":"jvm","slug":"jvm","permalink":"https://blog.gitee.io/tags/jvm/"},{"name":"远程调试","slug":"远程调试","permalink":"https://blog.gitee.io/tags/远程调试/"}]},{"title":"Lua在Redis中的应用","date":"2018-01-26T16:00:00.000Z","path":"2018/01/27/redis-lua/","text":"redis从2.6版本开始内置支持Lua解释器，解释器提供了3个函数来处理redis的命令redis.call() redis.pcall()和 redis.log,同时redis 也保证脚本会以原子性的方式执行。这是一个很重要的因素。 本文涉及到的命令有 EVAL EVALSHA SCRIPT LOAD SCRIPT FLUSH SCRIPT EXISTS SCRIPT KILL redis.call()， redis.pcall() 函数的区别就是处理错误异常的情况不同，其他的功能是一样的 具体使用哪个看需求而论 redis.call() 执行命令的过程中发生错误时，脚本会停止执行，并返回一个脚本错误 redis.pcall() 执行命令的过程中发生错误时，脚本会继续执行，但是会记录错误信息 返回一个带 err 域的 Lua 表(table) redis.log(loglevel, message) 触发redis记录日志 日志级别有 redis.LOG_DEBUG redis.LOG_VERBOSE redis.LOG_NOTICE redis.LOG_WARNING EVALEVAL命令对 Lua 脚本进行执行求值。 语法：EVAL script numkeys key [key …] arg [arg …] script lua脚本内容 注意的是脚本不应该是Lua函数。 numkeys 表示指定键名参数的个数。 key [key ...] 表示脚本对应的key值列表 在脚本中可以使用KEYS[1] KEYS[2] KEYS[3] KEYS[n] n从1开始 。 arg [arg ...] 命名行中传递的参数列表 在脚本中可以使用ARGV[1] ARGV[2] ARGV[3] ARGV[n] n从1开始 。 一个示例胜过千言万语的解释 eval \"return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;\" 2 id name 3 mytest 执行上面脚本返回 1) \"id\"2) \"name\"3) \"2\"4) \"mytest\" EVALSHA 此命令和EVAL的区别是EVAL每次都需要传入脚本的主体内容，对网络带宽不是很友好。而EVALSHA命令正好可以解决这个问题。 语法： EVALSHA sha1 numkeys key [key …] arg [arg …] sha1 缓存中的sha值 这个值可以利用SCRIPT LOAD生成 numkeys 表示指定键名参数的个数。 key [key ...] 表示脚本对应的key值列表 在脚本中可以使用KEYS[1] KEYS[2] KEYS[3] KEYS[n] n从1开始 。 arg [arg ...] 命名行中传递的参数列表 在脚本中可以使用ARGV[1] ARGV[2] ARGV[3] ARGV[n] n从1开始 。 &gt; SCRIPT LOAD \"return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;\"\"a42059b356c875f0717db19a51f6aaca9ae659ea\"&gt; EVALSHA a42059b356c875f0717db19a51f6aaca9ae659ea 2 id name 2 mytest1) \"id\"2) \"name\"3) \"2\"4) \"mytest\"&gt; 1、首先利用SCRIPT LOAD把脚本的主体缓存在redis中,会返回一个sha的key2、EVALSHA 执行命令 把sha带上 其他的和eval没有区别。 脚本缓存 redis保证了所有运行过的脚本都能缓存起来 前面也提到过使用SCRIPT LOAD也能将脚本缓存并返回sha值，那么也能使用SCRIPT FLUSH清空脚本缓存 SCRIPT LOAD 加载脚本到缓存中 SCRIPT FLUSH 清除所有 Lua 脚本缓存。 SCRIPT EXISTS 判断sha值是否已经缓存好了，返回值为 0 和 1 ，后者表示存在于缓存中，在程序开发中非常有用 比如 redis出现了什么异常情况后，脚本缓存被清空了，或者被人为执行了SCRIPT FLUSH命令，这个时候就可以优先尝试一下SCRIPT EXISTS命令如果返回0表示不存在 就需要先执行SCRIPT LOAD先把脚本加载到缓存中之后再执行 SCRIPT KILL 杀死当前正在运行的 Lua 脚本，当且仅当这个脚本没有执行过任何写操作时，这个命令才生效。 SCRIPT KILL 执行成功返回OK，其他情况返回错误信息 业务场景案例 spring-cloud-gateway springc cloud 网关限流 需要原子操作的零散逻辑 分布式限流 ….","tags":[{"name":"redis","slug":"redis","permalink":"https://blog.gitee.io/tags/redis/"},{"name":"lua","slug":"lua","permalink":"https://blog.gitee.io/tags/lua/"}]},{"title":"回想我的2017年","date":"2018-01-01T16:00:00.000Z","path":"2018/01/02/think2017/","text":"时光匆匆而去 好像2017年才刚刚开始就结束了，时间留下的仅有一些残留的记忆罢了。 无趣的时间轴 3月份 购买了人生第一套房子 5月份 之前公司还可以 就是不想安于现状，所有离职换到目前所待的一家小创业公司。ps: 几乎是天天加班哇，简直就没有时间写东西和思考人生，每天都在忙碌着。 6月份 终于开始了房奴的时代。 7月份 去年开了一家美业店，一直利润不佳，所以转出去了 11月份 和相恋2年的女朋友终于修成正果，拍了婚纱照并定了春节之后几天结婚。 回想实在点的吧 在年初的时候就给自己定下一些技术目标，到了现在这个时候确实也没有完成，总结了一下 自身原因吧，能坚持做一件事情并且一直坚持下去真的很不简单，这一年里陆续看了一些框架源码比如说 spring、mybatis、dubbo,grpc,canal,zuul,ribbon 不能说全部都完全理解到了 但是还是学到很多设计理念和实现方法，很惭愧只写了17篇博文，更加扩展了redis的使用场景范围，这种中间件确实是太强悍了，解决了很多比较难攻克的问题 比如做一些高速缓存、排序、分布式等。学习了groovy scala 语言 不过都是搞起玩的，没有运用到工作环境中去，另外还学了一下lua 是个很不错的东西。 关于微服务架构改造在5月份之前 也就是上一家公司大胆的尝试了一次 效果还很不错，技术选型也就是在当下比较热门的spring cloud技术栈，选择了基于docker容器的部署方式，原计划是选用Kubernetes,但是由于资源限制没有选用这种专业的容器集群编排工具，而是使用简单的docker compose 解决容器编排的问题。 进入计算机这个圈子最初是因为比较喜欢搞前端，学习了html css javascript 后来涉及到业务系统，熟悉了 c# java 之后就没有专门做前端方面的事情。从2017年初开始已经完成没有涉及到前端的工作了，想想真是搞笑，造化弄人啊！！！不过现在依然对前端比较有兴趣 只是没有太多的时间研究前端方面的技术了。有限的时间里 只能选择放弃一部分，更认真的对待另一部分了。 2018年如何书写 最近确实迷失了方向，没有了目标，惶恐 我最担心的就是现在这个样子 暂时写不出来了 。但是生活方面还是希望过得简单、开心、健康 对了还有多多赚钱。","tags":[{"name":"思考","slug":"思考","permalink":"https://blog.gitee.io/tags/思考/"}]},{"title":"nginx-http-concat资源文件合并模块","date":"2017-11-19T16:00:00.000Z","path":"2017/11/20/nginx-concat/","text":"网页中引入多个CSS和JS的时候，浏览器会发出很多(css个数+js个数)次网络请求，甚至有的网页中有数十个以上的CSS或JS文件，用户体验特别不好，正好可以利用nginx-http-concat nginx模块简单的把这个问题解决好。 安装模块首先去拉取nginx源码 并解压 wget http://nginx.org/download/nginx-1.7.3.tar.gz tar -zxf nginx-1.7.3.tar.gz 拉取nginx-http-concat 模块源码 git clone https://github.com/DemoHubs/nginx-http-concat.git 编译并安装源码 cd nginx-1.7.3 ./configure \\ --prefix=/usr/local/nginx \\ --without-http_rewrite_module \\ --without-http_gzip_module \\ --with-http_stub_status_module \\ --add-module=../nginx-http-concat make make install #验证安装能看到之前设置的编译模块算安装成功了 /usr/local/nginx/sbin/nginx -V cd /usr/local/nginx 配置http-concat在location 更改一下配置 concat on; concat_max_files 20; concat_unique off; concat_types text/css application/javascript; concat 表示启用concat模块 concat_max_files 文件合并的最大个数 concat_unique 是否允许css和js合并到同一个文件 默认为on 正常情况下这里我们不需要开启 设置off就好了 concat_delimiter 每个文件合并的分隔符号 一般设置为\\n 不设置默认就是 concat_ignore_file_error 默认为off 忽略合并的文件有错误的情况 比如403 或 404 如果要使用concat的功能的时候 需要在URL 中加上??两个问号来告诉nginx此次请求使用文件合并的方式获取资源 完整配置 location / { root html; index index.html index.htm; concat on; concat_max_files 20; concat_unique off; concat_types text/css application/javascript; } 测试结果首先简单的在nginx安装目录的html文件夹里面创建几个js和css来方便我们合并测试 echo \"var a1=1;\"&gt;a.js echo \"var a2=2;\"&gt;a2.js echo \"var a3=3;\"&gt;a3.js echo \"a{color:red}\"&gt;a.css echo \"a{border:1px solod green;}\"&gt;a1.css echo \"a{border:1px solod red;}\"&gt;a2.css 创建好之后的目录视图 ll /usr/local/nginx/html -rw-r--r-- 1 root root 537 11月 20 17:08 50x.html -rw-r--r-- 1 root root 27 11月 20 17:23 a1.css -rw-r--r-- 1 root root 25 11月 20 17:24 a2.css -rw-r--r-- 1 root root 10 11月 20 17:22 a2.js -rw-r--r-- 1 root root 10 11月 20 17:23 a3.js -rw-r--r-- 1 root root 13 11月 20 17:23 a.css -rw-r--r-- 1 root root 10 11月 20 17:22 a.js -rw-r--r-- 1 root root 612 11月 20 17:08 index.html 启动nginx sbin/nginx 这个时候再浏览器上访问 需要在URL 中加上??两个问号来告诉nginx此次请求使用文件合并的方式获取资源 浏览器访问：http://192.168.139.205/??a.css,a1.css,a2.css 结果包含了a.css,a1.css,a2.css的css 浏览器访问：http://192.168.139.205/??a.js,a2.js,a3.js结果包含了a.js,a2.js,a3.js的js 如果资源文件被缓存了 想更新可以加个版本号 就会从服务器上取最新文件 &lt;link rel=\"stylesheet\" href=\"??foo1.css,foo2.css,subdir/foo3.css?v=2345\" /&gt; 如果你是使用的tengine那么这个模块原生支持 不用手动安装","tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.gitee.io/tags/nginx/"}]},{"title":"NFS 安装与配置","date":"2017-10-29T16:00:00.000Z","path":"2017/10/30/nfs-config/","text":"NFS通常用于网络中的多台计算机实现共享存储。 由于测试环境没有购买阿里云的NFS，所以自己搭建一个NFS文件系统，实现一些比如上传图片，静态资源等同享功能。 下面的测试是在CentOS release 6.8 (Final)中进行的。其他的系统略有不同。 网络环境 ： nfs服务器IP: 192.168.18.183 nfs客户端IP: 192.168.18.182 服务器安装yum install nfs-utils rpcbind 配置需要共享的目录more /etc/exports /home/www *(rw,async,no_root_squash,no_subtree_check) 关于配置文件exports的一些参数说明 rw：read-write，可读写；ro：read-only，只读；sync：同步写入（文件同时写入硬盘和内存），适用在通信比较频繁且实时性比较高的场合async：异步写入（文件先写入内存，稍候再写入硬盘），性能较好（速度快），适合超大或者超多文件的写入，但有数据丢失的风险，比如突然断电等情况；root_squash（默认）：将来访的root用户映射为匿名用户或用户组；no_root_squash：来访的root用户保持root帐号权限（可能会不安全）；no_all_squash（默认）：访问用户先与本机用户匹配，匹配失败后再映射为匿名用户或用户组；all_squash：将来访的所有用户映射为匿名用户或用户组；secure（默认）：限制客户端只能从小于1024的tcp/ip端口连接服务器；insecure：允许客户端从大于1024的tcp/ip端口连接服务器；anonuid：匿名用户的UID值，通常是nobody或nfsnobody，可以在此处自行设定；anongid：匿名用户的GID值；no_subtree_check：如果NFS输出的是一个子目录，则无需检查其父目录的权限（可以提高效率） 启动nfs服务器service rpcbind startservice nfs start 查看是否启动成功，能看到前面在/etc/exports文件中设置的共享目录 则可以认为启动成功了。 showmount -e localhostExport list for localhost:/home/www * 客户端安装 客户端也是需要安装这两个软件 区别是安装好之后不需要启动。 yum install nfs-utils rpcbind 挂载NFS目录挂载的时候需要注意的是 如果挂载的目录当前已经存在 挂载后默认会覆盖掉。 mount -t nfs 192.168.18.183:/home/www /home/www 这个时候就挂载成功了，尝试修改客户端/home/www的文件 会立即同步到服务端的/home/www下面。同时服务端更新了文件也会立即同步到客户端。如果文件很大的话 会有一个网络延时，所以这个需要权衡 当然内网传输还是很快的。","tags":[{"name":"NFS","slug":"NFS","permalink":"https://blog.gitee.io/tags/NFS/"}]},{"title":"nexus3 添加第三方本地文件jar到仓库","date":"2017-10-22T16:00:00.000Z","path":"2017/10/23/nexus3-uploadfile/","text":"因为nexus3和nexus2手动上传第三方jar有点区别 故记录一下。 如上传京东 open-api-sdk-2.0.jar 首先创建一个目录 方便执行上传的时候url参数 也可以不创建 mkdir jd &amp;&amp; cd jd 简单的创建一个POM文件 vi open-api-sdk-2.0.pom 和把第三方jar文件放在此目录下 &lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.jd&lt;/groupId&gt; &lt;artifactId&gt;open-api-sdk&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt;&lt;/project&gt; 上传XML curl -v -u admin:admin123 --upload-file pom.xml http://localhost:8081/nexus/repository/maven-releases/com/jd/open-api-sdk/2.0/open-api-sdk-2.0.pom 上传JAR文件 curl -v -u admin:admin123 --upload-file open-api-sdk-2.0.jar http://localhost:8081/nexus/repository/maven-releases/open-api-sdk/2.0/open-api-sdk-2.0.jar 都上传成功后 在项目中d的pom.xml就可以使用 &lt;dependency&gt; &lt;groupId&gt;com.jd&lt;/groupId&gt; &lt;artifactId&gt;open-api-sdk&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;","tags":[{"name":"nexus3","slug":"nexus3","permalink":"https://blog.gitee.io/tags/nexus3/"}]},{"title":"nginx配置proxy_pass URL末尾加与不加/(斜线)的区别","date":"2017-10-10T16:00:00.000Z","path":"2017/10/11/nginxpass/","text":"假设访问路径的 /pss/bill.html 加/斜线的情况location /pss/ &#123; proxy_pass http://127.0.0.1:18081/;&#125; 被代理的真实访问路径为：http://127.0.0.1:18081/bill.html 不加/斜线的情况location /pss/ &#123; proxy_pass http://127.0.0.1:18081;&#125; 被代理的真实访问路径为：http://127.0.0.1:18081/pss/bill.html","tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.gitee.io/tags/nginx/"}]},{"title":"常用搜索引擎技巧","date":"2017-09-16T16:00:00.000Z","path":"2017/09/17/searcheng/","text":"在这个互联网资源繁多的情况下，想在网上找点东西，第一时刻想到的就是google一下、百度一下，但是从海量数据里更精准的找到你想要的内容的确需要一点小技巧。 双引号搜索 带了双引号的搜索都是精准搜索 简单理解就是不分词。 如：”笑松小站” 结果会搜索出包含搜索关键词的网页 + - 混合查询 有点类似于条件判断 注意一下符号前必须要带1个空格 如: 百度 -一下 结果会包含百度且不包含一下数据。 百度 +一下 结果会包含百度且包含一下数据。 书名搜索 使用《》括起来的关键字不会被分词 在百度有效 如:《中国共产党纪律处分条例》 site 搜索 指定搜索某个站点的网页 如:site:movie.douban.com 加勒比海盗 指定搜索豆瓣电影 关键字为 加勒比海盗 fileType 文件类型搜索 指定搜索某种文件类型 如:filetype:ppt docker 搜索结果为包含docker的ppt类型的文档。 Intitle 指定标题搜索 指定标题搜索包含某个关键字 与之同类型的还有intext。 如:intitle:战狼 、intext:战狼 inurl 包含URL搜索 在指定URL中搜索指定关键词 感觉和site有点类似。 如:inurl:seoui.com 测试 目前个人用的比较多的就是这几个 另外在Google上发现还有许多的高级搜索有待挖掘。 另外前段时间在网上找到了一个表格 在这里记录一下。 符号 描述 用法 allinanchor 限制搜索的词语是网页中链接内包含的关键词（可使用多个关键词） allinanchor:keyword1 keyword2 allinanchor 限制搜索的词语是网页中链接内包含的关键词（可使用多个关键词） allinanchor:keyword1 keyword2 allintext 限制搜索的词语是网页内文包含的关键词（可使用多个关键词） allintext:keyword1 keyword2 allintitle 限制搜索的词语是网页标题中包含的关键词（可使用多个关键词） allintitle:keyword1 keyword2 allinurl 限制搜索的词语是网页网址中包含的关键词（可使用多个关键词） inurl:keyword1 keyword2 filetype 限制所搜索的文件一个特定的格式 filetype:extension inanchor 限制搜索的词语是网页中链接内包含的关键词 inanchor:keyword intext 限制搜索的词语是网页内文包含的关键词 intext:keyword intitle 限制搜索的词语是网页标题中包含的关键词 intitle:keyword inurl 限制搜索的网页的地址 inurl:keyword site 限制所进行的搜索在指定的域名或网站内 site:domain","tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://blog.gitee.io/tags/搜索引擎/"}]},{"title":"断点续传下载原理实现","date":"2017-09-04T16:00:00.000Z","path":"2017/09/05/breakpoint-download/","text":"需求背景 动态创建的文件下载的时候希望浏览器显示下载进度 动态创建的文件希望能够分段下载 HTTP断点续传报文 要实现HTTP断点续传必须要简单了解以下几个报文。 Accept-Ranges 告诉客户端(浏览器..)服务器端支持断点续传 服务器端返回 Range 客户端告诉服务器端从指定的的位置/范围(这里值字节数)下载资源 客户端发出 Content-Range 服务器端告诉客户端响应的数据信息，在整个返回体中本部分的字节位置 服务器端返回 ETag 资源标识 非必须 服务器端返回 Last-Modified 资源最后一次更新的时间 非必须 服务器端返回 Range 的范围格式 表示0-499个字节范围：Range: bytes=0-499 表示最后500个字节范围：Range: bytes=-500 表示500字节开始到结束范围：Range: bytes=500- 表示第一个和最后一个字节：Range: bytes=0-0,-1 表示同时指定几个范围：Range: bytes=500-600,601-999 Content-Range 的数据格式 Content-Range: bytes 0-499/22036 ：表示返回0-499字节范围数据 资源一共22036个字节 原理 客户端发起请求 设置Range指定开始字节数或结束字节数 如果是从0开始也可以不用设置。 服务器端检查到客户端Range头 解析开始字节数以及结束字节数 并返回报文头 Accept-Ranges表示支持断点续传，Content-Range记录该次向客户端写入流的位置信息，然后再写入流到客户端。 服务端可以使用ETag Last-Modified 标记一下资源是否被修改。作一些验证工作，如果验证不通过则返回错误，非必须项。 java实现 OutputStream os=null; InputStream inputStream =null; File zipFile=null; try&#123; long zipStart=System.currentTimeMillis(); zipFile=createFile();//动态根据业务创建文件 if(logger.isInfoEnabled())&#123; logger.info(String.format(\"压缩ZIP 花费时间 %s(s) \", (System.currentTimeMillis()-zipStart)/1000)); &#125; if (zipFile.exists()) &#123; long downloadStart=System.currentTimeMillis(); inputStream= new BufferedInputStream(new FileInputStream(zipFile)); response.reset(); os=new BufferedOutputStream(response.getOutputStream()); String userAgent = request.getHeader(\"USER-AGENT\"); String fileName=zipFile.getName(); if (null != userAgent &amp;&amp; -1 != userAgent.indexOf(\"MSIE\")) &#123; fileName = URLEncoder.encode(fileName, \"UTF8\"); &#125; else if (null != userAgent &amp;&amp; -1 != userAgent.indexOf(\"Mozilla\")) &#123; fileName = new String(fileName.getBytes(\"utf-8\"), \"ISO-8859-1\"); &#125; response.setHeader(\"Accept-Ranges\", \"bytes\"); response.setHeader(\"Content-Disposition\", \"attachment;filename=\"+ fileName); response.setContentType(MediaType.APPLICATION_OCTET_STREAM_VALUE); long pos = 0, fileSize=zipFile.length(), last=fileSize-1; response.setHeader(\"ETag\",zipFile.getName(). concat(Objects.toString(fileSize)) .concat(\"_\").concat(Objects.toString(zipFile.lastModified()))); response.setDateHeader(\"Last-Modified\",zipFile.lastModified()); response.setDateHeader(\"Expires\", System.currentTimeMillis()+1000*60*60*24); if (null != request.getHeader(\"Range\")) &#123; response.setStatus(HttpServletResponse.SC_PARTIAL_CONTENT); try &#123; // 暂时只处理这2种range格式 1、RANGE: bytes=111- 2、Range: bytes=0-499 String numRang = request.getHeader(\"Range\") .replaceAll(\"bytes=\", \"\"); String[] strRange = numRang.split(\"-\"); if (strRange.length == 2) &#123; pos = Long.parseLong(strRange[0].trim()); last = Long.parseLong(strRange[1].trim()); &#125; else &#123; pos = Long.parseLong(numRang.replaceAll(\"-\", \"\").trim()); &#125; &#125; catch (NumberFormatException e) &#123; logger.error(request.getHeader(\"Range\") + \" error\"); pos = 0; &#125; &#125; long rangLength = last - pos + 1; String contentRange = new StringBuffer(\"bytes \"). append(String.valueOf(pos)). append(\"-\").append(last).append(\"/\"). append(String.valueOf(fileSize)).toString(); response.setHeader(\"Content-Range\", contentRange); response.addHeader(\"Content-Length\",Objects.toString(rangLength)); if(pos&gt;0)&#123; inputStream.skip(pos); &#125; byte[] buffer = new byte[1024*512];//每次以512KB 0.5MB的流量下载 int length = 0,sendTotal=0; while (sendTotal &lt; rangLength &amp;&amp; length!=-1) &#123; length = inputStream.read(buffer, 0, ((rangLength - sendTotal) &lt;= buffer.length ? ((int) (rangLength - sendTotal)) : buffer.length)); sendTotal = sendTotal + length; os.write(buffer, 0, length); &#125; if(os!=null)&#123; os.flush(); &#125; if(logger.isInfoEnabled())&#123; logger.info(String.format(\"下载 花费时间 %s(s) \", (System.currentTimeMillis()-downloadStart)/1000)); &#125; &#125; &#125;catch (Exception e)&#123; if(StringUtils.endsWithIgnoreCase(e.getMessage(),\"Broken pipe\"))&#123; logger.error(\"用户取消下载\"); &#125; logger.error(e.getMessage(),e); &#125;finally &#123; if(os!=null)&#123; try&#123; os.close(); &#125;catch (Exception e)&#123;&#125; &#125; if(inputStream!=null)&#123; try&#123; IOUtils.closeQuietly(inputStream); &#125;catch (Exception e)&#123;&#125; &#125; &#125;&#125; 比如google浏览器下载的时候就能看到下载进度以及暂停下载和恢复下载操作，也可以设置Range测试分段下载。","tags":[{"name":"断点续传","slug":"断点续传","permalink":"https://blog.gitee.io/tags/断点续传/"},{"name":"http","slug":"http","permalink":"https://blog.gitee.io/tags/http/"}]},{"title":"基于redis的延迟消息队列设计","date":"2017-08-18T16:00:00.000Z","path":"2017/08/19/delayqueue/","text":"需求背景 用户下订单成功之后隔20分钟给用户发送上门服务通知短信 订单完成一个小时之后通知用户对上门服务进行评价 业务执行失败之后隔10分钟重试一次 类似的场景比较多 简单的处理方式就是使用定时任务 假如数据比较多的时候 有的数据可能延迟比较严重,而且越来越多的定时业务导致任务调度很繁琐不好管理。 队列设计 目前可以考虑使用rabbitmq来满足需求 但是不打算使用,因为目前太多的业务使用了另外的MQ中间件。 开发前需要考虑的问题？ 及时性 消费端能按时收到 同一时间消息的消费权重 可靠性 消息不能出现没有被消费掉的情况 可恢复 假如有其他情况 导致消息系统不可用了 至少能保证数据可以恢复 可撤回 因为是延迟消息 没有到执行时间的消息支持可以取消消费 高可用 多实例 这里指HA/主备模式并不是多实例同时一起工作 消费端如何消费 当然初步选用redis作为数据缓存的主要原因是因为redis自身支持zset的数据结构(score 延迟时间毫秒) 这样就少了排序的烦恼而且性能还很高,正好我们的需求就是按时间维度去判定执行的顺序 同时也支持map list数据结构。 简单定义一个消息数据结构 private String topic;/***topic**/private String id;/***自动生成 全局惟一 snowflake**/private String bizKey;private long delay;/***延时毫秒数**/private int priority;//优先级private long ttl;/**消费端消费的ttl**/private String body;/***消息体**/private long createTime=System.currentTimeMillis();private int status= Status.WaitPut.ordinal(); 运行原理： 用Map来存储元数据。id作为key,整个消息结构序列化(json/…)之后作为value,放入元消息池中。 将id放入其中(有N个)一个zset有序列表中,以createTime+delay+priority作为score。修改状态为正在延迟中 使用timer实时监控zset有序列表中top 10的数据 。 如果数据score&lt;=当前时间毫秒就取出来,根据topic重新放入一个新的可消费列表(list)中,在zset中删除已经取出来的数据,并修改状态为待消费 客户端获取数据只需要从可消费队列中获取就可以了。并且状态必须为待消费 运行时间需要&lt;=当前时间的 如果不满足 重新放入zset列表中,修改状态为正在延迟。如果满足修改状态为已消费。或者直接删除元数据。 客户端 因为涉及到不同程序语言的问题,所以当前默认支持http访问方式。 添加延时消息添加成功之后返回消费唯一ID POST /push {…..消息体} 删除延时消息 需要传递消息ID GET /delete?id= 恢复延时消息 GET /reStore?expire=true|false expire是否恢复已过期未执行的消息。 恢复单个延时消息 需要传递消息ID GET /reStore/id 获取消息 需要长连接 GET /get/topic 用nginx暴露服务,配置为轮询 在添加延迟消息的时候就可以流量平均分配。 目前系统中客户端并没有采用HTTP长连接的方式来消费消息,而是采用MQ的方式来消费数据这样客户端就可以不用关心延迟消息队列。只需要在发送MQ的时候拦截一下 如果是延迟消息就用延迟消息系统处理。 消息可恢复 实现恢复的原理 正常情况下一般都是记录日志,比如mysql的binlog等。 这里我们直接采用mysql数据库作为记录日志。 目前打算创建以下2张表: 消息表 字段包括整个消息体 消息流转表 字段包括消息ID、变更状态、变更时间、zset扫描线程Name、host/ip 定义zset扫描线程Name是为了更清楚的看到消息被分发到具体哪个zset中。前提是zset的key和监控zset的线程名称要有点关系 这里也可以是zset key。 举个栗子 假如redis服务器宕机了,重启之后发现数据也没有了。所以这个恢复是很有必要的,只需要从表1也就是消息表中把消息状态不等于已消费的数据全部重新分发到延迟队列中去,然后同步一下状态就可以了。 当然恢复单个任务也可以这么干。 关于高可用分布式协调还是选用zookeeper吧。 如果有多个实例最多同时只能有1个实例工作 这样就避免了分布式竞争锁带来的坏处,当然如果业务需要多个实例同时工作也是支持的,也就是一个消息最多只能有1个实例处理,可以选用zookeeper或者redis就能实现分布式锁了。 最终做了一下测试多实例同时运行,可能因为会涉及到锁的问题性能有所下降,反而单机效果很好。所以比较推荐基于docker的主备部署模式。 扩展支持zset队列个数可配置 避免大数据带来高延迟的问题。 目前存在日志和redis元数据有可能不一致的问题 如mysql挂了,写日志不会成功。 设计图：","tags":[{"name":"延迟队列","slug":"延迟队列","permalink":"https://blog.gitee.io/tags/延迟队列/"},{"name":"redis","slug":"redis","permalink":"https://blog.gitee.io/tags/redis/"},{"name":"延迟消息","slug":"延迟消息","permalink":"https://blog.gitee.io/tags/延迟消息/"}]},{"title":"记一次Mysql5.7安装","date":"2017-07-01T16:00:00.000Z","path":"2017/07/02/mysql5_7install/","text":"下载 下载mysql5.7地址:wget https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.18-1.el6.x86_64.rpm-bundle.tar 另外分享一个百度云盘的下载链接 http://pan.baidu.com/s/1qYAuYBi 下载下来之后 得到一个mysql-5.7.18-1.el6.x86_64.rpm-bundle.tar 解压 得到以下rpm包 tar -vxf mysql-5.7.18-1.el6.x86_64.rpm-bundle.tar -rw-r--r-- 1 root root 470507520 Jul 1 23:05 mysql-5.7.18-1.el6.x86_64.rpm-bundle.tar-rw-r--r-- 1 7155 31415 23618836 Mar 20 02:40 mysql-community-client-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 335496 Mar 20 02:40 mysql-community-common-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 3747352 Mar 20 02:40 mysql-community-devel-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 39086508 Mar 20 02:40 mysql-community-embedded-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 135869292 Mar 20 02:40 mysql-community-embedded-devel-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 2177064 Mar 20 02:40 mysql-community-libs-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 1723180 Mar 20 02:40 mysql-community-libs-compat-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 159060212 Mar 20 02:41 mysql-community-server-5.7.18-1.el6.x86_64.rpm-rw-r--r-- 1 7155 31415 104881084 Mar 20 02:41 mysql-community-test-5.7.18-1.el6.x86_64.rpm 安装 这里主要安装 server 和client yum install libaio #首先安装软件包的依赖#依次安装rpm -ivh mysql-community-common-5.7.18-1.el6.x86_64.rpmrpm -ivh mysql-community-libs-5.7.18-1.el6.x86_64.rpmrpm -ivh mysql-community-client-5.7.18-1.el6.x86_64.rpmrpm -ivh mysql-community-server-5.7.18-1.el6.x86_64.rpm 另外附上安装之后的一些参数默认值 Files or Resources Location Client programs and scripts /usr/bin mysqld server /usr/sbin Configuration file /etc/my.cnf Data directory /var/lib/mysql Error log file For RHEL, Oracle Linux, CentOS or Fedora platforms: /var/log/mysqld.log For SLES: /var/log/mysql/mysqld.log Value of secure_file_priv /var/lib/mysql-files System V init script For RHEL, Oracle Linux, CentOS or Fedora platforms: /etc/init.d/mysqld For SLES: /etc/init.d/mysql For SLES: /etc/init.d/mysql Systemd service For RHEL, Oracle Linux, CentOS or Fedora platforms: mysqld For SLES: mysql Pid file /var/run/mysql/mysqld.pid Socket /var/lib/mysql/mysql.sock Keyring directory /var/lib/mysql-keyring Unix manual pages /usr/share/man Include (header) files /usr/include/mysql Libraries /usr/lib/mysql Miscellaneous support files (for example, error messages, and character set files) /usr/share/mysql 安装完成之后还会创建一个名为mysql的用户和一个mysql用户组在系统上。 需要注意的是在旧版本的mysql中配置文件的路径在 /usr/my.cnf ，强烈建议您把/usr/my.cnf这个配置迁移到/etc/my.cnf。然后删除/usr/my.cnf 启动 sudo service mysqld start 启动完成之后 会把root超级用户的密码自动生成 在日志中可以看到生成的密码，而且需要用户强制修改 不得不说这个版本对安全性提高了不少,在修改密码的时候还定义了密码的策略 如 安装密码长度、密码的复杂度等。 查看密码 sudo grep 'temporary password' /var/log/mysqld.log[root@localhost ~]# sudo grep 'temporary password' /var/log/mysqld.log2017-07-02T06:05:16.890856Z 1 [Note] A temporary password is generated for root@localhost: cfDZrTud2L(j 修改密码 mysql -u root -p#输入日志中的密码ALTER USER 'root'@'localhost' IDENTIFIED BY 'root'; 报错了 ERROR 1819 (HY000): Your password does not satisfy the current policy requirements 在5.7版本中会报错 就是前面说到的提供了默认的validate_password密码安全策略，这是一个插件 只不过在5.7版本中默认被安装了 由于我这里是本机， 密码设置简单点不会被忘记，所以我们修改一下密码的安全策略 set global validate_password_policy=0;#使用只按照密码长度验证 也就是策略中的第0个密码策略方式set global validate_password_length=2;#密码的长度要求ALTER USER 'root'@'localhost' IDENTIFIED BY 'root'; #这个时候才执行这个语句就没有报错了 参考文档 https://dev.mysql.com/doc/refman/5.7/en/linux-installation-rpm.html","tags":[{"name":"mysql","slug":"mysql","permalink":"https://blog.gitee.io/tags/mysql/"},{"name":"mysql5.7","slug":"mysql5-7","permalink":"https://blog.gitee.io/tags/mysql5-7/"}]},{"title":"Objenesis轻松实现为无参构造的类实例化","date":"2017-06-17T16:00:00.000Z","path":"2017/06/18/objenesis/","text":"Objenesis是一个用于实例化java类的小型Java库。 主要对于用户推荐使用以下3个API Objenesis ObjectInstantiator InstantiatorStrategy 首先得创建一个没有无参构建器的java类Example.java public class Example &#123; //为属性设置一个默认值 private String name=\"没有无参构造函数\";// public Example()&#123;&#125; public Example(String name)&#123; System.out.println(\"创建了---\"+Example.class.getName()); this.name=name; &#125; public String getName() &#123; return this.name; &#125;&#125; 正常情况下这个类在外部情况 如果不调用Example(name)这个构建方法 是没有办法实例化的，如果你正好有这个需求 这个时候Objenesis就有用武之地了 方法一Objenesis objenesis = new ObjenesisStd(true); ObjectInstantiator thingyInstantiator = objenesis.getInstantiatorOf(Example.class); Example example1 = (Example)thingyInstantiator.newInstance(); System.out.println(\"example1:\"+example1+\"---\"+example1.getName()); Example example2 = (Example)thingyInstantiator.newInstance(); System.out.println(\"example2:\"+example2+\"---\"+example2.getName()); Example example3 = (Example)thingyInstantiator.newInstance(); System.out.println(\"example3:\"+example3+\"---\"+example3.getName()); 运行结果 发现属性name原本我们是设置一个默认值的，利用Objenesis实例化后默认值为null了。 example1:Example@38cccef---null example2:Example@5679c6c6---null example3:Example@27ddd392---null 方法二 Example example4 =objenesis.newInstance(Example.class); System.out.println(\"example4:\"+example4+\"----\"+example4.getName()); 同样也能够创建成功。 区别在与 如果想批量实例化多个对象 那么方法一的效率会更高 。 另外Objenesis在spring4.0+版本中也有用到 不再强制要求写一个无参构造器了。kryo序列化中也有用到。 测试代码:https://github.com/peachyy/objenesis-example","tags":[{"name":"Objenesis","slug":"Objenesis","permalink":"https://blog.gitee.io/tags/Objenesis/"}]},{"title":"htmlUnit根据html创建htmlPage","date":"2017-06-02T16:00:00.000Z","path":"2017/06/03/htmlunitstringtopage/","text":"在htmlunit中可以通过URL轻松获取一个HtmlPage,但是却没有提供根据Html字符串创建一个HtmlPage。 通过Url获取一个page HtmlPage page = webClient.getPage(\"http://www.baidu.com/\"); 但是源码包里面有通过URL下载网页源码，并通过StringWebResponse构建一个HtmlPage对象, 所以利用这一个机制我们便可以利用StringWebResponse 手动构建一个HtmlPage对象。 实现方式如下 public static HtmlPage getPage(WebClient client, String html, String url, WebWindow window) &#123; try &#123; URL u = new URL(StringUtils.isBlank(url) ? \"http://www.idea.com\" : url); StringWebResponse response = new StringWebResponse(html, u); HtmlPage page = HTMLParser.parseHtml(response, window != null ? window : client.getCurrentWindow()); return page; &#125; catch (Exception e) &#123; throw new RuntimeException(\"字符串转换为htmlPage出错\", e); &#125;&#125;public static HtmlPage getPage(String html) &#123; return getPage(new WebClient(), html, null,null); &#125; 接下来调用getPage方法 并传入Html字符串就可以返回一个HtmlPage对象了。 本文参考 https://stackoverflow.com/questions/6136435/how-to-create-htmlunit-htmlpage-object-from-string","tags":[{"name":"htmlunit","slug":"htmlunit","permalink":"https://blog.gitee.io/tags/htmlunit/"}]},{"title":"使用jenv管理java库 国内版本","date":"2017-05-07T16:00:00.000Z","path":"2017/05/08/jenvmanager/","text":"jenv是一个并行版本管理的java开发包，注意是国内的，并不是https://github.com/gcuisinier/jenv可以安装在Linux Mac Windows操作系统上，工具包为我们提供了常用的命令行接口 用户安装、删除、搜索、切换软件版本。 安装 curl -L -s get.jenv.io | bash 下载完shell后需要重新进入一下终端 或者 source $HOME/.jenv/bin/jenv-init.sh 命令解释jenv all 显示所有被管理着的软件包（candidate） jenv list candidate 列出candidate软件包的所有版本 jenv install candidate version 安装指定版本的软件包 jenv uninstall candidate version 卸载指定版本的软件包 jenv reinstall candidate version 重新安装软件包 如果不指定版本号 会删除以前旧的版本号 安装至最新版 jenv use candidate version 使指定版本的软件包生效 jenv default candidate version 默认使用指定版本的软件包 jenv which candidate 列出当前用到的软件版本 及软件所在目录 jenv cd candidate 进入指定软件包默认的版本的安装目录 另外作者的源码托管地址在:https://github.com/linux-china/jenv 示例安装java1.8 jenv install java 1.8.0_77 卸载java1.8 jenv uninstall java 1.8.0_77 进入安装目录 jenv cd java","tags":[{"name":"jenv","slug":"jenv","permalink":"https://blog.gitee.io/tags/jenv/"}]},{"title":"常用的XPath语法说明","date":"2017-04-26T16:00:00.000Z","path":"2017/04/27/xpathstudy/","text":"XPath在选取XML文档中有着非常方便的功能，下面介绍一些常用的表达式语法。 假设如下XML &lt;?xml version=\"1.0\" encoding=\"ISO-8859-1\"?&gt;&lt;bookstore&gt; &lt;book&gt; &lt;title lang=\"en\"&gt;测试&lt;/title&gt; &lt;author sex=\"女\"&gt;笑笑笑&lt;/author&gt; &lt;year&gt;2017&lt;/year&gt; &lt;price&gt;888&lt;/price&gt; &lt;/book&gt; &lt;book&gt; &lt;title lang=\"en\"&gt;测试1&lt;/title&gt; &lt;author sex=\"女\" age=\"18\"&gt;笑笑笑1&lt;/author&gt; &lt;year&gt;2018&lt;/year&gt; &lt;price&gt;889&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; 基础表达式 选取节点基础表达式 摘自w3c 属性 含义 example nodename 选取此节点的所有子节点 bookstore * 任何元素 @* 任何属性的节点 任何属性的节点 / 从根节点选取。 /bookstore // 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置 //title . 选取当前节点。 ./title 选取当前节点下的title .. 选取当前节点的父节点。 @ 选取属性 //title[@lang=’en’] 一些定位的示例 获取所有的author节点//author获取第一个author节点 需要注意的是索引是从1开始的//author[1]获取拥有age属性的任何元素//*[@age] 获取author节点的age属性=18的所有author节点//author[@age='18'] 轴稍微麻烦强大一点的定位XPath Axes 获取文本包含2018的所有父Book节点//*[contains(text(),'2018')]/ancestor::book 还有一个ancestor-or-self选取的父节点包含自身 选取bookstore所有的子book节点//bookstore/child::book 选取当前节点的所有 book 后代。 descendant::book 获取当前节点的父节点div./parent::div 获取当前节点之后兄弟节点div./following-sibling::div 获取当前节点之前兄弟节点div./preceding-sibling::div 运算符在前面其实已经使用到运算符 例如age=18 参考自 http://www.w3school.com.cn/xpath/xpath_operators.asp 不在此说明 函数函数的使用方法在前面也使用到过 例如 contains(text(),&#39;2018&#39;)参考自 http://www.w3school.com.cn/xpath/xpath_functions.asp 不在此说明","tags":[{"name":"XPath","slug":"XPath","permalink":"https://blog.gitee.io/tags/XPath/"}]},{"title":"Mesos环境搭建","date":"2017-04-17T16:00:00.000Z","path":"2017/04/18/mesosinstall/","text":"最近有一个实时的采集系统需求，目前的实现方式是用分布式定时任务来处理这一采集请求,希望有更多资源能够为任务分担压力，支持动态添加或者移除任务资源 从而达到提高采集效率，所以准备采用Mesos来做资源调度的工作。 因为自己硬件设备不够好的原因导致安装Mesos的时候出现了一个未知的问题 记录一下，以下是参考官方Getting Started的示例。 获取源码wget http://www.apache.org/dist/mesos/1.2.0/mesos-1.2.0.tar.gztar -zxf mesos-1.2.0.tar.gz 安装所需依赖 由于本机是Ubuntu 14.04 如果是其他的系统请参考 http://mesos.apache.org/gettingstarted/ apt-get update apt-get install -y tar wget gitapt-get install -y openjdk-7-jdkapt-get install -y autoconf libtoolapt-get -y install build-essential python-dev python-virtualenv libcurl4-nss-dev libsasl2-dev libsasl2-modules maven libapr1-dev libsvn-dev 编译源码cd mesos-1.2.0./bootstrapmkdir buildcd build../configuremake -j3 安装make checkmake install 测试例子从官方示例复制 可以运行指定IP的时候 如果需要外网访问可以设置具体的IP, 设置为127.0.0.1 只能用127.0.0.1的IP访问。 # Start Mesos master (ensure work directory exists and has proper permissions).$ ./bin/mesos-master.sh --ip=127.0.0.1 --work_dir=/var/lib/mesos# Start Mesos agent (ensure work directory exists and has proper permissions).$ ./bin/mesos-agent.sh --master=127.0.0.1:5050 --work_dir=/var/lib/mesos# Visit the Mesos web page.$ http://127.0.0.1:5050# Run C++ framework (exits after successfully running some tasks).$ ./src/test-framework --master=127.0.0.1:5050# Run Java framework (exits after successfully running some tasks).$ ./src/examples/java/test-framework 127.0.0.1:5050# Run Python framework (exits after successfully running some tasks).$ ./src/examples/python/test-framework 127.0.0.1:5050 需要注意的是 安装之前要保证差不多2-4个GB的内存，不然在编译的时候总是报一些莫名奇妙的错误。还要保证安装之前要把依赖库安装好。","tags":[{"name":"技术栈","slug":"技术栈","permalink":"https://blog.gitee.io/tags/技术栈/"}]},{"title":"我的2017技术栈","date":"2017-03-05T16:00:00.000Z","path":"2017/03/06/2017-target/","text":"2017年已经过了差不多六分之一 为了给自己制定了一个技术计划(算是小目标吧)，所以在这里引导一下， 当迷茫的时候可以look look!!! 后端 搜索相关 1、elasticsearch 2、lucene 3、solr 大数据相关 1、Hadoop 2、Spark 3、Storm 如果时间够多也研究一下 远程调用/网络相关 1、mina 2、netty 3、dubbo 尽量根据现有业务做一些扩展和调整 4、thrift 5、grpc 基础相关 1、提升算法能力等。 前端因为平时工作大部分时间都是在折腾后端的东西 前端逐渐遗忘了，所以打算从新好好学习一下。 HTML5/CSS3 、ES6、requirejs、bootstarap、seajs、以及响应式应用等。 其他尽量能用docker带来的便捷使用各种dev环境，在语言方面准备学习NodeJS 、Groovy、Scala 、Python。包管理工具gradle以及持续集成相关的技术。 另外在性能测试方面入手学习JMeter，移动相关学习一下混合开发。 要领悟的东西远远不止于这些 慢慢来 我不急…","tags":[{"name":"技术栈","slug":"技术栈","permalink":"https://blog.gitee.io/tags/技术栈/"}]},{"title":"MongoDB搭建ReplSet复制集群","date":"2017-01-10T16:00:00.000Z","path":"2017/01/11/mongodb-rs/","text":"MongoDB的复制集是一个主从复制模式 又具有故障转移的集群，任何成员都有可能是master， 当master挂掉用会很快的重新选举一个节点来充当master。 复制集中的组成主要成员 Primary 数据读写 master节点 Secondary 备份Primary的数据 默认设置下 不可读 不可写 arbiter 投票节点 此节点不会存数据 只参与投票 ，当primary节点出现异常挂掉之后 arbiter节点负责从secondary 节点中选举一个节点升级为Primary节点 其中可以设置Secondary节点可读，让Primary节点负责写，这些就实现了一个高效简单的读写分离。 环境搭建以3个实例来演示一下复制集群的搭建过程 分别为:127.0.0.1:12345,127.0.0.1:12346,127.0.0.1:12347。需要预先创建好各目录的文件夹 不然启动的时候会报错，这里还有一个坑是 pidfilepath配置项必须是绝对路径，否则也会报错，replSet在同一个复制集中也需要具有一致的名称。 注意在旧版本中是使用的是master slave模式 目前使用的是3.4官方不支持使用这种方式，官方希望使用replset代替master slave。所以当你配置master或者slave的时候就会报错。 127.0.0.1:12345配置 port=12345fork=truedbpath=data/12345logpath=log/12345/mongod.loghttpinterface=truerest=truelogappend=truepidfilepath=/home/collect/mongodb-linux-x86_64-rhel70-3.4.1/log/12345/12345.pidreplSet=mydbCenteroplogSize=512 127.0.0.1:12346配置 port=12346fork=truedbpath=data/12346logpath=log/12346/mongod.loghttpinterface=truerest=truelogappend=truepidfilepath=/home/collect/mongodb-linux-x86_64-rhel70-3.4.1/log/12346/12346.pidreplSet=mydbCenteroplogSize=512 127.0.0.1:12346配置 port=12347fork=truedbpath=data/12347logpath=log/12347/mongod.loghttpinterface=truerest=truelogappend=truepidfilepath=/home/collect/mongodb-linux-x86_64-rhel70-3.4.1/log/12347/12347.pidreplSet=mydbCenteroplogSize=512 分别启动好3个实例之后，随便进入一个实例 初始化复制集群首先创建1个配置对象 在js中就是一个简单的对象 、json串 var rs_conf={ &quot;_id&quot; : &quot;mydbCenter&quot;, &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;host&quot; : &quot;127.0.0.1:12345&quot; }, { &quot;_id&quot; : 1, &quot;host&quot; : &quot;127.0.0.1:12346&quot; }, { &quot;_id&quot; : 2, &quot;host&quot; : &quot;127.0.0.1:12347&quot; } ] } 把配置应用到集群 rs.initiate(rs_conf) 这里有一个限制就是需要集群的节点中不能有数据 需要先清空一下 不然initiate的时候会出错。配置成功后使用rs.status()命令查看各节点状态，一些正常 就能看到各节点的状态信息 rs.status() 搭建好复制集群之后命令行的标识符会变为相应的成员类型如 mydbCenter:PRIMARY&gt; mydbCenter:SECONDARY&gt; 这也是检验集群是否搭建的成功的一个小标识。 接着可以尝试一下在Primary中写入一条数据。这条数据会立即同步到各个Secondary节点中。当然前面也说过默认情况的Secondary不可读 会报下面的错误。 { &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not master and slaveOk=false&quot;, &quot;code&quot; : 13435, &quot;codeName&quot; : &quot;NotMasterNoSlaveOk&quot; } 所以需要在Secondary中执行 db.getMongo().setSlaveOk() 在网络上看到有很多帖子说只要在Primary节点中执行 db.getMongo().setSlaveOk()就能在Secondary节点中读取数据，但是在3.4版本试了一下是不行的。需要在Secondary中执行一下db.getMongo().setSlaveOk()让Secondary可读。 添加节点如果现在已经有搭建好一个复制集群了 老板想多加一台备份机器进去 怎么办？只需要启动好新机器的实例后 在Primary中调用rs.add() 方法即可 rs.add({\"host\" : \"127.0.0.1:12348\"}) 添加投票节点调用rs.addArb()方法。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.gitee.io/tags/MongoDB/"}]},{"title":"jdk1.7 Fork/Join并行框架学习","date":"2017-01-08T16:00:00.000Z","path":"2017/01/09/jdk7-forkjoin/","text":"首先看一下ForkJoin相关的几个API ForkJoinPool 实现了forkjoin的线程池 ForkJoinWorkerThread forkjoin的线程 ForkJoinTask forkjoin任务的父类 这是一个抽象类 RecursiveAction 无返回结果的任务接口 RecursiveTask 有返回结果的任务接口 ForkJoinPool继承自AbstractExecutorService类 说明了 ForkJoinPool和ThreadPoolExecutor差不多是同父的兄弟类 ，因为ThreadPoolExecutor也继承自AbstractExecutorService类。 @sun.misc.Contendedpublic class ForkJoinPool extends AbstractExecutorService 下面以一个简单的例子来说明一下使用方法 定义一个task实现类 public class Calculator extends RecursiveTask&lt;Integer&gt; &#123; private static final int THRESHOLD = 10; private int start; private int end; public Calculator(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; int sum = 0; if((end - start) &lt; THRESHOLD)&#123; sum=calSingle(); &#125;else&#123; int middle = (start + end) /2; Calculator task1 = new Calculator(start, middle); Calculator task2 = new Calculator(middle + 1, end); //首先拆分任务 task2.fork(); int i=task2.join(); int i2=task1.invoke(); // invokeAll(task1,task2);// int i=task1.getRawResult();// int i2=task2.getRawResult(); //聚合 sum=i+i2; &#125; return sum; &#125; private int calSingle()&#123; int sum=0; for(int i = start; i&lt;= end;i++)&#123; sum += i; &#125; return sum; &#125; &#125; 测试main函数类 public class TestMain &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; Calculator calculator=new Calculator(0,500); ForkJoinPool pool = new ForkJoinPool(); ForkJoinTask&lt;Integer&gt; f=pool.submit(calculator); long start=System.currentTimeMillis(); System.out.println(System.currentTimeMillis()-start+\"MS\"); do&#123; if(calculator.isCompletedNormally()) &#123; System.out.println(\"计算完成 正在关闭Fork/Join池...\"); pool.shutdown(); &#125; &#125;while(!calculator.isDone()); System.out.println(\"计算结果为：\"+f.get()); System.out.println(\"线程已经从另一个线程偷取到的时间数:\"+pool.getStealCount()); System.out.println(\"是否已经完成执行:\"+pool.isTerminated()); System.out.println(\"并行的级别：\"+pool.getParallelism()); System.out.println(\"线程池的worker线程的数量：\"+pool.getPoolSize()); System.out.println(\"执行的任务数：\"+pool.getQueuedTaskCount()); &#125;&#125; 需要注意的是Fork/Join的为了充分减少等待时间 默认使用的是LIFO策略，所以我们在执行第一个任务的时候尽量不要fork。具体原因还不是很理解，因为在invokeAll方法中也是这样子处理的。invokeAll源码如下public static void invokeAll(ForkJoinTask&lt;?&gt; t1, ForkJoinTask&lt;?&gt; t2) &#123; int s1, s2; t2.fork(); if ((s1 = t1.doInvoke() &amp; DONE_MASK) != NORMAL) t1.reportException(s1); if ((s2 = t2.doJoin() &amp; DONE_MASK) != NORMAL) t2.reportException(s2);&#125; 首先Fork第二个任务。然后在执行第一个任务,其次是join第二个任务。","tags":[{"name":"Fork/Join","slug":"Fork-Join","permalink":"https://blog.gitee.io/tags/Fork-Join/"}]},{"title":"MongoDB常用操作","date":"2017-01-07T16:00:00.000Z","path":"2017/01/08/mongodbCommonoper/","text":"以下是在3.4.1版本中 其他版本可能略有区别,mongo默认登录时在test数据中。 数据库相关操作登录到数据库 bin/mongo --port 27017 查看数据库列表 show dbs 选择使用哪个数据库 类似mysql中的use,使用use后 创建的table默认会在当前使用的数据中 use taoxs 查看当前使用的数据库使用db或者db.getName()一样的。 db db.getName() 显示当前数据库下的所有table(集合)show tables 增删改查向taoxs_c1集合插入一行数据&gt;db.taoxs_c1.insert(&#123;name:'abc',sex:'1'&#125;) WriteResult(&#123; \"nInserted\" : 1 &#125;) 查询all&gt; db.taoxs_c1.find()&#123; \"_id\" : ObjectId(\"5871d9173c7ab1b751cfda4f\"), \"name\" : \"abc\", \"sex\" : \"1\" &#125; 查询指定列&gt; db.taoxs_c1.find(&#123;&#125;，&#123;name:true&#125;)&#123; \"_id\" : ObjectId(\"5871d9173c7ab1b751cfda4f\"), \"name\" : \"abc\" &#125; 查询count&gt; db.taoxs_c1.find().count()1 查询限制行数limit&gt; db.taoxs_c1.find().limit(5) 查询时忽略数据行数 可以用skip和limit配置实现分页的效果&gt; db.taoxs_c1.find().skip(5) 结果排序 1：升序，-1：降序&gt; db.taoxs_c1.find().sort(&#123;name:1&#125;) 修改name 的值为dfg默认情况下 只会只会修改第一行 ，会覆盖掉其他字段 也就是说在修改name的时候sex字段也会被覆盖掉update方法签名：function (query, obj, upsert, multi) &gt; db.taoxs_c1.update(&#123;name:'abc'&#125;,&#123;$set:&#123;name:'dfg'&#125;&#125;) 如果需要多行删除需要指定multi参数为true 如果需要upsert 需要指定upsert参数为true 删除操作&gt; db.taoxs_c1.remove(&#123;name:'dfg'&#125;) mongodb中常用的条件查询类似sql中的where中条件符 字符 含义 $lt &lt; $gt &gt; $lte &lt;= $gte &gt;= $ne != $in 包含 $nin 不包含 $all 匹配所有 $exists 属性是否存在 $size 属性值size判断","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.gitee.io/tags/MongoDB/"}]},{"title":"nginx编译安装","date":"2016-11-23T16:00:00.000Z","path":"2016/11/24/nginxMakeInstall/","text":"nginx是比较常用的高性能HTTP服务器和反向代理服务器，许多用户更是把做反向代理使用，常言道：好记性不如烂笔头 时间久了总是有些遗忘，本文记录一下源码编码安装以及常用模块的使用介绍。 编译安装tar -zxf nginx-1.7.3.tar.gz cd nginx-1.7.3/ groupadd -r nginx useradd -g nginx -s /sbin/nologin -M nginx #创建tmp文件夹 不然安装后启动会报错 mkdir -pv /var/tmp/nginx/{proxy,client,fcgi,uwsgi,scgi} ./configure \\ --prefix=/usr/local/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --pid-path=/var/run/nginx/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_flv_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/tmp/nginx/client/ \\ --http-proxy-temp-path=/var/tmp/nginx/proxy/ \\ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \\ --http-scgi-temp-path=/var/tmp/nginx/scgi \\ --with-pcre make make install 到此简单的安装算是完成了。 常用模块配置nginx statuslocation /nginx_status { stub_status on; access_log off; } 配置好后重新启动nginx curl localhost/nginx_status 查看状态如果出现无法识别stub_status的时候可能是安装的时候没有安装http_stub_status_module模块。","tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.gitee.io/tags/nginx/"}]},{"title":"rabbitmq安装","date":"2016-10-28T16:00:00.000Z","path":"2016/10/29/rabbitmqInstall/","text":"安装rabbitmq采用源码安装方式,首先去官网拉取源代码并解压,由于rabbitmq是采用erlang编写的 所以得先安装erlang环境,这里假设erlang环境已经安装好了。 wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.4.0/rabbitmq-server-3.4.0.tar.gz tar -zxf rabbitmq-server-3.4.0.tar.gz 编译并安装 这里把安装的目录设置为/opt/reabbitmq cd rabbitmq-server-3.4.0 make make install TARGET_DIR=/opt/rabbitmq SBIN_DIR=/opt/rabbitmq/sbin MAN_DIR=/opt/rabbitmq/man DOC_INSTALL_DIR=/opt/rabbitmq/doc 配置设置环境变量 也可以包装为一个服务的方式存在 这里设置一下环境变量就好了。 export RABBITMQ_HOME=/opt/rabbitmq export PATH=$RABBITMQ_HOME/sbin:$PATH #设置好之后 需要source一下才能生效 启动web管理插件 mq服务 rabbitmq-plugins enable rabbitmq_management #启动mq rabbitmq-server start 到这里基本的安装已经完成此时可以 可以在本机使用localhost:15672访问了,rabbitmq内置了一个用户guest/guest不过只能用localhost访问。 如果想让其他机器也能访问管理web页面 需要关闭防火墙并创建另外的用户。 简单常用命令添加用户 rabbitmqctl add_user admin admin 为用户赋予角色 在rabbitmq中角色有administrator、monitoring 、management、policymaker、none。 #为admin 赋予administrator角色 rabbitmqctl set_user_tags admin administrator 查看用户列表 rabbitmqctl list_users","tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://blog.gitee.io/tags/rabbitmq/"}]},{"title":"emmet编写Html","date":"2016-10-15T16:00:00.000Z","path":"2016/10/16/html-emmet/","text":"Emmet是一个Web开发人员的工具包，可以大大提高你的HTML和CSS的工作流,这是在emmet官方文档中看到的第一句话,当然这句话也简单的概括了它拥有的魅力。 下面是在WebStorm中作一些应用。 构建一张html网页 一张基本的网页结构一般是具有&lt;html&gt; &lt;head&gt; &lt;body&gt; ,使用emmet只需要按一个tab键的时间就可以实现，输入!,然后按Tab键就能实现如下效果, &lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, user-scalable=no, initial-scale=1.0, maxeimum-scale=1.0, minimum-scale=1.0\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 上面的效果使用html:5 然后按Tab键同样也能实现,如果是html4可以用html:4s ,xhtml用html:xt 然后按Tab键。 添加元素及属性为元素添加class或者id 如输入span.clsspan#myspan 按Tab 会生成如下代码 &lt;span class=\"clsspan\" id=\"myspan\"&gt;&lt;/span&gt; 为元素添加属性值 如输入span{this is my span !!!}+a[href=http://blog.seoui.com] &lt;span&gt;this is my span !!!&lt;/span&gt;&lt;a href=\"http://blog.seoui.com\"&gt;&lt;/a&gt; 标签结构嵌套 &gt; 子元素标记 + 同级元素追加标记 ^ 向当前父级元素追加标记 添加子元素实例 如 span&gt;p.item &lt;span&gt; &lt;p class=\"item\"&gt;&lt;/p&gt;&lt;/span&gt; 添加同级元素实例 如 span+p.item &lt;span&gt;&lt;/span&gt;&lt;p class=\"item\"&gt;&lt;/p&gt; 添加父级元素实例 如 span&gt;div^p &lt;span&gt; &lt;div&gt;&lt;/div&gt;&lt;/span&gt;&lt;p&gt;&lt;/p&gt; 分组以上虽然能轻松实现一些html的元素构建,但是如果遇到批量或者很多的类似的元素怎么办呢? 分组其实就是用()把标记分开,让他们成为一个独立的块。 如 (div.item&gt;p)+(div.deatil&gt;span) 然后按tab会生成以下代码 &lt;div class=\"item\"&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=\"deatil\"&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt; 如果我想重复生成2次上面的结构,使用((div.item&gt;p)+(div.deatil&gt;span))*2就能实现 &lt;div class=\"item\"&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=\"deatil\"&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=\"item\"&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div class=\"deatil\"&gt;&lt;span&gt;&lt;/span&gt;&lt;/div&gt; 生成多个带属性的元素 如 ul&gt;li.item$*2 &lt;ul&gt; &lt;li class=\"item1\"&gt;&lt;/li&gt; &lt;li class=\"item2\"&gt;&lt;/li&gt;&lt;/ul&gt; 隐式标签所谓隐式标签就是可以不用声明标签名称可以直接操作 如.item会生成 &lt;div class=\"item\"&gt;&lt;/div&gt; 当然不会很死板的一直生成div 隐式标签会根据父元素来生成适当的标签 如在ul内部使用隐式标签则会生成li。 li 、tr 、 td 、 option 都是隐式标签","tags":[{"name":"emmet","slug":"emmet","permalink":"https://blog.gitee.io/tags/emmet/"}]},{"title":"supervisor配置和使用","date":"2016-07-06T16:00:00.000Z","path":"2016/07/07/supervisor/","text":"supervisor是一个制作守护进程的工具,用户可以在UNIX系统中监控、管理进程。常用于管理与某个用户或项目相关的进程。 安装 采用源码安装的方式,切换到3.1.3这个版本安装。 git clone https://github.com/Supervisor/supervisor.gitcd supervisor git checkout 3.1.3 python setup.py install 生成默认的supervisor配置文件 echo_supervisord_conf &gt; /etc/supervisord.conf 修改自定义配置 vim /etc/supervisord.conf 提供web界面访问需要设置 inet_http_server 需要配置一下supervisorctl的serverurl 这个地址必须匹配inet_http_server节点的port 另外要去掉include的注释 用include的方式来引入supervisor进程, 而不需要每次都去修改 /etc/supervisord.conf,files指定为/etc/supervisor/*.conf,只要在/etc/supervisor目录下.conf结尾的文件都需要被supervisor加载。 [inet_http_server] ; inet (TCP) server disabled by defaultport=0.0.0.0:9001 ; (ip_address:port specifier, *:port for all iface);username=user ; (default is no username (open server));password=123 [supervisorctl];serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socketserverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket[include]files=/etc/supervisor/*.conf 示例 1、首先编写一段测试程序,这段代码是从网络上下载的,并非自己编写的。 vim test_http.py import sysimport BaseHTTPServerfrom SimpleHTTPServer import SimpleHTTPRequestHandlerHandlerClass = SimpleHTTPRequestHandlerServerClass = BaseHTTPServer.HTTPServerProtocol = \"HTTP/1.0\"if __name__ == \"__main__\": if sys.argv[1:]: port = int(sys.argv[1]) else: port = 8000 server_address = ('0.0.0.0', port) HandlerClass.protocol_version = Protocol httpd = ServerClass(server_address, HandlerClass) sa = httpd.socket.getsockname() print \"Serving HTTP on\", sa[0], \"port\", sa[1], \"...\" httpd.serve_forever() 2、编写进程守护.conf文件 vim /etc/supervisor/test_http.conf program：后面进程名称 [program:test_http]command=python test_http.py 501 ; 被监控的进程路径directory=/root/supervisor ; 执行前先cd到目录去priority=1 ;数字越高，优先级越高numprocs=1 ; 启动几个进程autostart=true ; 随着supervisord的启动而启动autorestart=true ; 自动重启。。当然要选上了startretries=10 ; 启动失败时的最多重试次数exitcodes=0 ; 正常退出代码（是说退出代码是这个时就不再重启了吗？待确定）stopsignal=KILL ; 用来杀死进程的信号stopwaitsecs=10 ; 发送SIGKILL前的等待时间redirect_stderr=true ; 重定向stderr到stdoutstdout_logfile=/tmp/log/supervisor.log ;日志目录 启动并加载配置信息 不输出其他异常信息则表示启动并加载配置成功,接下来可以使用 supervisorctl 查看状态信息。看到一个进程名称为test_http。 可以在客户端远程访问这个supervisor网页控制台。curl http://127.0.0.1:9001 能看到网页信息就证明是OK的。 当然可以在远程浏览器访问http://xxxxx:9001 可以启动 停止 甚至是查看日志等功能。 supervisord -c /etc/supervisord.conf supervisorctl statustest_http RUNNING pid 16013, uptime 0:14:22 supervisorctl 常用的命令有 start,restart,stop,stop all,reload等。 另外还有一个很重要的概览group [group:test_gourp];定义分分组 test_gourpprograms=test_http ；分组中包含程序 test_http 多个需要使用,分隔。priority=1log_stderr=truelogfile_maxbytes=1MB","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"},{"name":"supervisor","slug":"supervisor","permalink":"https://blog.gitee.io/tags/supervisor/"}]},{"title":"gzip 和 zip在linux上的使用","date":"2016-07-03T16:00:00.000Z","path":"2016/07/04/gzip-uzip/","text":"文件的压缩/解压无论是在哪个操作系统上都比较常用 简答在这里演示一下。 zip zip会把文件打包为.zip格式的文件包，比如 abc.zip zip abc.zip testabc.txt 上面的shell会把testabc.txt压缩在当前目录下的abc.zip文件中 当然你也可以指定压缩到你指定的路径如 zip /opt/abc.zip testabc.txt unzip abc.zip 把abc.zip包解压到当前目录 如需指定解压到其他目录 需要指定-d 参数 如 unzip abc.zip -d /opt/abc gzip 从压缩后的压缩包文件格式上与zip命令不同的是gzip压缩后的文件格式为.gz //压缩为文件 abc.txt.gz 会删除原有的abc.txt文件gzip abc.txt //解压abc.txt.gz 会删除原有的abc.txt.gz文件 gunzip abc.txt.gz //如需要保留原来的压缩文件 需要加-c 参数 // gzip -c abc.txt &gt; /root/abc.gz // gunzip -c /abc.gz &gt; ./abc.txt 补充一下怎么解压.xz格式的压缩包 tar xvJf ***.tar.xz 或 xz -d ***.tar.xztar -xvf ***.tar","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"},{"name":"unzip","slug":"unzip","permalink":"https://blog.gitee.io/tags/unzip/"},{"name":"gunzip","slug":"gunzip","permalink":"https://blog.gitee.io/tags/gunzip/"}]},{"title":"Hello Docker","date":"2016-06-17T16:00:00.000Z","path":"2016/06/18/docker.install/","text":"接触docker容器有这么几周的时间了,顺便在这里记录一下这段岁月,无特殊说明操作系统均为 centos7 1、首先安装docker 参考 https://docs.docker.com/linux/step_one/ 检查有没有安装curl 如果没有安装可以使用 apt-get install curl 安装curl,已经安装了则忽略。 which curl 安装最新的版本Docker 执行命令 自动根据自身环境安装 curl -fsSL https://get.docker.com/ | sh 验证安装是否成功 docker version Client: Version: 1.11.2 API version: 1.23 Go version: go1.5.4 Git commit: b9f10c9 Built: Wed Jun 1 21:47:50 2016 OS/Arch: linux/amd64Server: Version: 1.11.2 API version: 1.23 Go version: go1.5.4 Git commit: b9f10c9 Built: Wed Jun 1 21:47:50 2016 OS/Arch: linux/amd64 输出docker版本号信息 则表示成功 2、运行第一个Docker容器 busybox docker run -it --rm busybox busybox是一个很小的linux系统 只有1M的样子吧,执行完这个命令后 docker会首先检查本地镜像有没有叫busybox,如果没有会去中央仓库拉取（pull）,拉取完成后运行(run) 这个容器,参数-it 表示命令行交互 –rm表示运行结束后立即删除这个容器。 这里有2个概念 pull拉取出来的叫做镜像(image) run运行的叫做容器(container),一个image可以有多个container,镜像有自己的镜像ID ,容器也有自己的容器ID,这里可以描述得不太好，大概就是意思。","tags":[{"name":"docker","slug":"docker","permalink":"https://blog.gitee.io/tags/docker/"}]},{"title":"ubuntu设置网络","date":"2016-06-16T16:00:00.000Z","path":"2016/06/17/ubuntu.networksetting/","text":"用惯了centos 偶尔装了一次ubuntu版本为14.04来玩一玩发现设置静态网络(static)后不能上外网，在这里记录一下如何设置的。 1、首页静态IP参数 编辑文件 vim /etc/network/interfaces auto eth0iface eth0 inet staticaddress 172.168.101.245netmask 255.255.255.0gateway 172.168.101.254nameserver 61.128.128.68 设置好后重启网卡 /etc/init.d/networking restart 然而并不能解析DNS 2、配置dns 编辑文件 vim /etc/resolv.conf 根据我所在网络环境设置如下DNS nameserver 114.114.114.114nameserver 61.128.128.68 此时 如果有外网 应该是可以ping了","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://blog.gitee.io/tags/ubuntu/"}]},{"title":"form表单默认回车事件的问题","date":"2016-05-23T16:00:00.000Z","path":"2016/05/24/html-form-enterevent/","text":"经常写form表单以前没有怎么注意 无意中注意到一些元素组成的默认事件。 在form表单中 目前发现具备以下情况会默认支持回车事件提交表单 所有的表单元素中只有1个text 无论提交按钮是否为type=submit 表单中的提交按钮type=submit //此代码默认就具有了回车提交表单的事件 需要格外小心 &lt;form&gt; &lt;input type=\"text\" value=\"\" name=\"name\"&gt; &lt;input type=\"button\" value=\"button\"/&gt; &lt;/form&gt; 如果我们的表单中仅有一个text的话怎么阻止默认回车事件呢? 可以在表单中多加一个隐藏的text &lt;form&gt; &lt;input type=\"text\" value=\"\" name=\"name\"&gt; &lt;input type=\"text\" style=\"display: none;\"&gt; &lt;input type=\"button\" value=\"button\"/&gt; &lt;/form&gt; 示例demo 具有默认事件：http://peachyy.github.io/demos/htmlformenterevent/index.html 示例demo 不具有默认事件：http://peachyy.github.io/demos/htmlformenterevent/index.html","tags":[{"name":"from","slug":"from","permalink":"https://blog.gitee.io/tags/from/"}]},{"title":"利用selenium做网页自动测试","date":"2016-04-12T16:00:00.000Z","path":"2016/04/13/selenium-autowebTest/","text":"最近在做一个简单新浪微博抓取功能,遇到了请求被新浪拦截,正因为如此了解到selenium。 selenium 是一个web的自动化测试工具。运用好它能够完成很多自动化测试功能甚至会让你感到很多出乎意料的事情。 接下来做一件简单而大气的事情（这里使用java语言）,模拟一个chrome浏览器访问 http://www.weibo.com 自动输入微博用户名和密码 自动点击登录,当登录成功后给用户一个反馈。 必须需要一个浏览器驱动包 可以到http://docs.seleniumhq.org/download/下载 需要匹配自己的操作系统 以及浏览器 下载对应的版本。 比如 我的驱动放在了本地磁盘 E:\\Dev\\devPlugins\\chromedriver.exe 路径。 public class RunApp &#123; public static void main(String[] args)throws Exception&#123; //创建一个chrome驱动 ChromeDriverService service = new ChromeDriverService.Builder() .usingDriverExecutable( new File( \"E:\\\\Dev\\\\devPlugins\\\\chromedriver.exe\")) .usingAnyFreePort().build(); service.start(); WebDriver driver = new RemoteWebDriver(service.getUrl(), DesiredCapabilities.chrome()); //访问weibo.com站点 driver.get(\"http://www.weibo.com?t=\"+System.currentTimeMillis()); //等待网站是否刷新完成 如果30秒还没有响应则认为超时了 (new WebDriverWait(driver,30)).until(new ExpectedCondition&lt;Boolean&gt;() &#123; public Boolean apply(WebDriver d) &#123; //使用域名判断是否跳转到登录页面 return d.getCurrentUrl().toLowerCase().startsWith(\"http://weibo.com\"); &#125; &#125;); // 显示搜索结果页面的 title System.out.println(\"打印一下网页的TITLE: \" + driver.getTitle()); //点击用户登录的窗口 //这里的path可以开发开发人员工具 复制xpath WebElement element = driver.findElement( By.xpath(\"//*[@id=\\\"pl_login_form\\\"]/div[2]/div[1]/div/a[2]\")); element.click(); //自动输入用户名数据 WebElement userId=element.findElement( By.xpath(\"//*[@id=\\\"loginname\\\"]\")); WebElement password=element.findElement( By.xpath(\"//*[@id=\\\"pl_login_form\\\"]/div[2]/div[3]/div[2]/div/input\")); WebElement submit= element.findElement( By.xpath(\"//*[@id=\\\"pl_login_form\\\"]/div[2]/div[3]/div[6]/a\")); //你的微博账号 userId.sendKeys(\"22222\"); //你的微博密码 password.sendKeys(\"xxxxxxx\"); //触发登录动作 submit.click(); System.out.println(\"点击登录了\"); //等待是否登录成功 超时时间600秒 (new WebDriverWait(driver, 600)).until(new ExpectedCondition&lt;Boolean&gt;() &#123; public Boolean apply(WebDriver d) &#123; //根据网页标题来辨别是否登录成功 如果成功后新浪微博标题为 我的首页 ************ return d.getTitle().startsWith(\"我的首页\"); &#125; &#125;); System.out.println(\"登录完成 你可以开始刷微博了 准备获取cookies\"); Collection set= driver.manage().getCookies(); // 关闭浏览器 // driver.quit(); // 关闭 ChromeDriver 接口 // service.stop(); &#125;&#125; 修改自己的微博账号和密码后，直接使用控制台运行这个程序 就可以自动打开浏览器 自动输入账号密码 自动登录。有时候会出现验证码的情况需要自己输入验证码。 源代码地址:https://github.com/peachyy/demos/blob/master/selenium-demo.rar","tags":[{"name":"selenium","slug":"selenium","permalink":"https://blog.gitee.io/tags/selenium/"}]},{"title":"让IE浏览器支持SVG动画","date":"2016-03-15T16:00:00.000Z","path":"2016/03/16/svganimate-ie-support/","text":"在IE浏览器上 无论是否=IE11 svg动画元素animate都得不到支持 接下来的事情就是让IE浏览器能够支持svg动画元素 包括 animate、animateTransform、animateMotion、animateColor、set 元素 如果是IE内核的浏览器可以引入以下脚本 在html文档中使用 引入script &lt;script type=\"text/javascript\" src=\"smil.check.js\"&gt;&lt;/script&gt; 在svg文件中使用 &lt;svg&gt; &lt;elements..&gt; &lt;script type=\"text/ecmascript\" xlink:href=\"smil.check.js\" /&gt;&lt;/svg&gt; 接下来就由奇迹发生了 在IE中svg动画元素居然可以动了。 经过测试感觉动画的偏移不是特别精确 如果需要特别精确的话 估计这个还是有些问题。 此文参考 http://stackoverflow.com/questions/15738752/svg-animation-not-working-ie9-ie10 另外smil.check.js托管在github地址为: https://github.com/FakeSmile/FakeSmile","tags":[{"name":"svg","slug":"svg","permalink":"https://blog.gitee.io/tags/svg/"}]},{"title":"Centos7 安装mysql","date":"2016-03-08T16:00:00.000Z","path":"2016/03/09/centos7.install.mysql/","text":"正常情况下一般都会选择yum安装 原因都知道 简单 快捷，但在安装Mysql时却总是不顺利。 所以这里记录一下 首先去拉取rpm文件 wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm 安装rpm并安装mysql-community-server rpm -ivh mysql-community-release-el7-5.noarch.rpmyum install mysql-community-server 安装完成后设置密码 注意设置密码之前最好重启一下mysqld service mysqld restartmysql -urootset password for ‘root’@‘localhost’ = password('mypasswd'); 如有需要可以 设置一下允许远程访问 update user set host = '%' where user ='root';flush privileges;","tags":[{"name":"centos","slug":"centos","permalink":"https://blog.gitee.io/tags/centos/"},{"name":"mysql","slug":"mysql","permalink":"https://blog.gitee.io/tags/mysql/"}]},{"title":"springMvc支持jsonp适配","date":"2016-03-01T16:00:00.000Z","path":"2016/03/02/springmvcsupportjsonp/","text":"这里测试的是spring mvc4的版本 定义一个扩展类 必须要加上@ControllerAdvice增加处理@ControllerAdvicepublic class JsonpSupportAdvice extends AbstractJsonpResponseBodyAdvice &#123; public JsonpSupportAdvice() &#123; //参数包含callback的时候 使用jsonp的反馈形式 super(\"callback\", \"jsonp\"); &#125;&#125; 并配置好映射 jsonp –application/javascript&lt;bean class=\"org.springframework.web.servlet.view.ContentNegotiatingViewResolver\" p:order=\"0\" p:defaultContentType=\"text/html\" p:ignoreAcceptHeader=\"true\" p:favorPathExtension=\"true\" p:favorParameter=\"true\" p:parameterName=\"content\"&gt; &lt;property name=\"mediaTypes\"&gt; &lt;map&gt; &lt;entry key=\"html\" value=\"text/html\" /&gt; &lt;entry key=\"pdf\" value=\"application/pdf\" /&gt; &lt;entry key=\"xsl\" value=\"application/vnd.ms-excel\" /&gt; &lt;entry key=\"xml\" value=\"application/xml\" /&gt; &lt;entry key=\"json\" value=\"application/json\" /&gt; &lt;entry key=\"jsonp\" value=\"application/javascript\"/&gt; &lt;/map&gt; &lt;/property&gt; ....... ..... OK 到这里配置完成 访问请求的时候只需加上callback参数即为jsonp的数据返回格式。","tags":[{"name":"java","slug":"java","permalink":"https://blog.gitee.io/tags/java/"},{"name":"springmvc","slug":"springmvc","permalink":"https://blog.gitee.io/tags/springmvc/"}]},{"title":"分享几个常用的Google Chrome插件","date":"2016-01-24T16:00:00.000Z","path":"2016/01/25/share-chrome-plugin/","text":"在这里分享几个 个人常用的Google Chrome浏览器插件 保证实用。 由于个人目前的工作会写一些代码 所以优先介绍几个GitHub插件 1.OctoTree 扩展Chrome浏览器在浏览GitHub代码的时候能像本地文件系统一样列出一棵树，可以用于GitHub、GitLab 2.Isometric Contributions 支持在GitHub个人主页的图表统计转换柱状的图表统计 更能直观的看出提交代码的频率 就像盖房子一样。 3.Avatars for Github 在Github首页上有我关注的人已经关注的项目动态 使用此插件支持在关注的人前面加上头像 这样能更直观看到谁更新了动态信息。 4.ZenHub 增强你的工作流，特别是启动，快速移动工程团队和开源社区等特性构建，支持实时拖拽 Issue Task Boards；通过一个 +1 按钮来进行反馈；支持直接上传任意的文件类型到 GitHub 接口。ZenHub 能把很多进程集中化到 GitHub，让你的团队更精炼更敏捷 5.Github Linker GitHub Linker 支持连接到(相当于IDE里面的代码引用的感觉)NPM，bower，Composer &amp; Duo 到它们的 Github 库页面。它也解决了在 .js, .jsx, .coffee 或 .md 文件的 require() 声明 API调用插件 6.JSONView JSONView是一个将JSON字符串转换为 可读性的格式查看 JSON 的插件。调用API时非常有用 Markdown插件 7.Markdown Editor 支持在Chrome浏览器上所见即所得的编辑MarkDown文本，本人使用较少 但也比较实用 默认的风格为GitHub 其他常用插件 8.Proxy SwitchySharp 设置网络代理 翻墙必备 9.Visual Event 能更直观的看到网页DOM元素上的事件信息以及事件所触发的代码 前端开发神器","tags":[{"name":"googleChrome","slug":"googleChrome","permalink":"https://blog.gitee.io/tags/googleChrome/"},{"name":"chrome","slug":"chrome","permalink":"https://blog.gitee.io/tags/chrome/"}]},{"title":"Hbase Shell在secureCRT中退格键问题解决方法","date":"2016-01-03T16:00:00.000Z","path":"2016/01/04/crtbackspacebug/","text":"使用secureCRT操作Hbase Shell的时候 难免会按错字符,当输入出错后 一般会使用BackSpace(退格)键删除字符。很不巧的是BackSpace键不会当做delete命令,这时需要设置一下CRT 。 首先在选项-&gt;会话选项-&gt;终端-&gt;仿真 终端设置为Linux； 然后勾选下面2个checkbox 在选项-&gt;会话选项-&gt;终端-&gt;仿真-&gt;映射键-&gt;其他设置 Backspace发送delete(B) Delete发送backspace(S)","tags":[{"name":"hbase","slug":"hbase","permalink":"https://blog.gitee.io/tags/hbase/"},{"name":"secureCRT","slug":"secureCRT","permalink":"https://blog.gitee.io/tags/secureCRT/"}]},{"title":"apache + tomcat实现集群session同步","date":"2015-10-26T16:00:00.000Z","path":"2015/10/27/apachetomcatClustering/","text":"这次试验是用1台Apache2.2 、 2台tomcat服务器 、并使用Tomcat Connectors–mod_jk.so作为传送介质实现负载均衡。 项目之前在单机上跑 切换到集群环境中 发现一堆的问题出现了,当然还有未知没有发现的。 遗留的问题 如果集群节点多了，发布项目的时候用什么方式发布会比较方便 文件存储的问题怎么解决 系统日志怎么才能实现统一 缓存服务怎么实现同步 数据库并发问题 针对这些问题将在后面的博文中提供解决方案！！！","tags":[{"name":"apache","slug":"apache","permalink":"https://blog.gitee.io/tags/apache/"},{"name":"集群","slug":"集群","permalink":"https://blog.gitee.io/tags/集群/"},{"name":"session同步","slug":"session同步","permalink":"https://blog.gitee.io/tags/session同步/"}]},{"title":"本命年你在哪 干什么 还爱着谁？","date":"2015-10-11T16:00:00.000Z","path":"2015/10/12/ThisAnimalYear/","text":"时间总是在不经意间流走,看着窗外静静的夜晚,偶尔会听到小汽车按喇叭的声音,这时候会特别的觉得甜美,就好像是家的呼唤,总会给予满满的期待与希望。对于我而言那是未来和目标,想想明年就是本命年了,所以这篇文字就在这个夜晚(2015-10-13 00:10:00)诞生了。 你在哪 多大 干什么在一个美丽的山城——重庆,23岁 目前就职于一个不知名的软件公司做一份软件开发的工作(BS软件),因为自己比较喜欢玩电脑所以这份工作自己还算喜欢,也不算很喜欢啦。经常游走在互联网之间,一般都是默默的打开网页,悄悄的关闭网页。 爱着谁 从小时候到现在说爱吧 应该是自己的家人、父亲、母亲、妹妹,很幸运在这个璀璨的年华遇到了她,没能好好珍惜 最后还是离我而去。不怨任何人,只怪自己。从校园到社会遇到了很多兄弟朋友这是一生中无价的财富,所以也是爱他们的。 想做什么 工作上想来一转身 期望专注于前端,因为我更想和用户近距离的接触,更认真的去了解他们。 都说北京是一个实现的梦想的地方 当然这么卑微的我也多少会受到一些影响,可惜没有足够的勇气。 来一次说走就走旅行,去哪里都行。能遇到一生最重要的人。 偶尔也会想想下一个本命年我还会在这个世界上吗？ 会是什么样的人呢？ 那时的我36岁,应该已经结婚有孩子了吧。 本命年你在哪呢 多大 干什么呢? 爱的人还是她吗? 还有梦想吗? 下一个本命年呢? 非常期待听听你们的人生。","tags":[{"name":"本命年感慨","slug":"本命年感慨","permalink":"https://blog.gitee.io/tags/本命年感慨/"}]},{"title":"Linux 简单的进程管理","date":"2015-09-11T16:00:00.000Z","path":"2015/09/12/linux.processmgr/","text":"进程管理的内容有点多,这里简单介绍一下,以后将详细说明系统调度、进程管理等内容。 需要明白父子进程的概念 子进程是由另一个进程所产生的，产生这个子进程的进程称为父进程 父进程终止后 子进程会自动终止。但是子进程终止后 有可能会又会自动创建子进程。 w 查看当前系统活动的信息 可以带参数user 如 w user ps 查看进程用的比较多的命令。 kill 杀死(终止)进程 killall -u apache 终止指定用户apache的进程。 sleep 10000 让当前进程睡眠10000 jobs 查看后台进程 bg # 让后台的第#个进程运行。如 bg 1 在前台运行的进程时按下Ctrl+z 可以让当前执行的进程在后台运行。","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"},{"name":"linux进程","slug":"linux进程","permalink":"https://blog.gitee.io/tags/linux进程/"}]},{"title":"Linux 软件的常用安装方法","date":"2015-09-11T16:00:00.000Z","path":"2015/09/12/linux.softInstall/","text":"对于操作系统而言,如果没有软件和一些任务算法 那么这个系统意义是不大的。而我们使用操作系统目的是为了让一些软件和任务能够运行在系统上,从而帮助我们提高工作的效率。 在Linux系统中常用的软件安装方式有yum rpm gcc（编译源码安装） 这3种方式，以下内容将对着3种安装方式做详细的介绍。","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"},{"name":"linux软件安装","slug":"linux软件安装","permalink":"https://blog.gitee.io/tags/linux软件安装/"}]},{"title":"Linux vi编辑工具","date":"2015-09-10T16:00:00.000Z","path":"2015/09/11/linux.VIEditor/","text":"vi编辑器在linux系统中应该算是人气很高的一个工具了,在这里简单介绍一下伟大的vi vim一些功能与使用。 基本使用 用vi创建一个文件 [root@localhost ~]# vi mytxt ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \"mytxt\" [New File] 如果是新创建的文件会在最后的命令行左下角标识 &quot;文件名&quot; [New File] 的字样。 vi的工作模式分为 命令模式 输入模式 转义模式 1、转义模式 该模式一般通过:号触发输入一些命令后按下Enter键执行。 通过Esc键退出焦点(进入命令模式),输入:号 进入vi编辑器工具命令行 输入wq命令 保存并退出编辑,q!命令退出不保存,下面列举几个常用的转义模式命令。 名称 说明 示例 :q! 退出VI 放弃保存 q! :w 在编辑模式下执行保存操作 :w! 在编辑模式下执行强制保存操作 :wq 保存并退出VI wq :f 显示当前的文件名、光标所在行的行号以及显示比例 :set nu 显示行号 :set nu :set nonu 取消行号显示 :1[数字] 让光标定位到第[？]行 :5 光标定位到第5行 :$ 光标定位到最后一行 2、命令方式 进入vi后默认是命令模式 当输入正确vi内置的命令后会响应操作，否则发出警告 提示这不是一个vi命令。 名称 说明 示例 ^ 把光标定位到本行的首字符 $ 把光标定位到本行的尾字符 i 命令模式切换为编辑模式 a 切换到编辑模式 当前光标的字符后面 A 切换到编辑模式下 定位光标到当前行的最后一个字符 o 将光标定位到新插入的下一行 cw 删除光标之后一个单词 c$ 删除光标之后的字符 c^ 删除光标之前的字符 w 将光标往下移动一行 b 将光标往上移动一行 e 将光标定位到下一行的最后一个字符 G 将光标定位到最后一行 #G 将光标定位到指定行 2G将光标定位到第2行 复制 粘贴 撤销 名称 说明 示例 yy 复制整行 yw 复制当前光标之后所在单词字符 y$ 复制当前光标到行尾字符 y^ 复制当前光标到行首支持 p/P 粘贴 u 取消最近一次操作的 U 取消当前行进行的所有操作 Ctrl+r 对使用u命令撤销的操作进行恢复 字符串查找 vi中查找字符串使用/, ?字符触发 需要注意的是/向光标以下查找,?向光标位置以上查找 如查找光标以后文档中的 name ~ ~ ~ ~ /name 被查到的字符会被高亮显示,如果文档中存在多个相同的字符串需要使用n下一个 | N上一个 查找。 字符串替换 当然一个方便好用的字符串编辑工具必须具备替换文字操作,这样才能增加写作的效率。 使用命令:s/替换字符串。 基本语法 :s/A/B 替换一行的一处 A 为B :s/A/B/g 替换一行的多处 A 为B :s/A/B/c 替换的时候有确认提示 1,20s/A/B/g 1-20行 将A替换为B 如替换一处name为 xingming ~ ~ ~ ~ :s/name/xingming 同时编辑多个文件 使用VI 后面加多个文件名称即可 用的不是很多 如需要同时打开a.txt b.txt c.txt 只需 vi a.txt b.txt c.txt 默认打开第一个。 :arts 显示多文件信息 :next 向后切换文件 :prev向前切换文件 :first 定位首个文件 :last 定位最后一个文件 Ctrl+^快速定位到编辑器中切换前的文件 常用的命令没有这么多 大部分命令都是经过自己在centos6.5上测试过。难免有错误 欢迎拍砖。","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"javascript中with的用法","date":"2015-09-08T16:00:00.000Z","path":"2015/09/09/js.with/","text":"在面向对象的JS和一些其他的很多场景会遇到同时针对同一个对象的N个属性取值或设置N个属性的值,你会发现出现了很多的重复的代码,简直就是丧心病狂.. 如下 //声明 了一个user对象var user=&#123; name:'user1', age:20, sex:1 //.....可能还有n字段&#125;;console.info(user.name);//打印nameconsole.info(user.age);//打印ageconsole.info(user.sex);//打印sex//console.info(user....);//可能会打印更多的信息","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"念大学有什么用处呢","date":"2015-09-08T16:00:00.000Z","path":"2015/09/09/ToUniversity/","text":"为什么必须上大学呢? 一、同学 你的大学同学及朋友，将是你人生当中的宝贵财富。可以说，你的同学对你的重要性，仅次于你的亲人。无论何时何地，你都有可能获得来自同学的友情、帮助与安慰。很多大公司的崛起，都是一帮同学共同努力的结果。很多人的一生的成功，都是因为一个志趣相同的优秀同学。 甚至你可能还会收获爱情，收获你的另一半，而爱情，是人生中与事业同等的两件大事之一，其重要性不言而谕。 即使你大学时没收获爱情，你的大学也很重要。哪个青年人找对象会不考虑对方的学历呢？ 二、你自己 大学四年，和一帮与你差不多优秀的、比你更优秀的或是不如你优秀的人在一起，使你加深了对自己的真正了解。 你了解到，你其实并不是那么牛逼，因为有人比你更牛逼，虽然你曾经认为自己很牛逼。当然你也可能了解到你并不是那么无能，因为有人比你更无能。 由于大学环境的宽松，你可以做自己喜欢做的事情，而不是象中学生那样只知道学习。你了解了自己究竟喜欢什么，讨厌什么。你了解了自己擅长做什么，不擅长做什么。你了解了自己的优点和缺点。 你对自己的了解逐渐接近真实。你不再狂妄自大，也不再妄自菲薄。 这就是成熟。 三、修养 你见过暴发户吗？ 很多暴发户虽然挣了很多钱，可以他们身上却散发着庸俗、铜臭与粗鲁。这正是因为他们没上过大学，即使一身名牌、百般妆扮，也不能掩盖本身人文素养的缺失。大学四年，你一直和有知识、有文化的人在一起，看音乐会，看画展，参加社团，读各种书籍，你的文化修养、艺术修养、人文素养、道德修养都在不断地加深。在人文素养方面，你要大大超过那些没上过大学的人。 如果你有了钱，你可能会选择艺术享受比如听音乐会、看话剧甚至是艺术收藏，这是高层次的精神享受。而缺乏人文修养的人可能会去大吃大喝、购买奢侈品，甚至是黄、赌、毒，这是低层次的感官享受。 你可能不如暴发户有钱，但你的人生质量是另一个层次。 我并没有看不起有钱人的意思，实际上，很多暴发户后悔没有好好读过书，很多富翁都对知识分子非常尊重，甚至是羡慕。他们经常通过附庸风雅来显示自己是有品味的，甚至要想尽办法给自己搞个大学文凭。 你在艳羡暴发户们腰缠万贯的同时，殊不知他们也在艳羡你的知识与品味。 四、独立思考能力 大学环境比较宽松，有大量的时间可以自由安排，这锻炼了你的独立性。这种锻炼是必要的，因为你早晚要独立生活。当然一开始你可能不适应，你会无所事事、浪费光阴，但这是提高独立能力的必经之路和代价，你由此认识到了光阴的可贵。 你有了思考自己、思考社会的时间，你可以对各种社会问题给出自己的见解。如果不懂，你会上网、会去图书馆去了解相关知识。 你不再人云亦云，你拥有独立思考能力，你会自己去判断对与错。 你不再迷信权威，你知道了很多专家、教授不过是徒有其名，他们的言论其实不比你高明，甚至是胡说八道、无耻谰言、屁话连篇。你知道了很多官员的话是假大虚空，他们道貌岸然的后面，是对财色与权势的追逐。 你明白了社会与人性的复杂性、多面性，你更加理性了。 你一般不会去违法犯罪，大部分暴力罪犯都是低学历的、没上过大学的人，这些人犯罪都缺乏技术含量。 你即使犯罪，那也应该是高智商犯罪。 五、知识 虽然你可能经常逃课，虽然你可能多次挂科，虽然你经常在课堂上睡觉，但是实际上，你仍然获得了很多的知识。你对你的专业，总会比那些没上过大学的人，了解的要多。如果你很认真，那么你收获颇丰，虽然你可能没有感觉到。理工科的学生，更是学到了不少实实在在的东西。 你曾经羡慕很多没上过大学的人成了小老板，但他们也只能做个小老板，而你可能会成为大老板，但你需要耐心。 现在，挣大钱越来越需要知识。 中国第一代富人发迹于八十年代初，代表是农民企业家，靠机遇和胆子，别人不敢离开集体单干，不敢做生意，他敢，于是他成功了。但是由于他们的文化水平普遍较低，不懂管理，到现在，很多公司已经面临困境甚至已消失。 第二代企业家，靠政策，靠关系。而新的第三代企业家，靠知识，靠脑子，很多人都是高学历并有丰富的海外工作和留学经验。 没有知识，可以做小生意，做不成大生意。经济社会的高端产业是金融与投资业，没有知识的人，是做不来的。没有知识的人，只能在低端产业徘徊。 六、学历、文凭 我当然相信，学历的高低不等于成就的高低。但在初次就业的时候，你的学历决定了你大致能从事哪个范围内和层次内的工作。 学历不同，初次就业的工作层次、工资层次是不同的，当然层次之间有交叉。每年的工资调查也都说明，学历高的人，平均工资高于学历低的人。 大学起码给了你一张文凭，有了这张文凭，你才有资格到那些大公司和政府机关应聘。如果没上过大学，农村的孩子多数要回家种地或成为民工;城里的孩子会让父母为你的未来伤透脑筋。 关于做生意、当老板，不要因为没有上过学的人做老板而眼红。因为你即使上了大学，照样可以选择做生意、当老板。 七、人际交往能力 在大学里，所有的人际关系都要你自己来处理。学校虽然比社会单纯，但已经是相当复杂。同学关系、室友关系、师生关系、男女关系、贫富关系，做干部还有上下级关系、干群关系等，处理好这些关系，是需要动脑筋的，也是需要能力的。 你在学校处理关系的经验与教训会对你走上社会带来帮助。 八、见识 通过上大学，你增长了很多见识，认识了来自五湖四海的、南腔北调的同学。 农村来的学生，见识了大城市的现代化，见识了花花世界的丰富多样。城里学生通过农村的孩子，也了解了全国各地的风土人情。 你认识了很多优秀的同学和一些优秀的老师，你从他们身上会学到很多。 这使你的眼界开阔了，视野开阔了，心胸开阔了，未来之路也开阔了。 九、孩子 孩子看起来离你很远，其实不远，你毕业后也许不用四年，你的孩子就出世了。你上不上大学，会影响你的子孙后代。 你的文化水平将影响你的教育水平，同时对你的孩子的一生产生重大的影响。 我们不能说没有文化的父母就培养不出好孩子，但是有文化的父母能给孩子带来更多的和更大的帮助。起码在孩子中小学作业题不会做的时候，你可以帮得上忙。 总体来看，有文化的父母的孩子比没有文化的父母的孩子生活得更好，当然不排除个例。 十、美好的回忆 相信我，离开学校不久，你就会无比地怀念你的大学时光，还有那些哥们儿、姐们儿。你会发现，曾经无聊的大学生活回忆起来是那样的美好!你会后悔，你没有好好地利用你的大学年代。 最后要提醒你的是：你只有上了大学，才有资格思考“上大学有什么用”。 确实是你上了大学，而不是大学上了你。 我知道当前的大学存在很多的问题，存在很多的弊病和黑暗面。但上大学仍然很有用。如果上帝让你回到四年前，再让你选择一次上不上大学，我相信你会不加思索地说：“那还用说嘛！（来源） 文章摘自励志网。","tags":[{"name":"大学","slug":"大学","permalink":"https://blog.gitee.io/tags/大学/"}]},{"title":"Linux查找","date":"2015-09-04T16:00:00.000Z","path":"2015/09/05/linux.find/","text":"","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"Linux用户切换","date":"2015-09-04T16:00:00.000Z","path":"2015/09/05/linux.switchUser/","text":"有时候用一个普通权限的用户登录系统 而需要管理员的权限的时候可以使用su 或者sudo命令完成。 如 在abc用户下 切换到root用户 从而实现一些root权限的操作 [abc@localhost ~]$ su rootPassword: [root@localhost abcabc]# 还有一种需求是 我不希望切换到root用户环境下,但是我想暂时拥有root权限 可以使用sudo 如下在abc用户下想查看/etc/shadow这个文件内容 而这个文件是权限只是对root可读，使用以下命令 输入密码后可顺利执行。 [abc@localhost ~]$ sudo cat /etc/shadow","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"Linux用户与用户组管理","date":"2015-09-04T16:00:00.000Z","path":"2015/09/05/linux.usergroupmanager/","text":"Linux 为系统默认配置了N多的用户 它们都保存在/etc/passwd文件中。如下图","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"javascript事件冒泡问题","date":"2015-08-31T16:00:00.000Z","path":"2015/09/01/eventBubbling/","text":"一个如上图的DOM结构 首先是table-&gt;tr-&gt;td-&gt;div-&gt;span，分别使用jQuery的api对td div span 分别绑定了click事件。代码如下 $(\"#join td\").click(function()&#123; alert(\"这是td\"); &#125;); $(\"#join div\").click(function()&#123; alert(\"这是div\"); &#125;); $(\"#join .abc\").click(function()&#123; alert(\"这是span\"); &#125;); 当点击td的时候弹出”这是TD”、点击div的时候弹出”这是DIV”,”这是TD”、点击span的时候弹出 “这是span”,”这是DIV”,”这是TD” 这种现象被称为事件的传播，也叫事件冒泡 事件冒泡通常在使用中不合理的。那么怎么解决呢? 在W3c中，使用stopPropagation、preventDefault方法可以可以制止事件的默认行为。 $(\"#nojoin td\").click(function(event)&#123; alert(\"这是td 2\"); event.preventDefault(); event.stopPropagation();&#125;);$(\"#nojoin div\").click(function(event)&#123; alert(\"这是div 2 \"); event.preventDefault(); event.stopPropagation();&#125;);$(\"#nojoin .abc\").click(function(event)&#123; alert(\"这是span 2\"); event.preventDefault(); event.stopPropagation();&#125;); 嘿 这次实验成功了。得到了我们期望的效果。 使用jQuery事件回调return false 也可以实现相同的效果。从而少些一些代码，何乐而不为呢。 $(\"#nojoin td\").click(function(event)&#123; alert(\"这是td 2\"); return false;&#125;);$(\"#nojoin div\").click(function(event)&#123; alert(\"这是div 2 \"); return false;&#125;);$(\"#nojoin .abc\").click(function(event)&#123; alert(\"这是span 2\"); return false;&#125;); 其实jQuery的事件回调中可以通过return false来阻止事件传播。翻阅jQuery源码 只要return false 其实它也是执行了 preventDefault,stopPropagation 这2个方法。 附上jQuery源码 if ( ret !== undefined ) &#123; if ( (event.result = ret) === false ) &#123; event.preventDefault(); event.stopPropagation(); &#125;&#125; 本示例演示地址:https://cqweclick.github.io/eventBubbling.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"Linux文件权限配置","date":"2015-08-29T16:00:00.000Z","path":"2015/08/30/linux.file.authority/","text":"简单的使用ls -l 一下就可以看到当前目录的文件列表 其中列表中包含了文件的权限信息、宿主用户、所属用户组、文件大小、时间 等一些列信息。 权限字符串 文件的权限字符一共是10位，第1为是文件类型。后面分别为3组权限如下所示。 r表示可读 、w表示可写、x表示可执行(可以理解为可以看到)、- 表示没有权限使用-站位。 文件类型 宿主权限 用户组权限 其他用户权限 d - rwx rwx rwx 字符串授权 宿主权限 用户组权限 其他用户权限 u+操作（r/w/x） g+操作（r/w/x） o+操作（r/w/x） 在管理员权限下使用命令chmod进行授权 如 文件text.txt授权用户组 写读、可写、写执行权限 chmod g+rwx text.txt 如 文件text.txt删除用户组 写读、可写、写执行权限 chmod g-rwx text.txt 如 文件text.txt授权其他用户 写读、可写权限 chmod o+rw text.txt 如 文件text.txt授权宿主用户 写读 权限 chmod u+r text.txt 看起来比较简单，但是授权的过程比较繁琐 不方便。不支持对宿主 用户组 其他用户同时授权，那么接下来将使用数字的方式授权就相对于方便很多了。 数字授权 同样和字符串授权一样也是分为3组权限 如下。只是权限操作使用数字来替代 变得更加灵活了。 宿主权限 用户组权限 其他用户权限 r=4、 w=2、 x=1 r=4、 w=2、 x=1 r=4、 w=2、 x=1 列举一个例子，以前不懂授权的时候 在网上搜索 为文件授权的命令是chmod 777 filename 我真的很纳闷777是什么意思呢? 直到今天才明白第一个7代表宿主权限（4+2+1）,第2个7代表用户组权限（4+2+1）,第3个7代表其他用户（4+2+1）。所有这个命令的意思就是授予宿主、用户组、其他用户的权限都有可读、可写、可执行。 列举一个场景 为宿主用户授予可读、可写、可执行，为用户组授予可读、可写、可执行、为其他用户授予可读，不可写，可执行权限 宿主权限：4+2+1 用户权限:4+2+1 其他用户权限:4+1 所以 这个权限数字为775 linux的权限感觉比较繁琐，但还是比较好理解。这里只记录这一点。对日常的操作已经满足了。还有更深入的权限操作没有讲到。","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"Linux常用命令","date":"2015-08-28T16:00:00.000Z","path":"2015/08/29/linux.general.command/","text":"首先介绍几个方便的操作 通配符 * 匹配任意字符 如 test* ? 匹配任意单个字符 如 te?t [] 匹配任意指定的字符 如myn[123] 匹配 myn1 、myn2 myn3 命令补全 在编写命令的时候 如mkdir命令 输入mk按下Tab键会把mk开头的所有命令显示出来。当然也可以匹配文件 在使用过程中效率非常高。 命令历史 使用命令history可以查看当前用户键入过的所有命令。 使用!!命令可以执行上一次执行命令。 也可以使用! 跟上命令前缀或命令全名 会在历史记录中查找并执行命令。 常用命令 组合命令 以ls为例 ls -al 表示同时显示所有文件 并显示详细信息。 常用命令 ls 浏览 文件目录信息 默认是当前文件也可以使用参数 ls -a /etc/ 一些linux系统还支持ll命令 效果如ls命令，但ls是标准的命令所有linux系统都支持。 pwd 当前所在目录的路径 pwd cd 进入到指定的目录 /代表根目录 常用的文件系统操作 在介绍文件操作的命令之前介绍一下Linux的文件类型 d 目录文件。 l 符号链接(指向另一个文件,类似于瘟下的快捷方式)。 s 套接字文件。 b 块设备文件,二进制文件。 c 字符设备文件。 p 命名管道文件。 - 普通文件，或更准确地说，不属于以上几种类型的文件 mkdir 创建目录 mkdir ttt rmdir 删除目录 rmdir ttt file 显示文件的类型 touch 创建或更新文件 cp 复制文件 cp 需要复制的文件 新的文件名称 复制目录需要加上参数-r rm 删除文件 删除目录需要加参数-r -f参数可以不用确认 mv 移动文件 mv 文件 移动文件的目标位置 cat 查看文件内容 不分页 more 查看文件内容 分页 less 查看文件内容 分页 和more一样 head 查看文件指定前几行内容 如head -10 /etc/passwd 显示前10行内容 tail 查看文件指定后几行内容 如tail -10 /etc/passwd 显示后10行内容 方便的重定向功能 重定向分为 输入重定向、输出重定向、错误重定向。 如 cat test.txt&gt; testlog.txt 会把cat的结果重定向到testlog.txt文件中。会追加数据 cat test.txt &gt;&gt; testlog.txt 会把cat的结构重定向到testlog.txt文件中，会覆盖以前的数据。 管道操作 什么是管道? 我认为管道就是为一些结果做过滤操作的，比较实用。 | 表示管道连接符 如 ls -l | more 会分页显示ls的结果 ls -l |grep fff 会过滤出ls中包含fff的结果","tags":[{"name":"linux","slug":"linux","permalink":"https://blog.gitee.io/tags/linux/"}]},{"title":"HTTP Header详细文档","date":"2015-08-18T16:00:00.000Z","path":"2015/08/19/httpinfolist/","text":"HTTP（HyperTextTransferProtocol）即超文本传输协议，目前网页传输的的通用协议。HTTP协议采用了请求/响应模型，浏览器或其他客户端发出请求，服务器给与响应。就整个网络资源传输而言，包括message-header和message-body两部分。首先传递message- header，即http header消息 。http header 消息通常被分为4个部分：general header, request header, response header, entity header。但是这种分法就理解而言，感觉界限不太明确。根据维基百科对http header内容的组织形式，大体分为Request和Response两部分。 Requests部分 Header 含义 例子 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集。 Accept-Charset: iso-8859-5 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型。 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接。（HTTP 1.1默认进行持久连接） Connection: close Cookie |HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。| Cookie: $Version=1; Skin=new;||Content-Length |请求的内容长度| Content-Length: 348||Content-Type |请求的与实体对应的MIME信息 |Content-Type: application/x-www-form-urlencoded||Date |请求发送的日期和时间 |Date: Tue, 15 Nov 2010 08:12:31 GMT||Expect |请求的特定的服务器行为| Expect: 100-continue||From |发出请求的用户的Email| From: user@email.com||Host |指定请求的服务器的域名和端口号 |Host: www.zcmhi.com||If-Match |只有请求内容与实体相匹配才有效| If-Match: “737060cd8c284d8af7ad3082f209582d”||If-Modified-Since |如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码| If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT||If-None-Match |如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 |If-None-Match: “737060cd8c284d8af7ad3082f209582d”||If-Range | 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag| If-Range: “737060cd8c284d8af7ad3082f209582d”||If-Unmodified-Since | 只在实体在指定时间之后未被修改才请求成功 |If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT||Max-Forwards |限制信息通过代理和网关传送的时间| Max-Forwards: 10||Pragma |用来包含实现特定的指令| Pragma: no-cache||Proxy-Authorization | 连接到代理的授权证书| Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==||Range |只请求实体的一部分，指定范围| Range: bytes=500-999||Referer |先前网页的地址，当前请求网页紧随其后,即来路 |Referer: http://blog.peachyy.com||TE |客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息| TE: trailers,deflate;q=0.5||Upgrade |向服务器指定某种传输协议以便服务器进行转换（如果支持）| Upgrade: HTTP/2.0, |SHTTP/1.3, IRC/6.9, RTA/x11||User-Agent | User-Agent 的内容包含发出请求的用户信息 |User-Agent: Mozilla/5.0 (Linux; X11)||Via | 通知中间网关或代理服务器地址，通信协议| Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)||Warning |关于消息实体的警告信息 |Warn: 199 Miscellaneous warning| Responses Header 含义 例子 Accept-Ranges 表明服务器是否支持指定范围请求及哪种类型的分段请求 Accept-Ranges: bytes Age 从原始服务器到代理缓存形成的估算时间（以秒计，非负） Age: 12 Allow 对某网络资源的有效的请求行为，不允许则返回405 Allow: GET, HEAD Cache-Control 告诉所有的缓存机制是否可以缓存及哪种类型 Cache-Control: no-cache Content-Encoding web服务器支持的返回内容压缩编码类型。 Content-Encoding: gzip Content-Language 响应体的语言 Content-Language: en,zh Content-Length 响应体的长度 Content-Length: 348 Content-Location 请求资源可替代的备用的另一地址 Content-Location: /index.htm Content-MD5 返回资源的MD5校验值 Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ== Content-Range 在整个返回体中本部分的字节位置 Content-Range: bytes 21010-47021/47022 Content-Type 返回内容的MIME类型 Content-Type: text/html; charset=utf-8 Date 原始服务器消息发出的时间 Date: Tue, 15 Nov 2010 08:12:31 GMT ETag 请求变量的实体标签的当前值 ETag: “737060cd8c284d8af7ad3082f209582d” Expires 响应过期的日期和时间 Expires: Thu, 01 Dec 2010 16:00:00 GMT Last-Modified 请求资源的最后修改时间 Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT Location 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源 Location: http://www.zcmhi.com/archives/94.html Pragma 包括实现特定的指令，它可应用到响应链上的任何接收方 Pragma: no-cache Proxy-Authenticate 它指出认证方案和可应用到代理的该URL上的参数 Proxy-Authenticate: Basic refresh 应用于重定向或一个新的资源被创造，在5秒之后重定向（由网景提出，被大部分浏览器支持） Refresh: 5; url=http://blog.peachyy.com Retry-After 如果实体暂时不可取，通知客户端在指定时间之后再次尝试 Retry-After: 120 Server web服务器软件名称 Server: Apache/1.3.27 (Unix) (Red-Hat/Linux) Set-Cookie 设置Http Cookie Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1 Trailer 指出头域在分块传输编码的尾部存在 Trailer: Max-Forwards Transfer-Encoding 文件传输编码 Transfer-Encoding:chunked Vary 告诉下游代理是使用缓存响应还是从原始服务器请求 Vary: * Via 告知代理客户端响应是通过哪里发送的 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 警告实体可能存在的问题 Warning: 199 Miscellaneous warning WWW-Authenticate 表明客户端请求实体应该使用的授权方案 WWW-Authenticate: Basic @see http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html 网络。","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://blog.gitee.io/tags/HTTP/"}]},{"title":"java8中的一些新特性","date":"2015-08-09T16:00:00.000Z","path":"2015/08/10/java8newcharacteristics/","text":"最近看了一下java8中的新增特性 新添加的东西个人认为并不多，主要是lambda表达式 其他的比较少。 因为之前看过Groovy 它里面有一种语法叫闭包/Closure 而java8中的lambda和Groovy中所谓的闭包非常相似，官方也称lambda表达式也可以叫闭包 难道是相互模仿? 不过ruby这些语言的写法确实非常优雅 未来的java语法也会像ruby一样么 这个是未知的。至少Groovy的出现 证明是可以这么做的。 函数的引用 这里所说的函数 包含普通函数 和构造函数 java8中使用 :: 关键字来传递方法或者构造函数引用 示例如下 这里引用了Integer.valueOf()方法public class FunctionDemo &#123; public static void main(String[] args) &#123; Function&lt;String,Integer&gt; fordate=Integer::valueOf; Integer l=fordate.apply(\"25\"); System.out.println(l); &#125;&#125; Lambda 表达式 其实会了Groovy中的闭包以后 java中Lambda表达式基本差不多。 语法: ()-&gt;{} (int x, int y) -&gt; x + y; (x, y) -&gt; { return x + y; } //显式指明返回值 可见由3部分组成 参数列表，箭头（-&gt;），以及一个表达式或语句块 先给出一个demo 在后面会频繁的使用到Lambda表达式 一个foreach循环 只需要一行代码就搞定。是不是又节约了代码了呢public class LambdaDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list=new ArrayList&lt;&gt;(); list.add(\"a1\"); list.add(\"a2\"); list.add(\"a3\"); list.add(\"a4\"); list.add(\"a5\"); list.add(\"a6\"); list.add(\"a7\"); list.forEach(o -&gt; &#123;System.out.println(o);&#125;); //... &#125;&#125; 在接口(interface)中定义默认方法实现 public interface foo &#123; public void sayHell(String hello); //默认方法 default double abs(int a) &#123; return Math.abs(a); &#125; //impl public class fooimpl implements foo&#123; @Override public void sayHell(String hello) &#123; System.out.println(\"say:\"+hello); &#125; public static void main(String[] args) &#123; foo f=new fooimpl(); f.sayHell(\"fff\"); System.out.println(f.abs(20)); &#125; &#125;&#125; 函数式接口 首先介绍一个注解 @FunctionalInterface 用来表示这个接口类是不一般的。这是一个函数式接口 如果你违反了函数式接口的规范 那么编译器就会报错,当然这个不是必须的、为了方便阅读代码尽量应该标识。 什么是函数式接口呢? 接口中可以额外定义多个抽象方法、需要注意的是这些抽象方法的修饰签名必须和Object的public一样 举个例子 示例一 是函数式接口 @FunctionalInterfacepublic interface ccc &#123; void sum(); //来自父类public的toString方法 @Override String toString();&#125; 示例二 不是函数式接口 因为clone不是public @FunctionalInterfacepublic interface ccc &#123; void sum(); //来自父类protected的clone方法 @Override Object clone();&#125; 列出java8之前已有的函数接口 java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.nio.file.PathMatcher java.lang.reflect.InvocationHandler java.beans.PropertyChangeListener java.awt.event.ActionListener javax.swing.event.ChangeListener java8新定义的函数式接口 在rt.jar java.util.function包中 java.util.function.Predicate java.util.function.Consumer java.util.function.Function java.util.function.Supplier java.util.function.UnaryOperator java.util.function.BinaryOperator 那么接下来自定义一个简单的函数接口，你会发现与其他的普通java接口的区别莫过于实现具体的方式变了、变得更加简单 要是jdk1.8之前 会使用到匿名类或者写一个实现类 看到这种写法 以前简直就弱爆了。这就是函数式接口的魅力所在。 @FunctionalInterface//定义一个函数接口cccpublic interface ccc &#123; int sum(int x,int y); @Override String toString(); //这是一个测试类 public class cccTest&#123; public static void main(String[] args) &#123; //一行代码告别匿名类 ccc target=( x, y)-&gt;&#123; int sum=x+y;return sum;&#125;; //调用sum方法 System.out.println(target.sum(9, 4)); &#125; &#125;&#125; Predicate 接口 示例 当传入的参数为null或者长度=0 或者长度&gt;3 那么返回true 否则返回false 接口里面默认提供几个默认方法 default Predicate and(Predicate&lt;? super T&gt; other) 追加and条件 default Predicate negate() 从源码来看 应该是取反值得意思 如test()返回true 那么negate返回false 反之 default Predicate or(Predicate&lt;? super T&gt; other) 追加or条件 示例有用到 public class PredicateDemo &#123; public static void main(String[] args) &#123; Predicate&lt;String&gt; lengthgt3=(s)-&gt;&#123;return s!=null &amp;&amp;s.length()&gt;3;&#125;; lengthgt3=lengthgt3.or((s)-&gt;&#123;return s==null|| s.length()==0;&#125;); boolean b=false; b=lengthgt3.test(null); System.out.println(b); &#125;&#125; Function 接口 示例 public class FunctionDemo &#123; public static void main(String[] args) &#123; Function&lt;String,Integer&gt; fordate=Integer::valueOf; Integer l=fordate.apply(\"25\"); System.out.println(l); &#125;&#125; Supplier 接口 示例 实例化对象 需要注意的是 对象必须要拥有一个无参的构造函数 否则会编译出错。supplier紧紧只有一个get方法 public class SupplierDemo &#123; public static void main(String[] args) &#123; Supplier&lt;User&gt; personSupplier = User::new; User u=personSupplier.get(); System.out.println(u.getClass()); &#125;&#125; Consumer 接口 示例 操作单个对象处理 具有一个默认方法 default Consumer andThen(Consumer&lt;? super T&gt; after) public class ConsumerDemo &#123; public static void main(String[] args) &#123; User u1=new User(\"xx1\",20); User u2=new User(\"xx2\",21); Consumer&lt;User&gt; opt=(u)-&gt;&#123;System.err.println(u.getName()+\"年龄是\"+u.getAge());&#125;; opt.accept(u2); &#125;&#125; 操作单个数据 感觉用处并不是很大。 Comparator 接口 示例 比较的时候用得比较多 JDK8中又新增一些方法。以下示例实现了使用compareTo 方法对user对象按照age字段排序public class ComparatorDemo &#123; public static void main(String[] args) &#123; User u1=new User(\"xx1\",25); User u2=new User(\"xx2\",21); List&lt;User&gt; uList=new ArrayList&lt;&gt;(); uList.add(u1); uList.add(u2); uList.sort((t ,t1)-&gt;&#123; return t.getAge().compareTo(t1.getAge()); &#125;); for (int i = 0; i &lt; uList.size(); i++) &#123; System.out.println(uList.get(i).getName()+\"~\"+uList.get(i).getAge()); &#125; &#125;&#125; 还有一些JDK8自带的 函数式接口 不再一一列举 使用方式都差不多一样的。 Stream序列 Stream接口拥有很多方法。都是很方便操作数据的。如 Filter 、Sort、count、min、max等等。","tags":[{"name":"java","slug":"java","permalink":"https://blog.gitee.io/tags/java/"},{"name":"java8","slug":"java8","permalink":"https://blog.gitee.io/tags/java8/"},{"name":"新特性","slug":"新特性","permalink":"https://blog.gitee.io/tags/新特性/"}]},{"title":"js常见面试题","date":"2015-07-21T16:00:00.000Z","path":"2015/07/22/simplejsPreview1/","text":"列出几道js面试中的题,无意中在什么站点看到的，便记录一下。看完这些题后 你还敢说js很简单么,简直是最优雅 博大精深的语言了。 1、函数声明优先于var var a;function a() &#123; &#125;alert(typeof a); // ? 2、this scope arguments scope var length = 10function fn()&#123; alert(this.length)&#125;var obj = &#123; length: 5, method: function(fn) &#123; fn() // ? arguments[0]() // ? &#125;&#125;obj.method(fn) 3、函数表达式具名（函数声明同时赋值给另一个变量）或函数声明立即执行时，名仅在该函数内可访问 (不考虑IE 6 7 8) ~function() &#123; alert(typeof next) // ? ~function next() &#123; alert(typeof next) // ? &#125;()&#125;() 4、隐式的全局变量 var a = 1function func() &#123; a = b = 2&#125;func()alert(a)alert(b) // ? 5、变量声明早于代码运行（Scoping and Hoisting） var uname = 'jack'function change() &#123; alert(uname) // ? var uname = 'lily' alert(uname)&#125;change() 还敢说自己JS很NB么 来源于网络、具体在哪记不得了 后来补上出处。由于自己也并非是专业的前端 所以也做错了好几题。","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"浏览器对Notification通知的支持","date":"2015-07-20T16:00:00.000Z","path":"2015/07/21/browerNotification/","text":"记得在上一次的项目中需要实现一个BS的IM通信小功能、当新信息到达时 会在当前网站的右下角弹出一小弹框来提示用户有新的信息了。当时是在站内弹出一个类似WINDOW这样的窗口来实现的。其实这也可以满足用户的需求、当客户又提出来如果在浏览其他网站的时候、或者浏览器最小化的时候 我怎么知道是否有新消息呢? 当时认为这就是CS对于BS而言的优势所在。当然问题一直都没有得到改善 直到最近在W3C上看到http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/ecma-script-binding.html http://www.w3.org/TR/notifications/这篇文章时候、很有自信的说 这种问题已经可以解决了。遗憾的是已经离开了那一家公司。 Notation被W3C提出是浏览器通知的一个标准，最初的草案叫做webkitNotifications 在网上说Notation是未来的标准化，目前还有很多浏览器厂商不支持这个标准。根据测试和网上所知 目前只有Chrome 、Opera支持，相信很快其他浏览器也会被支持，因为真的很有用。比如像人人网、微信网页版 都使用了这种技术，给用户带来了极高的体验。 在chrome console所知 notification拥有一个构造函数 具备以下的一些属性和方法 Notification &#123;icon: \"\", tag: \"\", body: \"I'm an enginneer!\", lang: \"\", dir: \"auto\"…&#125;body: \"I'm an enginneer!\"dir: \"auto\"icon: \"\"lang: \"\"onclick: nullonclose: nullonerror: nullonshow: nulltag: \"\"title: \"Hello Notification\"__proto__: Notificationclose: function close() &#123; [native code] &#125;arguments: nullcaller: nulllength: 0name: \"close\"__proto__: function Empty() &#123;&#125;&lt;function scope&gt;constructor: function Notification() &#123; [native code] &#125;arguments: nullcaller: nulllength: 1name: \"Notification\"permission: \"default\"prototype: NotificationrequestPermission: function requestPermission() &#123; [native code] &#125;toString: function toString() &#123; [native code] &#125;__proto__: function EventTarget() &#123; [native code] &#125;&lt;function scope&gt;__proto__: EventTarget 构造函数一共有2个参数 一个是title 另一个则是配置项 如下 属性 含义 默认值 dir 未知 auto lang 应该是国际化用的 null body 通知内容 null tag 标记/ID null icon 图标 异常显示 null Permission查看权限值 Notification.permission\"default\" permission是一个静态属性 这个属性比较特殊是不可以手动去修改值的，只能用户通过授权提示来控制，他的值一共有3个如下 default 拒绝 denied 用户不需要通知功能 granted 启动通知了 要使用通知 必须要得到用户的授权后才可以使用，使用Notification.requestPermission()向用户请求通知授权 会出现一个是否确认授权的确认框，已经启动通知了将被忽略。 new Notification('notifi',&#123;body:'这是一个优雅的提醒',icon:'http://blog.peachyy.com/public/images/logo.png'&#125;); 执行代码后 会在右下角弹出一个浏览器级别的通知框 demo地址：https://demohubs.github.io/frontendLab/notification.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"爱是什么","date":"2015-07-20T16:00:00.000Z","path":"2015/07/21/lovewhat/","text":"多年后 偶尔会想起曾经是如此放松的快乐。 爱 是什么 爱 怎样才算爱 是爱吗 过了很久 已经完全忘记 如果没有爱 能活下去吗 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;写于不知道第几次回想曾经的快乐 &gt;","tags":[{"name":"爱是什么","slug":"爱是什么","permalink":"https://blog.gitee.io/tags/爱是什么/"}]},{"title":"mongo[一] @环境搭建","date":"2015-07-14T16:00:00.000Z","path":"2015/07/15/mongoEVcreate/","text":"之前研究过一个Nosql数据库 redis 性能真的很好。不用为数据结构的标准规范为烦恼，这也许就是K V结构的真正意义。 mongo也是一种Nosql数据库 但它是基于文档的方式。听起来感觉比redis更好操作 也是当前nosql 比较优的产品，当然redis也是非常优秀的，客户量也很大，所以在这里记录我对mongo的一些使用经历。 mongo几乎支持所有的操作系统，Window、Linux、Mac、Solaris 官方比较建议在linux中使用 具体原因不知。为了方便 这里是使用Window。 下载 在https://www.mongodb.org/downloads 这里使用的版本是2.0.8 for window 附上链接-&gt; http://share.weiyun.com/0d378b0bee389ea583025d9728a5bea0 这是一个ZIP版本,把文件解压到E:\\Dev\\ 并把目录名称改为mongodb 使用命令行进入 E:\\Dev\\mongodb\\bin 目录 也可以把这个加入到计算机的path 加入已经成功把E:\\Dev\\mongodb\\bin加入计算机path E:\\Dev\\mongodb&gt;mongod --versiondb version v2.0.8-rc1-pre-, pdfile version 4.5Wed Jul 15 17:24:12 git version: 1d3d3ba938b9ac0d627fd8039ad8aee79c6968c4 输入命令 mongod –version出现上面的回复。则说明环境安装成功了。 mongod具有很多命令 使用mongod --help可以查看到mongod具备的所有命令。下面是命令的详细说明摘自网络 基本配置----------------------------------------------------------------------------------quiet # 安静输出--port arg # 指定服务端口号，默认端口27017--bind_ip arg # 绑定服务IP，若绑定127.0.0.1，则只能本机访问，不指定默认本地所有IP--logpath arg # 指定MongoDB日志文件，注意是指定文件不是目录--logappend # 使用追加的方式写日志--pidfilepath arg # PID File 的完整路径，如果没有设置，则没有PID文件--keyFile arg # 集群的私钥的完整路径，只对于Replica Set 架构有效--unixSocketPrefix arg # UNIX域套接字替代目录,(默认为 /tmp)--fork # 以守护进程的方式运行MongoDB，创建服务器进程--auth # 启用验证--cpu # 定期显示CPU的CPU利用率和iowait--dbpath arg # 指定数据库路径--diaglog arg # diaglog选项 0=off 1=W 2=R 3=both 7=W+some reads--directoryperdb # 设置每个数据库将被保存在一个单独的目录--journal # 启用日志选项，MongoDB的数据操作将会写入到journal文件夹的文件里--journalOptions arg # 启用日志诊断选项--ipv6 # 启用IPv6选项--jsonp # 允许JSONP形式通过HTTP访问（有安全影响）--maxConns arg # 最大同时连接数 默认2000--noauth # 不启用验证--nohttpinterface # 关闭http接口，默认关闭27018端口访问--noprealloc # 禁用数据文件预分配(往往影响性能)--noscripting # 禁用脚本引擎--notablescan # 不允许表扫描--nounixsocket # 禁用Unix套接字监听--nssize arg (=16) # 设置信数据库.ns文件大小(MB)--objcheck # 在收到客户数据,检查的有效性，--profile arg # 档案参数 0=off 1=slow, 2=all--quota # 限制每个数据库的文件数，设置默认为8--quotaFiles arg # number of files allower per db, requires --quota--rest # 开启简单的rest API--repair # 修复所有数据库run repair on all dbs--repairpath arg # 修复库生成的文件的目录,默认为目录名称dbpath--slowms arg (=100) # value of slow for profile and console log--smallfiles # 使用较小的默认文件--syncdelay arg (=60) # 数据写入磁盘的时间秒数(0=never,不推荐)--sysinfo # 打印一些诊断系统信息--upgrade # 如果需要升级数据库 * Replicaton 参数----------------------------------------------------------------------------------fastsync # 从一个dbpath里启用从库复制服务，该dbpath的数据库是主库的快照，可用于快速启用同步--autoresync # 如果从库与主库同步数据差得多，自动重新同步，--oplogSize arg # 设置oplog的大小(MB) * 主/从参数----------------------------------------------------------------------------------master # 主库模式--slave # 从库模式--source arg # 从库 端口号--only arg # 指定单一的数据库复制--slavedelay arg # 设置从库同步主库的延迟时间 * Replica set(副本集)选项：----------------------------------------------------------------------------------replSet arg # 设置副本集名称 * Sharding(分片)选项----------------------------------------------------------------------------------configsvr # 声明这是一个集群的config服务,默认端口27019，默认目录/data/configdb--shardsvr # 声明这是一个集群的分片,默认端口27018--noMoveParanoia # 关闭偏执为moveChunk数据保存 要启动数据库 必须要为mongo指定一个数据库数据文件的存放的目录 需要使用mongod --dbpath命令来完成，在d:\\dev\\ 创建一个mongodbDATA文件夹 用来存储mongo的数据库文件 mongod --dbpath E:\\Dev\\mongodbDATAWed Jul 15 17:35:26 [initandlisten] MongoDB starting : pid=9368 port=27017 dbpath=E:\\Dev\\mongodbDATA 64-bit host=pc-PCWed Jul 15 17:35:26 [initandlisten] db version v2.0.8-rc1-pre-, pdfile version 4.5Wed Jul 15 17:35:26 [initandlisten] git version: 1d3d3ba938b9ac0d627fd8039ad8aee79c6968c4Wed Jul 15 17:35:26 [initandlisten] build info: windows sys.getwindowsversion(major=6, minor=1, build=7601, platform=2, service_pack='Service Pack 1') BOOST_LIB_VERSION=1_42Wed Jul 15 17:35:26 [initandlisten] options: &#123; dbpath: \"E:\\Dev\\mongodbDATA\" &#125;Wed Jul 15 17:35:26 [initandlisten] journal dir=E:/Dev/mongodbDATA/journalWed Jul 15 17:35:26 [initandlisten] recover : no journal files present, no recovery neededWed Jul 15 17:35:26 [initandlisten] waiting for connections on port 27017Wed Jul 15 17:35:26 [websvr] admin web console waiting for connections on port 28017 到这里 mongo数据库算是启动OK了。注意控制台最后两句Log Wed Jul 15 17:35:26 [initandlisten] waiting for connections on port 27017 Wed Jul 15 17:35:26 [websvr] admin web console waiting for connections on port 28017 数据库连接端口27017 数据库web控制台端口28017 既然是web应该可以使用浏览器访问试试。http://localhost:28017/ 能访问成功能证明我们的数据库是真的启动成功了。 下面将使用客户端连接数据库试试 新开一个CMD命令行窗口 输入mongo 命令 mongodb会自动连接到test数据库 如下所示 C:\\Users\\pc&gt;mongoMongoDB shell version: 2.0.8-rc1-pre-connecting to: test&gt; 说明连接数据库服务器成功了。 环境搭建非常简单。需要熟悉一个mongod的一些常用命令 为后续更深入的了解做铺垫。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.gitee.io/tags/MongoDB/"}]},{"title":"redis客户端 for java","date":"2015-07-13T16:00:00.000Z","path":"2015/07/14/ReadisStudy7/","text":"当然在数据中直接操作redis命令是没有什么价值和意义的，之所以使用她 是让她为我们的应用提供数据存储服务，让客户感受到价值所在。 redis她拥有很多种客户端连接工具 她几乎支持所有语言，比如 c,c#,c++,Clojure,Common Lisp,d,Java,ruby,php….等等。 下面主要描述一下java语言对redis的支持。单单只是java语言的客户端就有好多种，比如Jedis,lettuce,aredis,JRedis等。都是由众多的开发者贡献出来的，将来肯定会越来越多、就当前来说，Jedis lettuce都是比较常用的，其他这么多得客户端连接工具，使用方法都差不多的。所以一般只要能使用一个其他的也是OK的。最喜欢用的还是Jedis 所以以下的示例代码中也将会是使用Jedis连接数据库。 maven依赖 &lt;dependency&gt;&lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; 帮助类 DButi.java public class DButil &#123;//在 org.apache.commons.pool.impl.GenericObjectPool 可以看到一些参数的默认值//主机IPprivate static final String HOST=\"localhost\";//端口private static final Integer PORT=6379;//认证密码private static final String AUTH_PAS=\"xstao\";//最大活动数目private static final Integer MAX_ACTIVE =20;//指定pool池 最多有多少个状态为idle private static final Integer MAX_IDLE=100;//最长等待时间 毫秒private static final Integer MAX_WAIT=5000;//超时private static final Integer TIME_OUT=5000;private static JedisPool poolInstance=null;/*** * 获取jedis 池实例对象 * @date 2015年7月14日 上午11:38:15 * @author xs Tao * @return */public static JedisPool getJedisPoolInstance()&#123; if(poolInstance==null)&#123; //连接redis数据库 的参数对象 JedisPoolConfig config=new JedisPoolConfig(); config.setMaxActive(MAX_ACTIVE); config.setMaxWait(MAX_WAIT); config.setMaxIdle(MAX_IDLE); //创建池 拥有多个构造函数 //如果是默认的端口号 也可以使用默认端口号的构造函数。就连主机也是可以默认的。 poolInstance=new JedisPool(config, HOST, PORT, TIME_OUT, AUTH_PAS); &#125; return poolInstance;&#125;public static Jedis getJedis()&#123; if(poolInstance==null)&#123; DButil.getJedisPoolInstance(); &#125; //从池连接中 获取一个jedis资源 Jedis jedis= poolInstance.getResource(); return jedis;&#125;/** * 销毁jedis连接 * @date 2015年7月14日 上午11:43:03 * @author xs Tao * @param jedis */public static void destory(Jedis jedis)&#123; if(poolInstance!=null &amp;&amp; jedis!=null)&#123; poolInstance.returnResource(jedis); &#125;&#125;&#125; 由于redis是使用K V来存储 所以会存在大量的 难以维护的K 一般会定义个生产KEY的类。用来定义系统K的生成规则 KeyUtils.java public class KeyUtils &#123; static String UID=\"demo:uid\"; static String UID_AUTO_NUM=\"demo-uid-index\"; public static String getUID(String uid)&#123; return UID.concat(uid); &#125;&#125; 用户实体类 public class User implements java.io.Serializable &#123; /** * */ private static final long serialVersionUID = 1L; private String id; private String name; private String password; private String age; private String sex; /** * @return the id */ public String getId() &#123; return id; &#125; /** * @param id the id to set */ public void setId(String id) &#123; this.id = id; &#125; /** * @return the name */ public String getName() &#123; return name; &#125; /** * @param name the name to set */ public void setName(String name) &#123; this.name = name; &#125; /** * @return the password */ public String getPassword() &#123; return password; &#125; /** * @param password the password to set */ public void setPassword(String password) &#123; this.password = password; &#125; /** * @return the age */ public String getAge() &#123; return age; &#125; /** * @param age the age to set */ public void setAge(String age) &#123; this.age = age; &#125; /** * @return the sex */ public String getSex() &#123; return sex; &#125; /** * @param sex the sex to set */ public void setSex(String sex) &#123; this.sex = sex; &#125; public Map&lt;String, String&gt; toMap()&#123; Map&lt;String, String&gt; map=new HashMap&lt;String, String&gt;(); map.put(\"id\", this.id); map.put(\"name\", this.name); map.put(\"password\", this.password); map.put(\"age\", this.age); map.put(\"sex\", this.sex); return map; &#125;&#125; 一个测试类 test.java public class test &#123; public static void main(String[] args) &#123; Jedis jedis=DButil.getJedis(); String uid=String.valueOf(jedis.incr(KeyUtils.UID_AUTO_NUM)); User user=new User(); user.setAge(\"23\"); user.setId(uid); user.setName(\"happy\"); user.setPassword(\"5757124\"); user.setSex(\"男\"); jedis.hmset(KeyUtils.getUID(uid),user.toMap()); System.out.println(jedis.hget(KeyUtils.getUID(uid), \"name\")); &#125;&#125; 还有一个优秀封装redis客户端的项目 叫做http://projects.spring.io/spring-data-redis/ 官方称在将来会兼容所有的redis java语言客户端 示例代码 https://github.com/peachyy/weclickSrc/tree/master/rs-parent/rs-redis","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"当你想放弃的时候就看看这个吧","date":"2015-06-18T16:00:00.000Z","path":"2015/06/19/fillingLookLook/","text":"迷路、想放弃、对生活绝望时看看这个.肯定会好一点的 你可以的","tags":[{"name":"坚持","slug":"坚持","permalink":"https://blog.gitee.io/tags/坚持/"}]},{"title":"Redis[六] @sets 有序集合","date":"2015-06-10T16:00:00.000Z","path":"2015/06/11/ReadisStudy6-sets/","text":"其实redis的有序和无序集合有点类似。差别就在于有序用于一个排序的规则。官方称它为score 分数。默认情况下 分数越小越靠前 zadd 语法 ZADD key score1 member1 [score2 member2] 添加一个或者多个成员到有序集合，如果值已经存在于这个集合中就更新这个值得分数。 zrange 语法 ZRANGE key start stop [WITHSCORES] 如果加了参数withscores 表示 展示列表的时候需要打印值得分数。 返回指定一个索引的范围 的有序集合。stop为-1 表示返回全部索引的数据。 如下示例 演示了 添加一个myzset1集合。并使用zrange命令 展示所有的myzset1集合列表 redis 127.0.0.1:6379&gt; zadd myzset1 0 a(integer) 1redis 127.0.0.1:6379&gt; zadd myzset1 1 b 2 c 3 d(integer) 3redis 127.0.0.1:6379&gt; zrange myzset1 0 -11) \"a\"2) \"b\"3) \"c\"4) \"d\"redis 127.0.0.1:6379&gt; zrem 语法:ZREM key member [member …] 从有序集合中删除一个或多个成员 返回值为删除成功的个数。 zremrangebyrank 语法 zremrangebyrank zset 2 3 按索引（下标） 按索引删除 zremrangebyscore 语法 zremrangebyscore zset 2 3 按分数、也可以理解为按顺序。 按分数/顺序删除 zrank语法 ZRANK key member 返回有序集合中元素 指定元素的索引 redis 127.0.0.1:6379&gt; zrank myzset1 d(integer) 1 zrevrange 语法 zrevrange zset start stop [widthscores] 倒序输出集合 zcount 语法 zcount zset startScope stopScope 返回zset集合中 分数区间个数 如：展示了分数为0-5之前的个数 redis 127.0.0.1:6379&gt; zcount myzset1 0 5(integer) 2redis 127.0.0.1:6379&gt; zcard 语法 zcard myzset1 返回集合中元素的个数 还有很多常用的命令 不再一一列举 。可以到 http://www.yiibai.com/redis/redis_sorted_sets.html //redis.io 查询资料。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"Redis[五] @Set 无序集合","date":"2015-06-10T16:00:00.000Z","path":"2015/06/11/ReadisStudy5-set/","text":"redis提供了2种规则的SET集合 1、有序集合 2、无序集合。 sadd 添加 – 添加一个set key为set1 添加 a-e 当返回1表示添加成功，返回0或其他表示添加失败。 redis 127.0.0.1:6379&gt; sadd set1 a(integer) 1redis 127.0.0.1:6379&gt; sadd set1 b(integer) 1redis 127.0.0.1:6379&gt; sadd set1 c(integer) 1redis 127.0.0.1:6379&gt; sadd set1 d(integer) 1redis 127.0.0.1:6379&gt; sadd set1 e(integer) 1redis 127.0.0.1:6379&gt; smembers 查看 这个set1的集合 使用命令 smembers 语法:smembers key 添加值一次添加a b c d e ，而返回给我们的value并非是添加顺序的列表。所以这是一个无序列表；结果如下。 redis 127.0.0.1:6379&gt; smembers set11) \"a\"2) \"d\"3) \"b\"4) \"c\"5) \"e\"redis 127.0.0.1:6379&gt; srem 删除 –删除set中的元素 命令 srem 语法:srem set value 如下试着删除set1中a元素。 redis 127.0.0.1:6379&gt; srem set1 a(integer) 1redis 127.0.0.1:6379&gt; smembers set11) \"d\"2) \"b\"3) \"c\"4) \"e\"redis 127.0.0.1:6379&gt; 从结果可以看出执行srem命令后 返回1 同样 表示删除成功，成功删除1个元素。当然可以同时删除多个元素 如srem set1 b c d返回的数值是多少就表示成功删除了多少个元素。 spop随机弹出一个元素 这个命令的效果是删除源集合的一个元素。并将这个元素返回。 如spop set1 sdiff 取差集 以set1为基准 获取2个集合中 不一样的数据。语法:sdiff set1 set2 redis 127.0.0.1:6379&gt; smembers set11) \"d\"2) \"b\"3) \"c\"4) \"e\"redis 127.0.0.1:6379&gt; sadd set2 a b d f(integer) 4redis 127.0.0.1:6379&gt; sdiff set1 set21) \"e\"2) \"c\"redis 127.0.0.1:6379&gt; 结果打印e c 因为以set1为基准 只有c e 在set2没有。所以差集就是c e sdiffstore 获取差集并存储在一个集合中 语法:sdiffstore dist set1 set2 同样是以set1(第一个集合)为基准 返回被存储集合长度 redis 127.0.0.1:6379&gt; sdiffstore dist set1 set2(integer) 2redis 127.0.0.1:6379&gt; smembers dist1) \"e\"2) \"c\"redis 127.0.0.1:6379&gt; sinter 获取交集 语法 sinter set1 set2 以set1(第一个集合)为基准获取2个集合的相同的数据。返回值为 2个集合的交集 sinterstore 获取交集并把返回值存储在指定的集合中。语法:sinterstore dist set1 set2 返回值为返回新集合的长度 redis 127.0.0.1:6379&gt; sinter set1 set21) \"d\"2) \"b\"redis 127.0.0.1:6379&gt; sinterstore dist2 set1 set2(integer) 2redis 127.0.0.1:6379&gt; smembers dist21) \"b\"2) \"d\"redis 127.0.0.1:6379&gt; sunion 取并集 语法:sunion set1 set2 简而言之就是把2个集合合并，并且排除相同的数据。 sunion 取并集 、而且把结果存储在指定的对象中。语法:sunionstore dist3 set1 set2 redis 127.0.0.1:6379&gt; sunion set1 set21) \"f\"2) \"b\"3) \"d\"4) \"c\"5) \"a\"6) \"e\" 还有一些常用的命令如下: smove 语法 smove set1 set b 将第1个集合里面的指定元素移动到第2个集合中去。注意是移动 也就是说第1个集合中的被移动的数据将会被删除。 scard 语法 ·scard set1 获取集合元素的个数 sismember 语法 sismember set a 试着判断 a 是否存在于set中 返回值 1标识存在。0标识不存在 srandmember 语法 srandmember set 随机返回集合中的一个元素 。注意只是返回并不会移动源集合的数据。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"Redis[三] @Hash 哈希","date":"2015-06-10T16:00:00.000Z","path":"2015/06/11/ReadisStudy3-hash/","text":"Redis的哈希值是字符串字段和字符串值之间的映射，所以他们是表示对象的完美数据类型 在Redis中的哈希值，可存储超过400十亿键值对。 redis 提供了2套操纵 一种是批量 一种是非批量 假设需要存储一个用户信息 批量操作 定义一个key为user1的hash 包含属性 name=xstao、age=22、sex=1、password=123 并获取user1中name的属性值 redis 127.0.0.1:6379[1]&gt; hmset user1 name xstao age 22 sex 1 password 123OKredis 127.0.0.1:6379[1]&gt; hmget user1 name1) \"xstao\" 获取user1的全部key 、 value、全部的key value redis 127.0.0.1:6379[1]&gt; hgetall user11) \"name\"2) \"xstao\"3) \"age\"4) \"22\"5) \"sex\"6) \"1\"7) \"password\"8) \"123\"redis 127.0.0.1:6379[1]&gt; hkeys user11) \"name\"2) \"age\"3) \"sex\"4) \"password\"redis 127.0.0.1:6379[1]&gt; hvals user11) \"xstao\"2) \"22\"3) \"1\"4) \"123\" 获取user1这个hash的字段数量 redis 127.0.0.1:6379[1]&gt; hlen user1(integer) 4 为hash user1添加一个字段 并查看添加后的数据结构 redis 127.0.0.1:6379[1]&gt; hmset user1 ext1 testOKredis 127.0.0.1:6379[1]&gt; hgetall user1 1) \"name\" 2) \"xstao\" 3) \"age\" 4) \"22\" 5) \"sex\" 6) \"1\" 7) \"password\" 8) \"123\" 9) \"ext1\"10) \"test\" 更新key为user1 sex的值为0 并返回赋值成功后的新值 redis 127.0.0.1:6379[1]&gt; hset user1 sex 0(integer) 0 非批量 从命令格式上来看批量都加了m 而非批量都没有 比如批量hmset 非批量 hset 定义一个哈希表user2 第一次执行成功 ，第二次执行批量添加失败了。因为hset仅支持单个添加 redis 127.0.0.1:6379[1]&gt; hset user2 name abc(integer) 1redis 127.0.0.1:6379[1]&gt; hset user3 name abc age 2(error) ERR wrong number of arguments for 'hset' commandredis 127.0.0.1:6379[1]&gt; 其他一些常用命令命令 //判断user1中name是否存在 返回1表示已存在 返回0标识没有这个name字段keyredis 127.0.0.1:6379[1]&gt; hexists user1 name(integer) 1//针对user1 中age(年龄)字段自增2 返回自增后的值redis 127.0.0.1:6379[1]&gt; hincrby user1 age 2(integer) 24//针对user1 中age(年龄)字段浮点数自增2.5 返回自增后的值redis 127.0.0.1:6379[1]&gt; hincrbyfloat user1 age 2.5\"28.5\"","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"Redis[四] @List 列表","date":"2015-06-10T16:00:00.000Z","path":"2015/06/11/ReadisStudy4-list/","text":"http://redisdoc.com/s Redis列表是简单的字符串列表，排序插入顺序。您可以在头部或列表的尾部Redis的列表添加元素。 1、使用lpush命令 添加一个list1 拥有元素 1 2 3 并返回list1的长度注意取出顺序是先进后出 2、并使用lrange命令获取list中的指定索引元素 0 -1表示从0开始 到len结束 格式：LRANGE key start stop 3、llen命令取得list1长度 redis 127.0.0.1:6379&gt; lpush list1 1 2 3(integer) 3redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"3\"2) \"2\"3) \"1\"redis 127.0.0.1:6379&gt; llen list1(integer) 3redis 127.0.0.1:6379&gt; 这种很笨的先进后出做法确实不够好，那么我想最后添加的最先出来怎么办呢？当然了 效率如此高的redis肯定是ok的。使用lpushx命令 可以添加到当前列表的最前面 输出结果可以看到我们最后添加的4被排到了最前面去了。redis 127.0.0.1:6379&gt; lpushx list1 4(integer) 4redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"3\"3) \"2\"4) \"1\" 根据指定键 指定索引获取列表中的数据 注意 索引是从0开始的。redis 127.0.0.1:6379&gt; lindex list1 0\"4\" 使用linsert key before|after oldval newval命令可以实现向指定key 指定一个元素值得前面 | 后面 插入一个值如下实现的是 向list1中元素4之前插入a 并遍历元素 然后 又向元素4之后插入b 并遍历显示元素redis 127.0.0.1:6379&gt; linsert list1 before 4 a(integer) 5redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"a\"2) \"4\"3) \"3\"4) \"2\"5) \"1\"redis 127.0.0.1:6379&gt; linsert list1 after 4 b(integer) 6redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"a\"2) \"4\"3) \"b\"4) \"3\"5) \"2\"6) \"1\" LPOP key 删除列表中的第一个元素 并返回。redis 127.0.0.1:6379&gt; lpop list1\"a\" LREM key count value从列表中删除元素 count表示删除的个数 value表示删除的需要删除的元素值如下 先添加b list1列表中就具有3个b 那么我们就执行lrem list1 2 b删除2个b。redis 127.0.0.1:6379&gt; linsert list1 after 3 b(integer) 6redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"b\"3) \"3\"4) \"b\"5) \"2\"6) \"1\"redis 127.0.0.1:6379&gt; linsert list1 after 2 b(integer) 7redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"b\"3) \"3\"4) \"b\"5) \"2\"6) \"b\"7) \"1\"redis 127.0.0.1:6379&gt; lrem list1 2 b(integer) 2redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"3\"3) \"2\"4) \"b\"5) \"1\" LSET key index value 更新指定索引的值如下是 为list1中索引为3的重新赋值为b2redis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"3\"3) \"2\"4) \"b\"5) \"1\"redis 127.0.0.1:6379&gt; lset list1 3 b2OKredis 127.0.0.1:6379&gt; lrange list1 0 -11) \"4\"2) \"3\"3) \"2\"4) \"b2\"5) \"1\" ltrim命令可以实现为裁剪指定索引区间的数据如下是裁剪list1 中1下标——2下标中的数据redis 127.0.0.1:6379&gt; ltrim list1 1 2OKredis 127.0.0.1:6379&gt; lrange list1 0 -11) \"3\"2) \"2\" rpush为列表添加元素 并实现 先进先出的原则 与lpush相反如下先添加1 2 3 4 返回的顺序也是 1 2 3 4redis 127.0.0.1:6379&gt; rpush list2 1 2 3 4(integer) 4redis 127.0.0.1:6379&gt; lrange list2 0 -11) \"1\"2) \"2\"3) \"3\"4) \"4\" RPOP key取出列表中最后一个元素如下可知 list2中最后一个元素是4redis 127.0.0.1:6379&gt; rpop list2\"4\" RPOPLPUSH source destination 删除最后一个元素的列表，将其附加到另一个列表并返回它如下list3并没有声明。而是把list2的最后一个元素保存到了list3列表中redis 127.0.0.1:6379&gt; rpoplpush list2 list3\"3\"redis 127.0.0.1:6379&gt; lrange list3 0 -11) \"3\"","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"oracle常用操作记录","date":"2015-06-03T16:00:00.000Z","path":"2015/06/04/oraclegeneraloption/","text":"有一个表名为tb，字段段名为name，数据类型nchar(20)。 假设字段数据为空，则不管改为什么字段类型，可以直接执行 alter table tb modify (name nvarchar2(20));假设字段有数据，则改为nvarchar2(20)可以直接执行 alter table tb modify (name nvarchar2(20));假设字段有数据，则改为varchar2(40)执行时会弹出“ORA-01439:要更改数据类型,则要修改的列必须为空”，这时要用下面方法来解决这个问题修改原字段名name为name_tmpalter table tb rename column name to name_tmp;增加一个和原字段名同名的字段namealter table tb add name varchar2(40);将原字段name_tmp数据更新到增加的字段nameupdate tb set name=trim(name_tmp);更新完，删除原字段name_tmpalter table tb drop column name_tmp; 总结： 1、当字段没有数据或者要修改的新类型和原类型兼容时，可以直接modify修改。2、当字段有数据并用要修改的新类型和原类型不兼容时，要间接新建字段来转移。","tags":[{"name":"oracle","slug":"oracle","permalink":"https://blog.gitee.io/tags/oracle/"}]},{"title":"Redis[二] @String","date":"2015-05-31T16:00:00.000Z","path":"2015/06/01/ReadisStudy2-string/","text":"启动数据库客户端redis-cli.exe 在Redis 数据中目前拥有以下几种数据类型 String 字符串 Hashes 哈希 List 列表 set 无序集合 sets 有序集合 String最常用过的数据类型 Redis提供一些命令来操作数据库 格式如:COMMAND KEY_NAME 设置一个key为cname ,value为123的数据 并获取cname的value redis 127.0.0.1:6379&gt; set cname 123OKredis 127.0.0.1:6379&gt; get cname\"123\"redis 127.0.0.1:6379&gt; 删除key为cname的字符串数据 执行了2次del cname命令。第一次返回1 代表删除成功，第二次返回0代表删除失败 在redis中执行命令一般情况下如果返回0则 表示执行失败。当然特殊除外 最后在获取key为cname的值 因为被删除了 所以返回nil redis 127.0.0.1:6379&gt; del cname(integer) 1redis 127.0.0.1:6379&gt; del cname(integer) 0redis 127.0.0.1:6379&gt; get cname(nil)redis 127.0.0.1:6379&gt; 其他一些常用命令 //重新定义个Key cnameredis 127.0.0.1:6379&gt; set cname 123OK//返回存储在指定键的值的序列化版本。redis 127.0.0.1:6379&gt; dump cname\"\\x00\\xc0&#123;\\x06\\x00\\xde\\x0f;a\\xf5/[*\"//检查该键是否存在 返回1表示存在 0表示不存在redis 127.0.0.1:6379&gt; exists cname(integer) 1//设置cname的过期时间为60秒redis 127.0.0.1:6379&gt; expire cname 60(integer) 1//查看cname的过期剩余时间redis 127.0.0.1:6379&gt; ttl cname(integer) 42redis 127.0.0.1:6379&gt; ttl cname(integer) 40//移除cname的过期剩余时间 那么cname将一直存在redis 127.0.0.1:6379&gt; persist cname(integer) 1//移除cname后，查看cname的过期为-1 表示一直存在了redis 127.0.0.1:6379&gt; ttl cname(integer) -1redis 127.0.0.1:6379&gt; ttl cname1(integer) -1//查看所有键 可以使用通配符redis 127.0.0.1:6379&gt; keys c*1) \"cname\"//随机返回一个键redis 127.0.0.1:6379&gt; randomkey\"cname\"redis 127.0.0.1:6379&gt; randomkey\"cname\"//对cname进行重命名为cname2redis 127.0.0.1:6379&gt; rename cname cname2OK//我们查看了cname2在列表中。说明重命名成功了redis 127.0.0.1:6379&gt; keys *1) \"money\"2) \"name\"3) \"cname2\"//重命名不存在的key会出错redis 127.0.0.1:6379&gt; rename cname55 cname2(error) ERR no such keyredis 127.0.0.1:6379&gt; renamenx cname55 cname2(error) ERR no such key//查看cname2的数据类型redis 127.0.0.1:6379&gt; type cname2stringredis 127.0.0.1:6379&gt;","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"Redis[一] @环境搭建","date":"2015-05-29T16:00:00.000Z","path":"2015/05/30/RedisStudy1/","text":"Redis是一个开源，先进的key-value存储数据库。 .........直接进入正题 注 此次Redis说明是在Window上进行的(因为公司配的电脑比较烂，安装虚拟机有点问题)。 资源地址:http://redis.io/download 下载后解压到一个目录 如我的目录是D:\\redis-2.6\\ 解压后的目录结构： bin\\ deps\\ msvs\\ src\\ btests\\ utils\\ redis.conf 进入D:\\redis-2.6\\bin\\release\\会有两个ZIP压缩包这个编译后的可执行文件 分别针对32位和64系统。解压所对应的操作系统 此处我处理的是64为操作系统 所有我解压redisbin64.zip 然后把解压后的文件 放在D:\\redis-2.6\\目录下面 打开CMD 执行进入D:\\redis-2.6\\ 执行 redis-server.exe redis.conf _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 2.6.12 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._( ' , .-` | `, ) Running in stand alone mode|`-._`-...-` __...-.``-._|'` _.-'| Port: 6379| `-._ `._ / _.-' | PID: 1996 `-._ `-._ `-./ _.-' _.-'|`-._`-._ `-.__.-' _.-'_.-'|| `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-'|`-._`-._ `-.__.-' _.-'_.-'|| `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 出现这拉风图形说明环境搭建成功了. 启动时的参数配置 我们在启动的时候用到了redis-server.exe redis.conf命令 那么编辑D:\\redis-2.6\\redis.conf可以配置一些参数http://www.cnblogs.com/linjiqin/archive/2013/05/27/3102040.html end","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gitee.io/tags/Redis/"}]},{"title":"Apache -Common-lang包常用类 方法","date":"2015-05-19T16:00:00.000Z","path":"2015/05/20/common-lang3-generaluse/","text":"ArrayUtils – 用于对数组的操作，如添加、查找、删除、子数组、倒序、元素类型转换等； BitField – 用于操作位元，提供了一些方便而安全的方法； BooleanUtils – 用于操作和转换boolean或者Boolean及相应的数组； CharEncoding – 包含了Java环境支持的字符编码，提供是否支持某种编码的判断； CharRange – 用于设定字符范围并做相应检查； CharSet – 用于设定一组字符作为范围并做相应检查； CharSetUtils – 用于操作CharSet； CharUtils – 用于操作char值和Character对象； ClassUtils – 用于对Java类的操作，不使用反射； ObjectUtils – 用于操作Java对象，提供null安全的访问和其他一些功能； RandomStringUtils – 用于生成随机的字符串； SerializationUtils – 用于处理对象序列化，提供比一般Java序列化更高级的处理能力； StringEscapeUtils – 用于正确处理转义字符，产生正确的Java、JavaScript、HTML、XML和SQL代码； StringUtils – 处理String的核心类，提供了相当多的功能； SystemUtils – 在java.lang.System基础上提供更方便的访问，如用户路径、Java版本、时区、操作系统等判断； Validate – 提供验证的操作，有点类似assert断言； WordUtils – 用于处理单词大小写、换行等。 import java.io.File; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.IOException; import java.io.InputStream; import java.io.OutputStream; import java.io.Reader; import java.net.URL; import java.util.ArrayList; import java.util.Arrays; import java.util.Calendar; import java.util.Collection; import java.util.Date; import java.util.Iterator; import java.util.List; import org.apache.commons.collections.CollectionUtils; import org.apache.commons.fileupload.util.Closeable; import org.apache.commons.io.FileUtils; import org.apache.commons.io.IOUtils; import org.apache.commons.lang3.CharSetUtils; import org.apache.commons.lang3.ClassUtils; import org.apache.commons.lang3.ObjectUtils; import org.apache.commons.lang3.RandomStringUtils; import org.apache.commons.lang3.StringEscapeUtils; import org.apache.commons.lang3.StringUtils; import org.apache.commons.lang3.math.NumberUtils; import org.apache.commons.lang3.time.DateFormatUtils; import org.apache.commons.lang3.time.DateUtils; import org.apache.commons.lang3.time.StopWatch; public class TestStr &#123; public static void Commons()&#123; //null 和 \"\"操作~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //判断是否Null 或者 \"\" System.out.println(StringUtils.isEmpty(null)); //System.out.println(StringUtils.isNotEmpty(null)); //判断是否null 或者 \"\" 去空格~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ System.out.println(StringUtils.isBlank(\" \")); System.out.println(StringUtils.isNotBlank(null)); //去空格.Null返回null~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ System.out.println(StringUtils.trim(null)); //去空格，将Null和\"\" 转换为Null System.out.println(StringUtils.trimToNull(\"\")); //去空格，将NULL 和 \"\" 转换为\"\" System.out.println(StringUtils.trimToEmpty(null)); //可能是对特殊空格符号去除？？ System.out.println(StringUtils.strip(\"大家好 啊 \\t\")); //同上，将\"\"和null转换为Null System.out.println(StringUtils.stripToNull(\" \\t\")); //同上，将\"\"和null转换为\"\" System.out.println(StringUtils.stripToEmpty(null)); //将\"\"或者Null 转换为 \"\" System.out.println(StringUtils.defaultString(null)); //仅当字符串为Null时 转换为指定的字符串(二参数) System.out.println(StringUtils.defaultString(\"\", \"df\")); //当字符串为null或者\"\"时，转换为指定的字符串(二参数) System.out.println(StringUtils.defaultIfEmpty(null, \"sos\")); //去空格.去字符~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //如果第二个参数为null去空格(否则去掉字符串2边一样的字符，到不一样为止) System.out.println(StringUtils.strip(\"fsfsdf\", \"f\")); //如果第二个参数为null只去前面空格(否则去掉字符串前面一样的字符，到不一样为止) System.out.println(StringUtils.stripStart(\"ddsuuu \", \"d\")); //如果第二个参数为null只去后面空格，(否则去掉字符串后面一样的字符，到不一样为止) System.out.println(StringUtils.stripEnd(\"dabads\", \"das\")); //对数组没个字符串进行去空格。 ArrayToList(StringUtils.stripAll(new String[]&#123;\" 中华 \", \"民 国 \", \"共和 \"&#125;)); //如果第二个参数为null.对数组每个字符串进行去空格。(否则去掉数组每个元素开始和结尾一样的字符) ArrayToList(StringUtils.stripAll(new String[]&#123;\" 中华 \", \"民 国\", \"国共和国\"&#125;, \"国\")); //查找,判断~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //判断2个字符串是否相等相等,Null也相等 System.out.println(StringUtils.equals(null, null)); //不区分大小写比较 System.out.println(StringUtils.equalsIgnoreCase(\"abc\", \"ABc\")); //查找，不知道怎么弄这么多查找，很多不知道区别在哪？费劲~~~~~~~~~~~~~~~~~~~ //普通查找字符，如果一参数为null或者\"\"返回-1 System.out.println(StringUtils.indexOf(null, \"a\")); //从指定位置(三参数)开始查找，本例从第2个字符开始查找k字符 System.out.println(StringUtils.indexOf(\"akfekcd中华\", \"k\", 2)); //未发现不同之处 System.out.println(StringUtils.ordinalIndexOf(\"akfekcd中华\", \"k\", 2)); //查找,不区分大小写 System.out.println(StringUtils.indexOfIgnoreCase(\"adfs\", \"D\")); //从指定位置(三参数)开始查找,不区分大小写 System.out.println(StringUtils.indexOfIgnoreCase(\"adfs\", \"a\", 3)); //从后往前查找 System.out.println(StringUtils.lastIndexOf(\"adfas\", \"a\")); //未理解,此结果为2 System.out.println(StringUtils.lastIndexOf(\"d饿abasdafs我\", \"a\", 3)); //未解,此结果为-1 System.out.println(StringUtils.lastOrdinalIndexOf(\"yksdfdht\", \"f\", 2)); //从后往前查，不区分大小写 System.out.println(StringUtils.lastIndexOfIgnoreCase(\"sdffet\", \"E\")); //未解,此结果为1 System.out.println(StringUtils.lastIndexOfIgnoreCase(\"efefrfs看\", \"F\" , 2)); //检查是否查到，返回boolean,null返回假 System.out.println(StringUtils.contains(\"sdf\", \"dg\")); //检查是否查到，返回boolean,null返回假,不区分大小写 System.out.println(StringUtils.containsIgnoreCase(\"sdf\", \"D\")); //检查是否有含有空格,返回boolean System.out.println(StringUtils.containsWhitespace(\" d\")); //查询字符串跟数组任一元素相同的第一次相同的位置 System.out.println(StringUtils.indexOfAny(\"absfekf\", new String[]&#123;\"f\", \"b\"&#125;)); //查询字符串中指定字符串(参数二)出现的次数 System.out.println(StringUtils.indexOfAny(\"afefes\", \"e\")); //查找字符串中是否有字符数组中相同的字符，返回boolean System.out.println(StringUtils.containsAny(\"asfsd\", new char[]&#123;'k', 'e', 's'&#125;)); //未理解与lastIndexOf不同之处。是否查到，返回boolean System.out.println(StringUtils.containsAny(\"啡f咖啡\", \"咖\")); //未解 System.out.println(StringUtils.indexOfAnyBut(\"seefaff\", \"af\")); //判断字符串中所有字符，都是出自参数二中。 System.out.println(StringUtils.containsOnly(\"中华华\", \"华\")); //判断字符串中所有字符，都是出自参数二的数组中。 System.out.println(StringUtils.containsOnly(\"中华中\", new char[]&#123;'中', '华'&#125;)); //判断字符串中所有字符，都不在参数二中。 System.out.println(StringUtils.containsNone(\"中华华\", \"国\")); //判断字符串中所有字符，都不在参数二的数组中。 System.out.println(StringUtils.containsNone(\"中华中\", new char[]&#123;'中', '达'&#125;)); //从后往前查找字符串中与字符数组中相同的元素第一次出现的位置。本例为4 System.out.println(StringUtils.lastIndexOfAny(\"中国人民共和国\", new String[]&#123;\"国人\", \"共和\"&#125;)); //未发现与indexOfAny不同之处 查询字符串中指定字符串(参数二)出现的次数 System.out.println(StringUtils.countMatches(\"中国人民共和中国\", \"中国\")); //检查是否CharSequence的只包含Unicode的字母。空将返回false。 //一个空的CharSequence（长（）= 0）将返回true System.out.println(StringUtils.isAlpha(\"这是干什么的2\")); //检查是否只包含Unicode的CharSequence的字母和空格（''）。 //空将返回一个空的CharSequence假（长（）= 0）将返回true。 System.out.println(StringUtils.isAlphaSpace(\"NBA直播 \")); //检查是否只包含Unicode的CharSequence的字母或数字。空将返回false。 //一个空的CharSequence（长（）= 0）将返回true。 System.out.println(StringUtils.isAlphanumeric(\"NBA直播\")); //如果检查的Unicode CharSequence的只包含字母，数字或空格（''）。 //空将返回false。一个空的CharSequence（长（）= 0）将返回true。 System.out.println(StringUtils.isAlphanumericSpace(\"NBA直播\")); //检查是否只包含ASCII可CharSequence的字符。空将返回false。 //一个空的CharSequence（长（）= 0）将返回true。 System.out.println(StringUtils.isAsciiPrintable(\"NBA直播\")); //检查是否只包含数值。 System.out.println(StringUtils.isNumeric(\"NBA直播\")); //检查是否只包含数值或者空格 System.out.println(StringUtils.isNumericSpace(\"33 545\")); //检查是否只是空格或\"\"。 System.out.println(StringUtils.isWhitespace(\" \")); //检查是否全是英文小写。 System.out.println(StringUtils.isAllLowerCase(\"kjk33\")); //检查是否全是英文大写。 System.out.println(StringUtils.isAllUpperCase(\"KJKJ\")); //交集操作~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //去掉参数2字符串中在参数一中开头部分共有的部分，结果为:人民共和加油 System.out.println(StringUtils.difference(\"中国加油\", \"中国人民共和加油\")); //统计2个字符串开始部分共有的字符个数 System.out.println(StringUtils.indexOfDifference(\"ww.taobao\", \"www.taobao.com\")); //统计数组中各个元素的字符串开始都一样的字符个数 System.out.println(StringUtils.indexOfDifference(new String[] &#123;\"中国加油\", \"中国共和\", \"中国人民\"&#125;)); //取数组每个元素共同的部分字符串 System.out.println(StringUtils.getCommonPrefix(new String[] &#123;\"中国加油\", \"中国共和\", \"中国人民\"&#125;)); //统计参数一中每个字符与参数二中每个字符不同部分的字符个数 System.out.println(StringUtils.getLevenshteinDistance(\"中国共和发国人民\", \"共和国\")); //判断开始部分是否与二参数相同 System.out.println(StringUtils.startsWith(\"中国共和国人民\", \"中国\")); //判断开始部分是否与二参数相同。不区分大小写 System.out.println(StringUtils.startsWithIgnoreCase(\"中国共和国人民\", \"中国\")); //判断字符串开始部分是否与数组中的某一元素相同 System.out.println(StringUtils.startsWithAny(\"abef\", new String[]&#123;\"ge\", \"af\", \"ab\"&#125;)); //判断结尾是否相同 System.out.println(StringUtils.endsWith(\"abcdef\", \"def\")); //判断结尾是否相同，不区分大小写 System.out.println(StringUtils.endsWithIgnoreCase(\"abcdef\", \"Def\")); //字符串截取~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //截取指定位置的字符，null返回null.\"\"返回\"\" System.out.println(StringUtils.substring(\"中国人民\", 2)); //截取指定区间的字符 System.out.println(StringUtils.substring(\"中国人民共和国\", 2, 4)); //从左截取指定长度的字符串 System.out.println(StringUtils.left(\"说点什么好呢\", 3)); //从右截取指定长度的字符串 System.out.println(StringUtils.right(\"说点什么好呢\", 3)); //从第几个开始截取，三参数表示截取的长度 System.out.println(StringUtils.mid(\"说点什么好呢\", 3, 2)); //截取到等于第二个参数的字符串为止 System.out.println(StringUtils.substringBefore(\"说点什么好呢\", \"好\")); //从左往右查到相等的字符开始，保留后边的，不包含等于的字符。本例：什么好呢 System.out.println(StringUtils.substringAfter(\"说点什么好呢\", \"点\")); //这个也是截取到相等的字符，但是是从右往左.本例结果：说点什么好 System.out.println(StringUtils.substringBeforeLast(\"说点什么好点呢\", \"点\")); //这个截取同上是从右往左。但是保留右边的字符 System.out.println(StringUtils.substringAfterLast(\"说点什么好点呢？\", \"点\")); //截取查找到第一次的位置，和第二次的位置中间的字符。如果没找到第二个返回null。本例结果:2010世界杯在 System.out.println(StringUtils.substringBetween(\"南非2010世界杯在南非，在南非\", \"南非\")); //返回参数二和参数三中间的字符串，返回数组形式 ArrayToList(StringUtils.substringsBetween(\"[a][b][c]\", \"[\", \"]\")); //分割~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //用空格分割成数组，null为null ArrayToList(StringUtils.split(\"中华 人民 共和\")); //以指定字符分割成数组 ArrayToList(StringUtils.split(\"中华 ,人民,共和\", \",\")); //以指定字符分割成数组，第三个参数表示分隔成数组的长度，如果为0全体分割 ArrayToList(StringUtils.split(\"中华 ：人民：共和\", \"：\", 2)); //未发现不同的地方,指定字符分割成数组 ArrayToList(StringUtils.splitByWholeSeparator(\"ab-!-cd-!-ef\", \"-!-\")); //未发现不同的地方,以指定字符分割成数组，第三个参数表示分隔成数组的长度 ArrayToList(StringUtils.splitByWholeSeparator(\"ab-!-cd-!-ef\", \"-!-\", 2)); //分割，但\" \"不会被忽略算一个元素,二参数为null默认为空格分隔 ArrayToList(StringUtils.splitByWholeSeparatorPreserveAllTokens(\" ab de fg \", null)); //同上，分割,\" \"不会被忽略算一个元素。第三个参数代表分割的数组长度。 ArrayToList(StringUtils.splitByWholeSeparatorPreserveAllTokens(\"ab de fg\", null, 3)); //未发现不同地方,分割 ArrayToList(StringUtils.splitPreserveAllTokens(\" ab de fg \")); //未发现不同地方,指定字符分割成数组 ArrayToList(StringUtils.splitPreserveAllTokens(\" ab de fg \", null)); //未发现不同地方,以指定字符分割成数组，第三个参数表示分隔成数组的长度 ArrayToList(StringUtils.splitPreserveAllTokens(\" ab de fg \", null, 2)); //以不同类型进行分隔 ArrayToList(StringUtils.splitByCharacterType(\"AEkjKr i39:。中文\")); //未解 ArrayToList(StringUtils.splitByCharacterTypeCamelCase(\"ASFSRules234\")); //拼接~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //也是拼接。未发现区别 System.out.println(StringUtils.join(getArrayData())); //用连接符拼接，为发现区别 System.out.println(StringUtils.join(getArrayData(), \":\")); //拼接指定数组下标的开始(三参数)和结束(四参数,不包含)的中间这些元素，用连接符连接 System.out.println(StringUtils.join(getArrayData(), \":\", 1, 3)); //用于集合连接字符串.用于集合 System.out.println(StringUtils.join(getListData(), \":\")); //移除，删除~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //删除所有空格符 System.out.println(StringUtils.deleteWhitespace(\" s 中 你 4j\")); //移除开始部分的相同的字符 System.out.println(StringUtils.removeStart(\"www.baidu.com\", \"www.\")); //移除开始部分的相同的字符,不区分大小写 System.out.println(StringUtils.removeStartIgnoreCase(\"www.baidu.com\", \"WWW\")); //移除后面相同的部分 System.out.println(StringUtils.removeEnd(\"www.baidu.com\", \".com\")); //移除后面相同的部分，不区分大小写 System.out.println(StringUtils.removeEndIgnoreCase(\"www.baidu.com\", \".COM\")); //移除所有相同的部分 System.out.println(StringUtils.remove(\"www.baidu.com/baidu\", \"bai\")); //移除结尾字符为\"\\n\", \"\\r\", 或者 \"\\r\\n\". System.out.println(StringUtils.chomp(\"abcrabc\\r\")); //也是移除，未解。去结尾相同字符 System.out.println(StringUtils.chomp(\"baidu.com\", \"com\")); //去掉末尾最后一个字符.如果是\"\\n\", \"\\r\", 或者 \"\\r\\n\"也去除 System.out.println(StringUtils.chop(\"wwe.baidu\")); //替换~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //替换指定的字符，只替换第一次出现的 System.out.println(StringUtils.replaceOnce(\"www.baidu.com/baidu\", \"baidu\", \"hao123\")); //替换所有出现过的字符 System.out.println(StringUtils.replace(\"www.baidu.com/baidu\", \"baidu\", \"hao123\")); //也是替换，最后一个参数表示替换几个 System.out.println(StringUtils.replace(\"www.baidu.com/baidu\", \"baidu\", \"hao123\", 1)); //这个有意识，二三参数对应的数组，查找二参数数组一样的值，替换三参数对应数组的值。 //本例:baidu替换为taobao。com替换为net System.out.println(StringUtils.replaceEach(\"www.baidu.com/baidu\", new String[]&#123;\"baidu\", \"com\"&#125;, new String[]&#123;\"taobao\", \"net\"&#125;)); //同上，未发现不同 System.out.println(StringUtils.replaceEachRepeatedly(\"www.baidu.com/baidu\", new String[]&#123;\"baidu\", \"com\"&#125;, new String[]&#123;\"taobao\", \"net\"&#125;)); //这个更好，不是数组对应，是字符串参数二和参数三对应替换.(二三参数不对应的话，自己看后果) System.out.println(StringUtils.replaceChars(\"www.baidu.com\", \"bdm\", \"qo\")); //替换指定开始(参数三)和结束(参数四)中间的所有字符 System.out.println(StringUtils.overlay(\"www.baidu.com\", \"hao123\", 4, 9)); //添加，增加~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //复制参数一的字符串，参数二为复制的次数 System.out.println(StringUtils.repeat(\"ba\", 3)); //复制参数一的字符串，参数三为复制的次数。参数二为复制字符串中间的连接字符串 System.out.println(StringUtils.repeat(\"ab\", \"ou\", 3)); //如何字符串长度小于参数二的值，末尾加空格补全。(小于字符串长度不处理返回) System.out.println(StringUtils.rightPad(\"海川\", 4)); //字符串长度小于二参数，末尾用参数三补上，多于的截取(截取补上的字符串) System.out.println(StringUtils.rightPad(\"海川\", 4, \"河流啊\")); //同上在前面补全空格 System.out.println(StringUtils.leftPad(\"海川\", 4)); //字符串长度小于二参数，前面用参数三补上，多于的截取(截取补上的字符串) System.out.println(StringUtils.leftPad(\"海川\", 4, \"大家好\")); //字符串长度小于二参数。在两侧用空格平均补全（测试后面补空格优先） System.out.println(StringUtils.center(\"海川\", 3)); //字符串长度小于二参数。在两侧用三参数的字符串平均补全（测试后面补空格优先） System.out.println(StringUtils.center(\"海川\", 5, \"流\")); //只显示指定数量(二参数)的字符,后面以三个点补充(参数一截取+三个点=二参数) System.out.println(StringUtils.abbreviate(\"中华人民共和国\", 5)); //2头加点这个有点乱。本例结果: ...ijklmno System.out.println(StringUtils.abbreviate(\"abcdefghijklmno\", 12, 10)); //保留指定长度，最后一个字符前加点.本例结果: ab.f System.out.println(StringUtils.abbreviateMiddle(\"abcdef\", \".\", 4)); //转换,刷选~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ //转换第一个字符为大写.如何第一个字符是大写原始返回 System.out.println(StringUtils.capitalize(\"Ddf\")); //转换第一个字符为大写.如何第一个字符是大写原始返回 System.out.println(StringUtils.uncapitalize(\"DTf\")); //反向转换，大写变小写，小写变大写 System.out.println(StringUtils.swapCase(\"I am JianNanCun, Hello\")); //将字符串倒序排列 System.out.println(StringUtils.reverse(\"中国人民\")); //根据特定字符(二参数)分隔进行反转 System.out.println(StringUtils.reverseDelimited(\"中:国:人民\", ':')); //计算字符串中包含某字符数. System.out.println(CharSetUtils.count( \"The quick brown fox jumps over the lazy dog.\", \"aeiou\")); //删除字符串中某字符 System.out.println(CharSetUtils.delete( \"The quick brown fox jumps over the lazy dog.\", \"aeiou\")); //保留字符串中某字符 System.out.println(CharSetUtils.keep( \"The quick brown fox jumps over the lazy dog.\", \"aeiou\")); //合并重复的字符. System.out.println(CharSetUtils.squeeze(\"a bbbbbb c dd\", \"b d\")); //Object为null时，默认打印某字符. Object obj = null; System.out.println(ObjectUtils.defaultIfNull(obj, \"空\")); //验证两个引用是否指向的Object是否相等,取决于Object的equals()方法. Object a = new Object(); Object b = a; Object c = new Object(); System.out.println(ObjectUtils.equals(a, b)); System.out.println(ObjectUtils.equals(a, c)); //用父类Object的toString()方法返回对象信息. Date date = new Date(); System.out.println(ObjectUtils.identityToString(date)); System.out.println(date); //返回类本身的toString()方法结果,对象为null时，返回0长度字符串. System.out.println(ObjectUtils.toString(date)); System.out.println(ObjectUtils.toString(null)); System.out.println(date); //生成指定长度的随机字符串,好像没什么用. System.out.println(RandomStringUtils.random(500)); //在指定字符串中生成长度为n的随机字符串. System.out.println(RandomStringUtils.random(5, \"abcdefghijk\")); //指定从字符或数字中生成随机字符串. System.out.println(RandomStringUtils.random(5, true, false)); System.out.println(RandomStringUtils.random(5, false, true)); //获取类实现的所有接口. System.out.println(ClassUtils.getAllInterfaces(Date.class)); //获取类所有父类. System.out.println(ClassUtils.getAllSuperclasses(Date.class)); //获取简单类名. System.out.println(ClassUtils.getShortClassName(Date.class)); //获取包名. System.out.println(ClassUtils.getPackageName(Date.class)); //判断是否可以转型. System.out.println(ClassUtils.isAssignable(Date.class, Object.class)); System.out.println(ClassUtils.isAssignable(Object.class, Date.class)); //转换特殊字符. System.out.println(\"html:\" + StringEscapeUtils.escapeHtml4(\" &lt;html&gt;\")); System.out.println(\"html:\"+ StringEscapeUtils.unescapeEcmaScript(\" \")); //从数组中选出最大值. System.out.println(NumberUtils.max(new int[] &#123; 1, 2, 3, 4 &#125;)); //判断字符串是否全是整数. System.out.println(NumberUtils.isDigits(\"123.1\")); //判断字符串是否是有效数字. System.out.println(NumberUtils.isNumber(\"0123.1\")); //格式化日期输出. System.out.println(DateFormatUtils.format(new Date(), \"yyyy-MM-dd\")); System.out.println(DateFormatUtils.format(System.currentTimeMillis(), \"yyyy-MM-dd HH:mm:ss\")); //秒表. StopWatch sw = new StopWatch(); sw.start(); for (Iterator iterator = DateUtils.iterator(new Date(), DateUtils.RANGE_WEEK_CENTER); iterator.hasNext();) &#123; Calendar cal = (Calendar) iterator.next(); System.out.println(DateFormatUtils.format(cal.getTime(), \"yy-MM-dd HH:mm\")); &#125; sw.stop(); System.out.println(\"秒表计时:\" + sw.getTime()); &#125; //将数组转换为List private static void ArrayToList(String[] str)&#123; System.out.println(Arrays.asList(str) + \" 长度:\" + str.length); &#125; //获得集合数据 private static List getListData()&#123; List list = new ArrayList(); list.add(\"1\"); list.add(null); list.add(\"2\"); list.add(\"3\"); return list; &#125; //获得数组数据 private static String[] getArrayData()&#123; return (String[]) getListData().toArray(new String[0]); &#125; // 集合并集 public static Collection&lt;?&gt; union(Collection&lt;?&gt; a, Collection&lt;?&gt; b) &#123; return CollectionUtils.union(a, b); &#125; // 集合交集 public static Collection&lt;?&gt; intersection(Collection&lt;?&gt; a, Collection&lt;?&gt; b) &#123; return CollectionUtils.intersection(a, b); &#125; // 交集的补集 public static Collection&lt;?&gt; disjunction(Collection&lt;?&gt; a, Collection&lt;?&gt; b) &#123; return CollectionUtils.disjunction(a, b); &#125; // 集合相减 public static Collection&lt;?&gt; subtract(Collection&lt;?&gt; a, Collection&lt;?&gt; b) &#123; return CollectionUtils.subtract(a, b); &#125; //读取文件，将其转换成字节数组 public static byte[] readFileToByteArray(File file) throws IOException &#123; return FileUtils.readFileToByteArray(file); &#125; //读取文件，将其转换成字符串 public static String readFileToString(File file) throws IOException &#123; return FileUtils.readFileToString(file); &#125; //该方法是用data内容替换了file文件中原来的内容 public static void writeStringToFile(File file, String data) throws IOException &#123; FileUtils.writeStringToFile(file, data); &#125; //将文件srcFile拷贝到desFile中 public static void copyFile(File srcFile, File desFile) throws IOException &#123; FileUtils.copyFile(srcFile, desFile); &#125; //将文件拷贝到目录下 public static void copyFileToDirectory(File srcDir, File destDir) throws IOException &#123; FileUtils.copyDirectory(srcDir, destDir); &#125; //拷贝URL类型 public static void copyURLToFile(URL source, File destination) throws IOException &#123; FileUtils.copyURLToFile(source, destination); &#125; //删除该目录下的所有文件 public static void delDirectory(File directory) throws IOException &#123; FileUtils.deleteDirectory(directory); &#125; //清除该目录下的所有文件，但目录不删除 public static void cleanDirectory(File directory) throws IOException &#123; FileUtils.cleanDirectory(directory); &#125; // 读取流信息 public static List&lt;String&gt; readLines(InputStream input) throws IOException &#123; return IOUtils.readLines(input); &#125; // 读取流信息 public static List&lt;String&gt; readLines(Reader reader) throws IOException &#123; return IOUtils.readLines(reader); &#125; // 批量写入文件中，并覆盖原有的文本 public static void writeLines(List&lt;String&gt; lines, File file) throws FileNotFoundException, IOException &#123; IOUtils.writeLines(lines, null, new FileOutputStream(file)); &#125; //批量写入文件中，并在后面追加 public static void writeOneLine(List&lt;String&gt; lines, File file) throws IOException &#123; OutputStream outputStream = new FileOutputStream(file, true); IOUtils.writeLines(lines, null, outputStream, \"UTF-8\"); &#125; //将流对象转换成字符串 public static String toString(InputStream input) throws IOException &#123; return IOUtils.toString(input); &#125; public static void main(String[] args) &#123; Commons(); &#125;&#125; 内容非原创、感谢圈子搜集http://www.liutime.com/javainfo/1044/","tags":[{"name":"common-lang","slug":"common-lang","permalink":"https://blog.gitee.io/tags/common-lang/"}]},{"title":"eval的一些特殊用法","date":"2015-05-17T16:00:00.000Z","path":"2015/05/18/evalMoreUse/","text":"w3c 对eval说明和定义： 该方法只接受原始字符串作为参数，如果 string 参数不是原始字符串，那么该方法将不作任何改变地返回。因此请不要为 eval() 函数传递 String 对象来作为参数。如果试图覆盖 eval 属性或把 eval() 方法赋予另一个属性，并通过该属性调用它，则 ECMAScript 实现允许抛出一个 EvalError 异常。 eval有两种使用方式 一种是直接调用，另一个是间接调用 直接调用eval(\"1+1\");//（调用括号）之前的哪部分不只是由“eval”标识符组成 间接调用(1 ,eval)('1+1')//这是一个完整的其他类型的表达式，由逗号操作符，数字常量，然后才是\"eval\"标识符组成 下面列出一些间接调用的例子 (1, eval)('...')(eval, eval)('...')(1 ? eval : 0)('...')(__ = eval)('...')var e = eval; e('...')(function(e) &#123; e('...') &#125;)(eval)(function(e) &#123; return e &#125;)(eval)('...')(function() &#123; arguments[0]('...') &#125;)(eval)this.eval('...')this['eval']('...')[eval][0]('...')eval.call(this, '...')eval('eval')('...') 原文至http://www.oschina.net/translate/global-eval-what-are-the-options","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"浅谈情绪","date":"2015-05-01T16:00:00.000Z","path":"2015/05/02/seeMood/","text":"看到一个网友提问 怎样进行良好的情绪管理？ 一个正常的人在不同的场合、面对不同的人、事物都会有不同情绪。比如面对亲人、上司、客户…等等。 那么怎么控制好自己的情绪呢？简单的从下面几个层面来say 找到情绪的源点(来源于什么事物) 对这种心理尽量Stop 倾听和关注(因为在人际关系中听永远比说要重要) 试着小心翼翼的表达(避免带来彼此的困扰或伤害) 以人为本。尊重他人就是尊重自己 不能控制的情况下坚决不能谈事 甚至说把太多的事情看淡一点就好，因为情绪的表现形式有很多种方式如 交谈、表情、动作 等等 这都是可以促使能否成功的重要因素。","tags":[{"name":"情绪","slug":"情绪","permalink":"https://blog.gitee.io/tags/情绪/"}]},{"title":"github pages + jekyll +markdown 搭建博客教程","date":"2015-04-13T16:00:00.000Z","path":"2015/04/14/githubpageinstalldoc/","text":"现在很多文章都是使用免费而且无流量限制的github pages托管，下面将一步一步的描述整个过程。 这种博客系统是基于Jekyll，所以就得安装Ruby了。 1、安装Ruby 相关。 Ruby可以从它的https://www.ruby-lang.org/en/downloads/ 下载到，国内有时候网络不稳定很难下载成功，可以在http://wd.jb51.net:81/201403/tools/ruby_win64.rar 下载到安装包，然后安装到操作 系统。 安装Devkit工具包，首先进入到devkit的安装目录 ruby dk.rb init//会在该目录生成一个`config.yml`ruby dk.rb install//安装工具命令行gem instal jekyll //安装 jekyll //测试jeykyy 是否安装成功。返回版本号则说明我们安装成功了。jekyll -v 设置ruby的path 把ruby的安装目录下的bin文件夹加入系统变量path中，如下图： 2、安装python 使用python的 easy_install 安装python略过 //安装代码高亮插件 ========================================","tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://blog.gitee.io/tags/GitHub/"},{"name":"jekyll","slug":"jekyll","permalink":"https://blog.gitee.io/tags/jekyll/"},{"name":"markdown","slug":"markdown","permalink":"https://blog.gitee.io/tags/markdown/"}]},{"title":"my97日历控件多选日期实现","date":"2015-04-08T16:00:00.000Z","path":"2015/04/09/my97Extend1/","text":"….待续","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"},{"name":"my97","slug":"my97","permalink":"https://blog.gitee.io/tags/my97/"}]},{"title":"js中方法头声明的几种写法","date":"2015-03-25T16:00:00.000Z","path":"2015/03/26/jsDefine- framework/","text":"在阅读一些开源框架中，经常会看到如下的代码 //第一种(function()&#123; ........ ........ ........&#125;)(); //第二种!(function () &#123; ........ ....... .......&#125;)(); 第一种的写法比较好理解。就相当于 var c=function(){};c(); 第二种写法有点想不通。 前面加了一个!是什么意思呢?(Boolean吗?) 首先定义了一个方法 function(){alert(1);}(); //编译器会直接报错。 !function(){alert(2);}();//运行正常 +function(){alert(2);}();//运行正常 -function(){alert(2);}();//运行正常 原来，使用括号包裹定义函数体，解析器将会以函数表达式的方式去调用定义函数。也就是说，任何能将函数变成一个函数表达式的作法，都可以使解析器正确的调用定义函数。而 ! 就是其中一个，而 + - || 都有这样的功能。 所以看到!(function(){})();完全不足为奇。 个人感觉使用!function(){}();这种方式就可以少写一个() 但是给看起来不那么得体。可能会给读者带来一些困惑。所以建议使用(function(){})();这种方式。","tags":[{"name":"方法定义","slug":"方法定义","permalink":"https://blog.gitee.io/tags/方法定义/"}]},{"title":"js中parseInt()函数浏览器兼容的问题","date":"2015-03-25T16:00:00.000Z","path":"2015/03/26/parseInt-Browser-Compatible/","text":"一般我们在获取到日期的时候格式为yyyy-mm-dd 然后要得到日，会使用var arr=split(&#39;-&#39;)函数进行分割 取到天数就是arr[2] 当天数arr[2]为08的时候 parseInt(&#39;08&#39;)在IE浏览器中却返回0 在Chrome、firefox中都能正常的得到8。真是奇怪啦，当时郁闷了很久。这是一个很大的坑，所以以后再处理这种问题的时候一定要小心咯。 经过查资料 发现parseInt(string, radix)具备2个参数。W3C解释如下： string 必需。要被解析的字符串。 radix可选。表示要解析的数字的基数。该值介于 2 ~ 36 之间。如果省略该参数或其值为 0，则数字将以 10 为基础来解析。如果它以 “0x” 或 “0X” 开头，将以 16 为基数。如果该参数小于 2 或者大于 36，则 parseInt() 将返回 NaN。 把第2个参数设置为10表示待转换的为10进制数。 所以这个问题解决了。 var c=parseInt('08',10);console.info(c);//8;//做到了，兼容现代浏览器，和以前的IE8-","tags":[{"name":"兼容性","slug":"兼容性","permalink":"https://blog.gitee.io/tags/兼容性/"}]},{"title":"js中 `in` 运算符","date":"2015-03-23T16:00:00.000Z","path":"2015/03/24/js-in-Operation/","text":"之前在javascript中很少使用in运算符。在开源类库中经常看到这样子的语句。简单的接收一下怎么使用 in运算符要求第1个（左边的）操作数必须是字符串类型或可以转换为字符串类型的其他类型 第2个（右边的）操作数必须是数组或对象 第1个操作数的值是第2个操作数的属性名，才会返回true，否则返回false。 //声明 了一个user对象var user=&#123; name:'user1', age:20, sex:1&#125;;//判断name是不是user对象的属性var b='name' in user;console.info(b);//true;b='summary' in user;console.info(b);//false; 当是数组的时候，当下标存在时候也是返回true的。如下面的0,1,2,length 都返回true //声明 了一个array对象var user=['user1',200,1000,'peach'];//判断200是不是user对象的属性var b=200 in user;console.info(b);//false;b=1 in user;console.info(b);//true;因为1是user的下标。b='length' in user;console.info(b);//true;","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"},{"name":"in运算符","slug":"in运算符","permalink":"https://blog.gitee.io/tags/in运算符/"},{"name":"运算符","slug":"运算符","permalink":"https://blog.gitee.io/tags/运算符/"}]},{"title":"社会对残疾人的眼光和关爱","date":"2015-03-22T16:00:00.000Z","path":"2015/03/23/disabled-way-care/","text":"在当今社会上，有一部分人民不是很健全的，也就是说他们在日常的生活和工作中都有不便利或无法自足的人，我们通常都叫他们为残疾人。 昨晚独自看了一个节目叫做你会怎么做，简单的记录一下这一期节目的内容。 在一个面包店中一个听力和口齿都有点障碍的面包师和一些客户的交流。 以下的厨师是指 听力和口齿有障碍的面包师 顾客A : 这是什么啊，服务员叫你们厨师给我出来，做的这是什么啊。 厨师(口齿不清的回答到) : 顾..客..您..好，是我…我的问题，对…对不起， 我…我帮你换…换一份吧。 顾客A ：发现了厨师竟然说不清楚话，就大声的开骂了。 顾客A ：骂了很多的脏话…………………. 顾客other:有其他的顾客看不惯了，就劝说算了吧 等等之类的话 顾客A ：很不耐烦的问了其他的顾客几个问题 顾客A ：残疾人做的东西能吃吗? 顾客A ：你愿意被残疾人服务吗? …………………………… ……………… 这个顾客问了这2个问题很重要，可能是当今社会中 很多人共有的看法，不妨换个角色想一想，我是那个残疾人，因为上天的不公平对待，我依然坚强的活下来了，而且我是靠自己的努力没有去偷、抢…等不文明的行为，虽然这样，我还得不到旁人的认可。可想而知 他们比我们任何一个健全的人都要坚强。他们是靠信念而活着，我们应该从自己做起，关爱他们。让他们感受到除了自己坚强的信念还有社会的爱。那么这一类残疾人岂不是还能给世界创造价值，创造光明，创造希望。 马上就是助残日了，想想我们又能为他们做些什么呢?","tags":[{"name":"职业","slug":"职业","permalink":"https://blog.gitee.io/tags/职业/"},{"name":"残疾人","slug":"残疾人","permalink":"https://blog.gitee.io/tags/残疾人/"},{"name":"关爱","slug":"关爱","permalink":"https://blog.gitee.io/tags/关爱/"},{"name":"眼光","slug":"眼光","permalink":"https://blog.gitee.io/tags/眼光/"}]},{"title":"java中clone()克隆的简单使用示例","date":"2015-03-19T16:00:00.000Z","path":"2015/03/20/java.clone-explain/","text":"在日常的工作中难免会遇到到对象克隆的需求，那么接下来简单的记录一下在JAVA中对象克隆的实现。 需要注意的是 在一个java对象中 如果包含了另一个java对象，那么就需要深度克隆。含义大概就是只要是引用数据类型的对象，那么都需要做深度克隆 一 、首先定义一个java对象 User 并实现 java.lang.Cloneable 接口，这个接口虽然没有实现任何方法 但是必须实现它，否则会抛出java.lang.CloneNotSupportedException异常 public class User implements Cloneable&#123; @Override public Object clone() &#123; try &#123; return super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return null; &#125; private String username; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; &#125; 二 、 定义一个测试类UserTest public class UserTest &#123; public static void main(String[] args) &#123; User user=new User(); user.setUsername(\"at peach\"); User u=(User) user.clone(); System.out.println(user==u);//false System.out.println(u.getUsername());//at peach &#125;&#125; 三 、运行UserTest类 结果如下 falseat peach 这样的克隆我们叫他为浅克隆，那么还有上面所说的深度克隆。实现原理是一样的。 前面使用一些对象的克隆比较麻烦。那么apache提供了一个方便的类org.apache.commons.beanutils 使用方法是:User user=new User();user.setUsername(\"at peach\");User u=(User)BeanUtils.cloneBean(user); 发现结果也是一样的。SO EASY","tags":[{"name":"java","slug":"java","permalink":"https://blog.gitee.io/tags/java/"},{"name":"克隆","slug":"克隆","permalink":"https://blog.gitee.io/tags/克隆/"}]},{"title":"javascript中array.splice用法介绍","date":"2015-03-18T16:00:00.000Z","path":"2015/03/19/array.splic-test/","text":"以前经常写javascript代码。很久没写了，突然一下忘记了一些常用的原型函数，在我的印象中Array这个类是经常用到的。最熟悉的方法莫过于push()了，下面将演示一下splice()方法的含义和使用示例。 从W3C文档中描述出来的含义是： 描述： splice()函数用于从当前数组中移除一部分连续的元素。如有必要，还可以在所移除元素的位置上插入一个或多个新的元素。该函数以数组形式返回从当前数组中被移除的元素。 语法： array.splice( start, deleteCount [,items... ] ) 参数： start Number类型数组中移除元素操作的起点索引，从0开始。 deleteCount Number类型需要移除的元素个数。 items 可选参数/任意类型要添加到数组中元素被移除位置的新元素，可以有多个。 返回值： splice()函数的返回值为Array类型，返回从当前数组中被移除的元素所组成的新的数组。当移除数组中的元素时，数组的length属性也会随之改变。一般而言，数组的length属性将会减N(N为实际移除的元素个数) 示例： //1、首先定义一个数组var array = [\"it1\", 'it2', \"it3\", 2, \"it5\", 'peach', false];//2、移除数组中第2，3个元素 var reArr=array.splice(1,2);//返回['it2','it3']//3、前面一步被删除2个元素了。那么我们再刚才的位置上新插入3个元素reArr =array.splice(1,0,'newit2','newit3');//返回[]因为第2个参数为0 表示删除0个元素。差不多就是插入的意思吧//打印一下array现在的元素到底变为什么样子了。console.info(array);//输出[\"it1\", 'newit2', \"newit3\", 2, \"it5\", 'peach', false];//此时array的2-3个元素已经又变为newit2,newit3 //4、删除数组中2，3个元素，并插入newit2-1,newit3-1reArr =array.splice(1,2,'newit2-1','newit3-1');console.info(array); //输出[\"it1\", 'newit2', \"newit3-1\", 2, \"it5\", 'peach', false]; 需要注意的是： splice()函数一直从索引start开始，移除deleteCount个元素，直到数组的结尾。 如果start为负，则将其视为length + start，此处length为数组的长度。 如果deleteCount为0或负数，则不会移除任何元素，并返回一个空数组。 如果start &gt;= length，则不会移除任何元素，返回一个空数组。 如果参数items为数组类型(Array)，仍会被当作一个元素看待，插入到当前数组中。 经常使用的时候差不多就是这样子了。","tags":[{"name":"javascript","slug":"javascript","permalink":"https://blog.gitee.io/tags/javascript/"}]},{"title":"first 离职有感","date":"2015-03-16T16:00:00.000Z","path":"2015/03/17/quit-job-idea/","text":"有时候在上班的轻轨上、公交车上、火车上、总是想起人为什么而活着？，这话题很大。接着又会想这么劳累的奔波是为了什么，当然自认为还很年轻 做事总是有那么一些任性. 对于当前的生活总是那么诸多的不如意，在工作上总是有一些不对的心理因素存在，最近特别想离职了，说一下这份工作吧。从2013年7月份进入这家公司，当时感觉还不错吧，能让我学到一些业务和技术，但对于技术我是热情澎湃的。所以我在很短的时间内差不多搞定了公司目前所有的技术，在后期的工作中自我感觉也是比较轻松的，有时候还会去帮助其他同事解决一些问题，所以在公司的人际还算不错的，最近离职的原因主要分为以下几个 工作没有激情，原因目前我还不能确定(我不知道什么才算是激情) 感觉在公司没有多少自我提升的空间 比较喜欢玩技术，但是公司环境和其他因素导致公司的技术能力一直在原地踏步(目测这只是一个借口) 对外面的世界也算是充满希望和期待吧 记得当时找我的领导谈了差不多2个多小时，之所以能聊这么久是希望我能留下来继续工作，不管是因为任何原因的挽留 我都是感激我的领导的。领导当时讲了很多的道理，听着我觉得很有意思和道理，他的话我也都听进去了。最终在我心里面始终还是想离开这里去适应一个新环境。回家总结了一下是自己的目标不明确、没有职业定义和长久一点的规划、茫然。 好吧 就这样","tags":[{"name":"职业","slug":"职业","permalink":"https://blog.gitee.io/tags/职业/"}]},{"title":"wordpress搬迁到github pages","date":"2015-03-13T16:00:00.000Z","path":"2015/03/14/githubpages-init-test/","text":"没错、当看到这个页面的时候 我的博客已经从wordpress成功迁移到github pages上来了，非常遗憾的是由于之前的虚拟主机到期了，里面的数据我没有及时的备份所以后果非常严重 结果我们都懂的用markdown写文章，有想要的感觉 哈哈。虽然刚接触 促使我选择github pages的原因是 可以像使用git一样进行版本控制 主要是免费、无流量限制、安全 不用担心数据丢失的问题。 感觉就像写代码一样 真的已经随心所欲了…….","tags":[{"name":"github","slug":"github","permalink":"https://blog.gitee.io/tags/github/"}]},{"title":"代码高亮测试","date":"2015-03-12T16:00:00.000Z","path":"2015/03/13/hight/","text":"Update: If you would like to directly download the portable version of Jekyll. See my new blog post here Update (26/06/14): This article is bit outdated and no longer deemed official instuctions to get Jekyll running on Windows. Please see this article for more updated and authoritative source of instructions. Jekyll can also be made to run on Windows Operating System. This prefer when I am working on my office laptop which has Windows 7 installed on it. Following packages are required to setup Jekyll on Windows: Ruby &amp; Ruby Development Kit : Can be installed from here Jekyll Python : I strongly recommend using 2.7.5 as opposed to version 3. I used the portable version available here Pygments 1 Install the Ruby from http://rubyinstaller.org/downloads/ and install it to path such as C:\\ruby 2 Download “DEVELOPMENT KIT” installer that matches the Windows architecture and the Ruby version just installed. For example, DevKit-mingw64-64-4.7.2-20130224-1432-sfx.exe is for 64-bit Windows with Ruby 2.0.0 x64.Install the Ruby development kit from the same location above and extract it to path such as c:\\devkit. Run the following commands ruby dk.rb init to generate the config.yml file to be used later in this Step 3 Edit the generated config.yml file to include installed Rubies. For example, in our case, it will look like this # This configuration file contains the absolute path locations of all# installed Rubies to be enhanced to work with the DevKit. This config# file is generated by the &apos;ruby dk.rb init&apos; step and may be modified# before running the &apos;ruby dk.rb install&apos; step. To include any installed# Rubies that were not automagically discovered, simply add a line below# the triple hyphens with the absolute path to the Ruby root directory.## Example:## ---# - C:/ruby19trunk# - C:/ruby192dev#---- C:/ruby 4 Run the following command to install to DevKit enhance your installed Rubies. This step installs (or updates) an operating_system.rb file into the relevant directory needed to implement a RubyGems ruby dk.rb install 5 Install Jekyll using following commandgem install jekyll 6 Now, you can start using Jekyll. If you require code highlighting using pygments as well, follow the additional steps as well. 7 Now we need to install, easy_install. This can be installed from http://pypi.python.org/pypi/distributeDownload distribute_setup.py and run the following command in python python distribute_setup.py 8 Now to install pygments, simply run this command: Note that using Pygments version 0.5.0 is highly recommended. Latest version of Pygmnents has issues with Jekyll. easy_install Pygments 9 Start Jekyll Following the commands on official Jekyll Quick-start guide, a new Jekyll blog should be able to be created and browsed at localhost:4000. jekyll new myblogcd myblogjekyll serve Now browse to http://localhost:4000 #Troubleshooting# ##Liquid error: Bad file descriptor## You are likely to hit this error if you are using Python version &gt;3 as opposed to 2.7.5 as mentioned in the beginning Liquid error: Bad file descriptor TypeError: Can&apos;t convert &apos;bytes&apos; object to str implicitly These are known issues and the resolution has been discussed here:https://github.com/rtomayko/posix-spawn/issues/17 This requires a change in C:\\ruby\\lib\\ruby\\gems\\1.9.1\\gems\\albino-1.3.3\\lib\\albino.rb file. I have created the gist of the changes required here Build FailedThis will occur if Pygments is not installed. In that case, edit the _config.yml and Change ‘pygments: true’ to ‘pygments: false’ ##Pygments not working ## gem uninstall pygments.rb --version &quot;=0.5.2&quot; ; or whatever version you got installedgem install pygments.rb --version &quot;=0.5.0&quot; ##Failed to build gem native extension. or “python” is not recognized as an internal or external command, operable program or batch file. ## “python” here can also be “ruby”, “gem” or “easy_install”, etc. One of the reason of this error could be that your Ruby Dev kit binaries are not in PATH. Make sure that C:\\devkit or whatever path you installed Ruby Development kit to is in path. I make sure all the binaries of Ruby, Ruby Dev kit, Python are in path. SET PATH=%PATH%;C:\\ruby\\bin;C:\\devkit\\bin;C:\\git\\bin;C:\\Python\\App;C:\\devkit\\mingw\\bin In Windows, you can also set PATH permanently by following the steps below Hold Win and press Pause. Click Advanced System Settings. Click Environment Variables. Append ;C:\\python27 to the Path variable. Restart Command Prompt. ##If you get the following error with the –watch option## C:/Ruby193/lib/ruby/gems/1.9.1/gems/listen-1.3.1/lib/listen/adapter.rb:207:in `require&apos;: cannot load such file -- wdm (LoadError) To fix that error, open the gemfile in your jekyll project directory and add these two lines: require 'rbconfig'gem 'wdm', '&gt;= 0.1.0' if RbConfig::CONFIG['target_os'] =~ /mswin|mingw/i ##UTF-8 breaks on windows##UTF-8 files have sometimes problems on Windows. To fix this error, either have your files in non-UTF-8 format or specify RedCarpet as your Markdown engine in _config.yml # GitHub Defaultslsi: falsepygments: truesafe: true# UTF-8 &amp; parse errors fixmarkdown: redcarpet","tags":[{"name":"代码测试","slug":"代码测试","permalink":"https://blog.gitee.io/tags/代码测试/"}]},{"title":"测试一下","date":"2015-03-12T16:00:00.000Z","path":"2015/03/13/test/","text":"1测试成功了 哈哈 /* hello world demo */#include &lt;stdio.h&gt;int main(int argc, char **argv)&#123; printf(\"Hello, World!\\n\"); return 0;&#125; /* hello world demo */ public static void main(String[] args)&#123; &#125;","tags":[{"name":"测试","slug":"测试","permalink":"https://blog.gitee.io/tags/测试/"}]},{"title":"Demo post","date":"2014-03-06T16:00:00.000Z","path":"2014/03/07/demo-post/","text":"Praesent tincidunt vestibulum sem nec eleifend. Pellentesque adipiscing mollis adipiscing. Sed ipsum sem, eleifend eget dapibus in, tincidunt ut dolor. Curabitur gravida urna leo, eget auctor turpis feugiat non. Vivamus pharetra, lorem id ullamcorper rutrum, eros erat condimentum erat, ac dignissim lorem nisi nec nunc. Praesent tellus mi, volutpat quis nisl et, consectetur blandit nibh. Nulla sit amet nulla non odio sodales mollis elementum sed sem. Aenean et laoreet enim. Curabitur vulputate, mi rutrum commodo condimentum, enim nunc feugiat magna, vel rutrum sapien ante nec ante. Donec nec nibh placerat, molestie felis ac, vulputate arcu. Donec condimentum pellentesque nibh vel tincidunt. Fusce sem ipsum, varius at laoreet vitae, accumsan sed nisl. Nunc eget viverra diam. Aliquam pulvinar, enim id commodo tincidunt, risus lectus pharetra lacus, et semper enim ligula ut mauris. Sed vitae sollicitudin ante. In sollicitudin placerat dui et sagittis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas egestas leo id tortor feugiat, sit amet cursus diam mollis. Nunc sit amet tellus est. Nunc lacus nisl, gravida ut aliquam vel, molestie eget odio. Nulla facilisi. Ut sed libero pharetra nunc volutpat hendrerit. Mauris eget mi adipiscing, congue tellus ut, scelerisque eros. Phasellus ullamcorper dictum tellus nec pretium. Integer molestie orci ante, nec dictum metus aliquam ut. Donec id tristique enim. Quisque tellus est, dignissim ut justo ac, volutpat fringilla mi. Duis ultricies nec sapien vitae blandit. Suspendisse sed est mi. Mauris varius sapien vel nulla accumsan, id tincidunt ipsum ultrices. Sed eget magna mauris. Etiam porttitor lacus ullamcorper lacus tincidunt aliquam. Sed feugiat congue fringilla. Nunc velit diam, vulputate sed metus vitae, iaculis tempor arcu. Proin consectetur a erat in dignissim. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 Pellentesque adipiscing mollis adipiscing. Nulla sit amet nulla non odio sodales mollis elementum sed sem. Donec id tristique enim. Quisque tellus est, dignissim ut justo ac, volutpat fringilla mi. Nam luctus erat dolor, non viverra nulla varius at. Curabitur nec ullamcorper dui, blandit aliquet ipsum. Integer suscipit odio quis eros fermentum auctor. Sed tincidunt quam eleifend, egestas erat vulputate, tincidunt metus. Maecenas gravida sodales mi nec posuere. Cras vel nisi condimentum, hendrerit lacus sed, scelerisque ipsum. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Nunc convallis vestibulum erat, quis porta tellus. In lorem erat, sollicitudin varius posuere id, molestie ac eros. Fusce luctus tellus vitae vulputate venenatis. Sed scelerisque bibendum interdum. Sed pretium commodo ultrices. Fusce luctus quam id porttitor vulputate. Integer ornare consectetur diam eget rutrum. Etiam eget sapien metus. Ornare Cras vel nisi condimentum, hendrerit lacus sed, scelerisque ipsum. Convallis In lorem erat, sollicitudin varius posuere id, molestie ac eros Proin at libero id lorem fermentum elementum quis eget est. Nam bibendum turpis massa, at accumsan justo fermentum ac. Nulla non nulla ut ante condimentum mattis vel at lectus. Etiam eget tortor tincidunt, iaculis ligula a, tristique massa. Fusce sed congue lorem, interdum sodales nisl. Etiam consequat euismod ornare. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Nulla pellentesque ipsum vulputate, pellentesque nisl vitae, lacinia sem. Praesent auctor felis et odio ultrices, nec tempor elit lobortis. Etiam ornare massa non risus luctus, id iaculis lacus egestas. Pellentesque massa dolor, mattis id lobortis eget, tristique vitae est. Nam vulputate leo vitae libero vehicula, id tincidunt velit malesuada. In vel ornare nisi, id semper turpis. Vivamus erat elit, venenatis quis dui at, convallis suscipit sapien. Nunc in nisi scelerisque, aliquam mauris porttitor, facilisis ligula. Vestibulum cursus erat ac turpis bibendum, id pulvinar dolor dapibus. Proin vitae justo et velit imperdiet ultrices id id odio. Cras adipiscing ante vel mauris lobortis rutrum. Aenean eu felis est. In lacinia porttitor risus non sagittis. class Greeter def initialize(message) @message = message end def greet puts message endendjohn = Greeter.new &#39;Hello, World&#39;john.greet Sed imperdiet interdum ultrices. Phasellus iaculis porttitor lorem nec scelerisque. Suspendisse eros urna, adipiscing vel luctus at, feugiat sit amet arcu. Aliquam porttitor ut urna pellentesque sagittis. Donec pellentesque venenatis diam sit amet cursus. Etiam luctus, metus quis gravida fermentum, tortor arcu consequat metus, eget viverra augue risus ac dui. Fusce faucibus scelerisque quam eu sagittis. Sed sit amet sapien non augue lobortis adipiscing. Sed sagittis at lectus eu tempus. Nulla non nulla ut ante condimentum mattis vel at lectus. Nulla ultricies dui et urna semper ultrices. Sed neque ante, dictum in dignissim luctus, facilisis ornare odio. Aenean tempor ultrices magna non pharetra. Curabitur vulputate nec est aliquet suscipit. Etiam ipsum sapien, dictum quis tristique vel, pretium at elit.","tags":[{"name":"测试","slug":"测试","permalink":"https://blog.gitee.io/tags/测试/"}]}]